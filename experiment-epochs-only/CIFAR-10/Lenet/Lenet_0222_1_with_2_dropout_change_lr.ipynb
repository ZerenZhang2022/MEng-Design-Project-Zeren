{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1sLDxOgbykC",
        "outputId": "769860b4-0aee-4f91-8221-1a7abcff9383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_gZ8miyVENF",
        "outputId": "7b263a3a-ecd1-428f-cf89-9fda9c8a8a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "391/391 [==============================] - 4s 8ms/step - loss: 2.2568 - accuracy: 0.1489 - val_loss: 2.1263 - val_accuracy: 0.2032 - lr: 0.0200\n",
            "Epoch 2/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0187 - accuracy: 0.2611 - val_loss: 1.9233 - val_accuracy: 0.3099 - lr: 0.0200\n",
            "Epoch 3/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8822 - accuracy: 0.3155 - val_loss: 1.8584 - val_accuracy: 0.3295 - lr: 0.0200\n",
            "Epoch 4/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.7742 - accuracy: 0.3569 - val_loss: 1.6522 - val_accuracy: 0.4134 - lr: 0.0200\n",
            "Epoch 5/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.6855 - accuracy: 0.3880 - val_loss: 1.6151 - val_accuracy: 0.4177 - lr: 0.0200\n",
            "Epoch 6/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.6124 - accuracy: 0.4129 - val_loss: 1.5183 - val_accuracy: 0.4441 - lr: 0.0200\n",
            "Epoch 7/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5580 - accuracy: 0.4365 - val_loss: 1.4819 - val_accuracy: 0.4704 - lr: 0.0200\n",
            "Epoch 8/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5130 - accuracy: 0.4540 - val_loss: 1.4543 - val_accuracy: 0.4780 - lr: 0.0200\n",
            "Epoch 9/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.4725 - accuracy: 0.4687 - val_loss: 1.3963 - val_accuracy: 0.4956 - lr: 0.0200\n",
            "Epoch 10/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4385 - accuracy: 0.4827 - val_loss: 1.3452 - val_accuracy: 0.5152 - lr: 0.0200\n",
            "Epoch 11/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.4155 - accuracy: 0.4875 - val_loss: 1.3251 - val_accuracy: 0.5255 - lr: 0.0200\n",
            "Epoch 12/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3920 - accuracy: 0.5009 - val_loss: 1.3609 - val_accuracy: 0.5139 - lr: 0.0200\n",
            "Epoch 13/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3627 - accuracy: 0.5133 - val_loss: 1.2970 - val_accuracy: 0.5353 - lr: 0.0200\n",
            "Epoch 14/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3419 - accuracy: 0.5201 - val_loss: 1.2718 - val_accuracy: 0.5450 - lr: 0.0200\n",
            "Epoch 15/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.3256 - accuracy: 0.5245 - val_loss: 1.2979 - val_accuracy: 0.5371 - lr: 0.0200\n",
            "Epoch 16/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.3078 - accuracy: 0.5343 - val_loss: 1.2228 - val_accuracy: 0.5696 - lr: 0.0200\n",
            "Epoch 17/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2887 - accuracy: 0.5409 - val_loss: 1.2259 - val_accuracy: 0.5644 - lr: 0.0200\n",
            "Epoch 18/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2747 - accuracy: 0.5446 - val_loss: 1.2343 - val_accuracy: 0.5599 - lr: 0.0200\n",
            "Epoch 19/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2536 - accuracy: 0.5549 - val_loss: 1.2040 - val_accuracy: 0.5707 - lr: 0.0200\n",
            "Epoch 20/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2387 - accuracy: 0.5594 - val_loss: 1.1902 - val_accuracy: 0.5802 - lr: 0.0200\n",
            "Epoch 21/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.2274 - accuracy: 0.5616 - val_loss: 1.1704 - val_accuracy: 0.5880 - lr: 0.0200\n",
            "Epoch 22/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2138 - accuracy: 0.5687 - val_loss: 1.1536 - val_accuracy: 0.5928 - lr: 0.0200\n",
            "Epoch 23/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1994 - accuracy: 0.5731 - val_loss: 1.2149 - val_accuracy: 0.5732 - lr: 0.0200\n",
            "Epoch 24/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1910 - accuracy: 0.5772 - val_loss: 1.1499 - val_accuracy: 0.5881 - lr: 0.0200\n",
            "Epoch 25/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.1778 - accuracy: 0.5840 - val_loss: 1.2713 - val_accuracy: 0.5435 - lr: 0.0200\n",
            "Epoch 26/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1705 - accuracy: 0.5843 - val_loss: 1.1397 - val_accuracy: 0.6042 - lr: 0.0200\n",
            "Epoch 27/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1576 - accuracy: 0.5883 - val_loss: 1.1020 - val_accuracy: 0.6153 - lr: 0.0200\n",
            "Epoch 28/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1468 - accuracy: 0.5914 - val_loss: 1.1030 - val_accuracy: 0.6092 - lr: 0.0200\n",
            "Epoch 29/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1363 - accuracy: 0.5984 - val_loss: 1.0967 - val_accuracy: 0.6106 - lr: 0.0200\n",
            "Epoch 30/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1274 - accuracy: 0.6028 - val_loss: 1.0925 - val_accuracy: 0.6090 - lr: 0.0200\n",
            "Epoch 31/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.1218 - accuracy: 0.6051 - val_loss: 1.0738 - val_accuracy: 0.6222 - lr: 0.0200\n",
            "Epoch 32/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1135 - accuracy: 0.6076 - val_loss: 1.0591 - val_accuracy: 0.6308 - lr: 0.0200\n",
            "Epoch 33/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1012 - accuracy: 0.6116 - val_loss: 1.0678 - val_accuracy: 0.6205 - lr: 0.0200\n",
            "Epoch 34/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.0930 - accuracy: 0.6138 - val_loss: 1.0383 - val_accuracy: 0.6336 - lr: 0.0200\n",
            "Epoch 35/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0910 - accuracy: 0.6161 - val_loss: 1.0375 - val_accuracy: 0.6371 - lr: 0.0200\n",
            "Epoch 36/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0789 - accuracy: 0.6197 - val_loss: 1.0539 - val_accuracy: 0.6276 - lr: 0.0200\n",
            "Epoch 37/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0684 - accuracy: 0.6235 - val_loss: 1.0846 - val_accuracy: 0.6169 - lr: 0.0200\n",
            "Epoch 38/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0643 - accuracy: 0.6250 - val_loss: 1.0359 - val_accuracy: 0.6349 - lr: 0.0200\n",
            "Epoch 39/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.0582 - accuracy: 0.6294 - val_loss: 1.0541 - val_accuracy: 0.6266 - lr: 0.0200\n",
            "Epoch 40/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0460 - accuracy: 0.6310 - val_loss: 1.0174 - val_accuracy: 0.6416 - lr: 0.0200\n",
            "Epoch 41/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0433 - accuracy: 0.6327 - val_loss: 1.0121 - val_accuracy: 0.6462 - lr: 0.0200\n",
            "Epoch 42/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0332 - accuracy: 0.6376 - val_loss: 1.0373 - val_accuracy: 0.6307 - lr: 0.0200\n",
            "Epoch 43/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0299 - accuracy: 0.6377 - val_loss: 1.0249 - val_accuracy: 0.6363 - lr: 0.0200\n",
            "Epoch 44/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0205 - accuracy: 0.6422 - val_loss: 1.0521 - val_accuracy: 0.6250 - lr: 0.0200\n",
            "Epoch 45/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0144 - accuracy: 0.6439 - val_loss: 1.0143 - val_accuracy: 0.6433 - lr: 0.0200\n",
            "Epoch 46/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0068 - accuracy: 0.6462 - val_loss: 0.9835 - val_accuracy: 0.6539 - lr: 0.0200\n",
            "Epoch 47/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0033 - accuracy: 0.6485 - val_loss: 0.9701 - val_accuracy: 0.6591 - lr: 0.0200\n",
            "Epoch 48/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9956 - accuracy: 0.6494 - val_loss: 0.9620 - val_accuracy: 0.6619 - lr: 0.0200\n",
            "Epoch 49/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9938 - accuracy: 0.6495 - val_loss: 0.9817 - val_accuracy: 0.6553 - lr: 0.0200\n",
            "Epoch 50/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9797 - accuracy: 0.6549 - val_loss: 0.9739 - val_accuracy: 0.6552 - lr: 0.0200\n",
            "Epoch 51/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9743 - accuracy: 0.6577 - val_loss: 0.9756 - val_accuracy: 0.6540 - lr: 0.0200\n",
            "Epoch 52/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9677 - accuracy: 0.6616 - val_loss: 0.9657 - val_accuracy: 0.6581 - lr: 0.0200\n",
            "Epoch 53/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9641 - accuracy: 0.6638 - val_loss: 0.9628 - val_accuracy: 0.6599 - lr: 0.0200\n",
            "Epoch 54/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.9604 - accuracy: 0.6615 - val_loss: 0.9866 - val_accuracy: 0.6495 - lr: 0.0200\n",
            "Epoch 55/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9536 - accuracy: 0.6666 - val_loss: 0.9428 - val_accuracy: 0.6655 - lr: 0.0200\n",
            "Epoch 56/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9450 - accuracy: 0.6657 - val_loss: 0.9349 - val_accuracy: 0.6691 - lr: 0.0200\n",
            "Epoch 57/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9409 - accuracy: 0.6694 - val_loss: 0.9470 - val_accuracy: 0.6609 - lr: 0.0200\n",
            "Epoch 58/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9319 - accuracy: 0.6717 - val_loss: 0.9593 - val_accuracy: 0.6627 - lr: 0.0200\n",
            "Epoch 59/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9294 - accuracy: 0.6742 - val_loss: 0.9198 - val_accuracy: 0.6738 - lr: 0.0200\n",
            "Epoch 60/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9237 - accuracy: 0.6750 - val_loss: 0.9319 - val_accuracy: 0.6676 - lr: 0.0200\n",
            "Epoch 61/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.9205 - accuracy: 0.6753 - val_loss: 0.9325 - val_accuracy: 0.6700 - lr: 0.0200\n",
            "Epoch 62/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9149 - accuracy: 0.6774 - val_loss: 0.9294 - val_accuracy: 0.6691 - lr: 0.0200\n",
            "Epoch 63/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9101 - accuracy: 0.6809 - val_loss: 0.9550 - val_accuracy: 0.6606 - lr: 0.0200\n",
            "Epoch 64/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9005 - accuracy: 0.6838 - val_loss: 0.9117 - val_accuracy: 0.6798 - lr: 0.0200\n",
            "Epoch 65/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.8956 - accuracy: 0.6858 - val_loss: 0.9158 - val_accuracy: 0.6747 - lr: 0.0200\n",
            "Epoch 66/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8896 - accuracy: 0.6865 - val_loss: 0.9297 - val_accuracy: 0.6763 - lr: 0.0200\n",
            "Epoch 67/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8879 - accuracy: 0.6881 - val_loss: 0.9167 - val_accuracy: 0.6781 - lr: 0.0200\n",
            "Epoch 68/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8847 - accuracy: 0.6895 - val_loss: 0.9276 - val_accuracy: 0.6709 - lr: 0.0200\n",
            "Epoch 69/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8810 - accuracy: 0.6897 - val_loss: 0.8972 - val_accuracy: 0.6847 - lr: 0.0200\n",
            "Epoch 70/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8723 - accuracy: 0.6932 - val_loss: 0.9087 - val_accuracy: 0.6787 - lr: 0.0200\n",
            "Epoch 71/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8682 - accuracy: 0.6944 - val_loss: 0.8934 - val_accuracy: 0.6872 - lr: 0.0200\n",
            "Epoch 72/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8718 - accuracy: 0.6949 - val_loss: 0.9124 - val_accuracy: 0.6756 - lr: 0.0200\n",
            "Epoch 73/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8595 - accuracy: 0.6974 - val_loss: 0.8884 - val_accuracy: 0.6830 - lr: 0.0200\n",
            "Epoch 74/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8530 - accuracy: 0.6988 - val_loss: 0.9279 - val_accuracy: 0.6690 - lr: 0.0200\n",
            "Epoch 75/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.8507 - accuracy: 0.6989 - val_loss: 0.9061 - val_accuracy: 0.6842 - lr: 0.0200\n",
            "Epoch 76/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8471 - accuracy: 0.7010 - val_loss: 0.9467 - val_accuracy: 0.6691 - lr: 0.0200\n",
            "Epoch 77/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8433 - accuracy: 0.7029 - val_loss: 0.8923 - val_accuracy: 0.6818 - lr: 0.0200\n",
            "Epoch 78/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8357 - accuracy: 0.7051 - val_loss: 0.8825 - val_accuracy: 0.6873 - lr: 0.0200\n",
            "Epoch 79/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8354 - accuracy: 0.7074 - val_loss: 0.8877 - val_accuracy: 0.6889 - lr: 0.0200\n",
            "Epoch 80/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8283 - accuracy: 0.7090 - val_loss: 0.8766 - val_accuracy: 0.6919 - lr: 0.0200\n",
            "Epoch 81/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8238 - accuracy: 0.7088 - val_loss: 0.8936 - val_accuracy: 0.6841 - lr: 0.0200\n",
            "Epoch 82/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8192 - accuracy: 0.7101 - val_loss: 0.8812 - val_accuracy: 0.6877 - lr: 0.0200\n",
            "Epoch 83/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8160 - accuracy: 0.7128 - val_loss: 0.8631 - val_accuracy: 0.6946 - lr: 0.0200\n",
            "Epoch 84/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8128 - accuracy: 0.7127 - val_loss: 0.8762 - val_accuracy: 0.6912 - lr: 0.0200\n",
            "Epoch 85/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.8133 - accuracy: 0.7138 - val_loss: 0.8905 - val_accuracy: 0.6899 - lr: 0.0200\n",
            "Epoch 86/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8035 - accuracy: 0.7163 - val_loss: 0.8746 - val_accuracy: 0.6901 - lr: 0.0200\n",
            "Epoch 87/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8048 - accuracy: 0.7179 - val_loss: 0.8846 - val_accuracy: 0.6880 - lr: 0.0200\n",
            "Epoch 88/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8039 - accuracy: 0.7137 - val_loss: 0.8754 - val_accuracy: 0.6906 - lr: 0.0200\n",
            "Epoch 89/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7978 - accuracy: 0.7176 - val_loss: 0.8593 - val_accuracy: 0.6957 - lr: 0.0200\n",
            "Epoch 90/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7905 - accuracy: 0.7227 - val_loss: 0.8491 - val_accuracy: 0.7006 - lr: 0.0200\n",
            "Epoch 91/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7914 - accuracy: 0.7196 - val_loss: 0.8806 - val_accuracy: 0.6916 - lr: 0.0200\n",
            "Epoch 92/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7797 - accuracy: 0.7240 - val_loss: 0.8877 - val_accuracy: 0.6842 - lr: 0.0200\n",
            "Epoch 93/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7748 - accuracy: 0.7274 - val_loss: 0.8722 - val_accuracy: 0.6926 - lr: 0.0200\n",
            "Epoch 94/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7763 - accuracy: 0.7262 - val_loss: 0.9208 - val_accuracy: 0.6745 - lr: 0.0200\n",
            "Epoch 95/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7787 - accuracy: 0.7267 - val_loss: 0.8795 - val_accuracy: 0.6919 - lr: 0.0200\n",
            "Epoch 96/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7722 - accuracy: 0.7272 - val_loss: 0.8802 - val_accuracy: 0.6947 - lr: 0.0200\n",
            "Epoch 97/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7732 - accuracy: 0.7287 - val_loss: 0.8448 - val_accuracy: 0.7060 - lr: 0.0200\n",
            "Epoch 98/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7634 - accuracy: 0.7298 - val_loss: 0.8460 - val_accuracy: 0.7046 - lr: 0.0200\n",
            "Epoch 99/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7603 - accuracy: 0.7319 - val_loss: 0.8662 - val_accuracy: 0.7008 - lr: 0.0200\n",
            "Epoch 100/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7618 - accuracy: 0.7295 - val_loss: 0.8959 - val_accuracy: 0.6859 - lr: 0.0200\n",
            "Epoch 101/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7323 - accuracy: 0.7422 - val_loss: 0.8389 - val_accuracy: 0.7060 - lr: 0.0100\n",
            "Epoch 102/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7314 - accuracy: 0.7411 - val_loss: 0.8299 - val_accuracy: 0.7093 - lr: 0.0100\n",
            "Epoch 103/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7281 - accuracy: 0.7441 - val_loss: 0.8367 - val_accuracy: 0.7053 - lr: 0.0100\n",
            "Epoch 104/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7280 - accuracy: 0.7445 - val_loss: 0.8318 - val_accuracy: 0.7113 - lr: 0.0100\n",
            "Epoch 105/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7256 - accuracy: 0.7421 - val_loss: 0.8374 - val_accuracy: 0.7094 - lr: 0.0100\n",
            "Epoch 106/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7211 - accuracy: 0.7461 - val_loss: 0.8361 - val_accuracy: 0.7077 - lr: 0.0100\n",
            "Epoch 107/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7175 - accuracy: 0.7463 - val_loss: 0.8280 - val_accuracy: 0.7109 - lr: 0.0100\n",
            "Epoch 108/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7241 - accuracy: 0.7426 - val_loss: 0.8337 - val_accuracy: 0.7106 - lr: 0.0100\n",
            "Epoch 109/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7191 - accuracy: 0.7447 - val_loss: 0.8522 - val_accuracy: 0.7024 - lr: 0.0100\n",
            "Epoch 110/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7164 - accuracy: 0.7469 - val_loss: 0.8241 - val_accuracy: 0.7119 - lr: 0.0100\n",
            "Epoch 111/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7104 - accuracy: 0.7483 - val_loss: 0.8326 - val_accuracy: 0.7076 - lr: 0.0100\n",
            "Epoch 112/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7127 - accuracy: 0.7478 - val_loss: 0.8426 - val_accuracy: 0.7074 - lr: 0.0100\n",
            "Epoch 113/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7115 - accuracy: 0.7491 - val_loss: 0.8366 - val_accuracy: 0.7105 - lr: 0.0100\n",
            "Epoch 114/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7080 - accuracy: 0.7495 - val_loss: 0.8208 - val_accuracy: 0.7128 - lr: 0.0100\n",
            "Epoch 115/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7100 - accuracy: 0.7495 - val_loss: 0.8301 - val_accuracy: 0.7103 - lr: 0.0100\n",
            "Epoch 116/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7076 - accuracy: 0.7488 - val_loss: 0.8178 - val_accuracy: 0.7132 - lr: 0.0100\n",
            "Epoch 117/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7080 - accuracy: 0.7480 - val_loss: 0.8231 - val_accuracy: 0.7173 - lr: 0.0100\n",
            "Epoch 118/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7000 - accuracy: 0.7522 - val_loss: 0.8339 - val_accuracy: 0.7125 - lr: 0.0100\n",
            "Epoch 119/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7046 - accuracy: 0.7520 - val_loss: 0.8207 - val_accuracy: 0.7157 - lr: 0.0100\n",
            "Epoch 120/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7081 - accuracy: 0.7493 - val_loss: 0.8394 - val_accuracy: 0.7121 - lr: 0.0100\n",
            "Epoch 121/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7020 - accuracy: 0.7505 - val_loss: 0.8389 - val_accuracy: 0.7106 - lr: 0.0100\n",
            "Epoch 122/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7016 - accuracy: 0.7508 - val_loss: 0.8213 - val_accuracy: 0.7149 - lr: 0.0100\n",
            "Epoch 123/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6984 - accuracy: 0.7527 - val_loss: 0.8406 - val_accuracy: 0.7101 - lr: 0.0100\n",
            "Epoch 124/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7004 - accuracy: 0.7505 - val_loss: 0.8257 - val_accuracy: 0.7164 - lr: 0.0100\n",
            "Epoch 125/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6969 - accuracy: 0.7548 - val_loss: 0.8167 - val_accuracy: 0.7171 - lr: 0.0100\n",
            "Epoch 126/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6889 - accuracy: 0.7547 - val_loss: 0.8208 - val_accuracy: 0.7170 - lr: 0.0100\n",
            "Epoch 127/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.7523 - val_loss: 0.8277 - val_accuracy: 0.7156 - lr: 0.0100\n",
            "Epoch 128/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6907 - accuracy: 0.7559 - val_loss: 0.8280 - val_accuracy: 0.7118 - lr: 0.0100\n",
            "Epoch 129/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6915 - accuracy: 0.7535 - val_loss: 0.8245 - val_accuracy: 0.7160 - lr: 0.0100\n",
            "Epoch 130/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6868 - accuracy: 0.7589 - val_loss: 0.8188 - val_accuracy: 0.7170 - lr: 0.0100\n",
            "Epoch 131/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6899 - accuracy: 0.7566 - val_loss: 0.8189 - val_accuracy: 0.7166 - lr: 0.0100\n",
            "Epoch 132/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6828 - accuracy: 0.7586 - val_loss: 0.8277 - val_accuracy: 0.7137 - lr: 0.0100\n",
            "Epoch 133/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6865 - accuracy: 0.7581 - val_loss: 0.8204 - val_accuracy: 0.7156 - lr: 0.0100\n",
            "Epoch 134/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6851 - accuracy: 0.7569 - val_loss: 0.8218 - val_accuracy: 0.7147 - lr: 0.0100\n",
            "Epoch 135/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6806 - accuracy: 0.7604 - val_loss: 0.8419 - val_accuracy: 0.7110 - lr: 0.0100\n",
            "Epoch 136/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6794 - accuracy: 0.7610 - val_loss: 0.8233 - val_accuracy: 0.7139 - lr: 0.0100\n",
            "Epoch 137/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6812 - accuracy: 0.7588 - val_loss: 0.8225 - val_accuracy: 0.7170 - lr: 0.0100\n",
            "Epoch 138/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6800 - accuracy: 0.7596 - val_loss: 0.8201 - val_accuracy: 0.7171 - lr: 0.0100\n",
            "Epoch 139/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6755 - accuracy: 0.7626 - val_loss: 0.8209 - val_accuracy: 0.7204 - lr: 0.0100\n",
            "Epoch 140/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6743 - accuracy: 0.7621 - val_loss: 0.8283 - val_accuracy: 0.7156 - lr: 0.0100\n",
            "Epoch 141/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6750 - accuracy: 0.7596 - val_loss: 0.8359 - val_accuracy: 0.7128 - lr: 0.0100\n",
            "Epoch 142/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6761 - accuracy: 0.7594 - val_loss: 0.8219 - val_accuracy: 0.7191 - lr: 0.0100\n",
            "Epoch 143/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6719 - accuracy: 0.7616 - val_loss: 0.8216 - val_accuracy: 0.7172 - lr: 0.0100\n",
            "Epoch 144/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6730 - accuracy: 0.7613 - val_loss: 0.8287 - val_accuracy: 0.7144 - lr: 0.0100\n",
            "Epoch 145/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6691 - accuracy: 0.7624 - val_loss: 0.8202 - val_accuracy: 0.7175 - lr: 0.0100\n",
            "Epoch 146/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6684 - accuracy: 0.7611 - val_loss: 0.8523 - val_accuracy: 0.7051 - lr: 0.0100\n",
            "Epoch 147/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6667 - accuracy: 0.7634 - val_loss: 0.8263 - val_accuracy: 0.7156 - lr: 0.0100\n",
            "Epoch 148/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6700 - accuracy: 0.7642 - val_loss: 0.8282 - val_accuracy: 0.7130 - lr: 0.0100\n",
            "Epoch 149/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6642 - accuracy: 0.7643 - val_loss: 0.8192 - val_accuracy: 0.7203 - lr: 0.0100\n",
            "Epoch 150/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6654 - accuracy: 0.7652 - val_loss: 0.8254 - val_accuracy: 0.7172 - lr: 0.0100\n",
            "Epoch 151/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6632 - accuracy: 0.7662 - val_loss: 0.8231 - val_accuracy: 0.7205 - lr: 0.0100\n",
            "Epoch 152/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6632 - accuracy: 0.7640 - val_loss: 0.8294 - val_accuracy: 0.7177 - lr: 0.0100\n",
            "Epoch 153/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6610 - accuracy: 0.7642 - val_loss: 0.8193 - val_accuracy: 0.7190 - lr: 0.0100\n",
            "Epoch 154/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6592 - accuracy: 0.7654 - val_loss: 0.8453 - val_accuracy: 0.7140 - lr: 0.0100\n",
            "Epoch 155/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6569 - accuracy: 0.7673 - val_loss: 0.8194 - val_accuracy: 0.7206 - lr: 0.0100\n",
            "Epoch 156/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6600 - accuracy: 0.7663 - val_loss: 0.8158 - val_accuracy: 0.7198 - lr: 0.0100\n",
            "Epoch 157/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6523 - accuracy: 0.7686 - val_loss: 0.8230 - val_accuracy: 0.7190 - lr: 0.0100\n",
            "Epoch 158/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6561 - accuracy: 0.7649 - val_loss: 0.8156 - val_accuracy: 0.7199 - lr: 0.0100\n",
            "Epoch 159/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6528 - accuracy: 0.7699 - val_loss: 0.8182 - val_accuracy: 0.7204 - lr: 0.0100\n",
            "Epoch 160/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6534 - accuracy: 0.7674 - val_loss: 0.8281 - val_accuracy: 0.7174 - lr: 0.0100\n",
            "Epoch 161/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6543 - accuracy: 0.7663 - val_loss: 0.8431 - val_accuracy: 0.7104 - lr: 0.0100\n",
            "Epoch 162/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6481 - accuracy: 0.7702 - val_loss: 0.8452 - val_accuracy: 0.7122 - lr: 0.0100\n",
            "Epoch 163/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6483 - accuracy: 0.7701 - val_loss: 0.8403 - val_accuracy: 0.7133 - lr: 0.0100\n",
            "Epoch 164/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6477 - accuracy: 0.7707 - val_loss: 0.8408 - val_accuracy: 0.7150 - lr: 0.0100\n",
            "Epoch 165/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6469 - accuracy: 0.7717 - val_loss: 0.8194 - val_accuracy: 0.7221 - lr: 0.0100\n",
            "Epoch 166/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6517 - accuracy: 0.7685 - val_loss: 0.8639 - val_accuracy: 0.7020 - lr: 0.0100\n",
            "Epoch 167/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6443 - accuracy: 0.7698 - val_loss: 0.8160 - val_accuracy: 0.7234 - lr: 0.0100\n",
            "Epoch 168/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6455 - accuracy: 0.7704 - val_loss: 0.8143 - val_accuracy: 0.7204 - lr: 0.0100\n",
            "Epoch 169/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6397 - accuracy: 0.7742 - val_loss: 0.8230 - val_accuracy: 0.7166 - lr: 0.0100\n",
            "Epoch 170/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6391 - accuracy: 0.7737 - val_loss: 0.8312 - val_accuracy: 0.7147 - lr: 0.0100\n",
            "Epoch 171/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6417 - accuracy: 0.7728 - val_loss: 0.8321 - val_accuracy: 0.7129 - lr: 0.0100\n",
            "Epoch 172/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6366 - accuracy: 0.7727 - val_loss: 0.8285 - val_accuracy: 0.7153 - lr: 0.0100\n",
            "Epoch 173/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6408 - accuracy: 0.7704 - val_loss: 0.8253 - val_accuracy: 0.7163 - lr: 0.0100\n",
            "Epoch 174/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6393 - accuracy: 0.7721 - val_loss: 0.8309 - val_accuracy: 0.7148 - lr: 0.0100\n",
            "Epoch 175/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6389 - accuracy: 0.7718 - val_loss: 0.8266 - val_accuracy: 0.7196 - lr: 0.0100\n",
            "Epoch 176/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6379 - accuracy: 0.7749 - val_loss: 0.8178 - val_accuracy: 0.7222 - lr: 0.0100\n",
            "Epoch 177/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6361 - accuracy: 0.7728 - val_loss: 0.8191 - val_accuracy: 0.7214 - lr: 0.0100\n",
            "Epoch 178/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6332 - accuracy: 0.7749 - val_loss: 0.8382 - val_accuracy: 0.7134 - lr: 0.0100\n",
            "Epoch 179/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6324 - accuracy: 0.7755 - val_loss: 0.8184 - val_accuracy: 0.7183 - lr: 0.0100\n",
            "Epoch 180/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6309 - accuracy: 0.7748 - val_loss: 0.8194 - val_accuracy: 0.7194 - lr: 0.0100\n",
            "Epoch 181/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6309 - accuracy: 0.7750 - val_loss: 0.8516 - val_accuracy: 0.7145 - lr: 0.0100\n",
            "Epoch 182/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6318 - accuracy: 0.7741 - val_loss: 0.8420 - val_accuracy: 0.7130 - lr: 0.0100\n",
            "Epoch 183/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6312 - accuracy: 0.7749 - val_loss: 0.8294 - val_accuracy: 0.7170 - lr: 0.0100\n",
            "Epoch 184/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6285 - accuracy: 0.7750 - val_loss: 0.8316 - val_accuracy: 0.7175 - lr: 0.0100\n",
            "Epoch 185/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6225 - accuracy: 0.7763 - val_loss: 0.8313 - val_accuracy: 0.7159 - lr: 0.0100\n",
            "Epoch 186/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6216 - accuracy: 0.7812 - val_loss: 0.8321 - val_accuracy: 0.7158 - lr: 0.0100\n",
            "Epoch 187/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6227 - accuracy: 0.7789 - val_loss: 0.8269 - val_accuracy: 0.7189 - lr: 0.0100\n",
            "Epoch 188/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6292 - accuracy: 0.7766 - val_loss: 0.8223 - val_accuracy: 0.7185 - lr: 0.0100\n",
            "Epoch 189/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6239 - accuracy: 0.7792 - val_loss: 0.8187 - val_accuracy: 0.7192 - lr: 0.0100\n",
            "Epoch 190/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6212 - accuracy: 0.7783 - val_loss: 0.8348 - val_accuracy: 0.7168 - lr: 0.0100\n",
            "Epoch 191/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6195 - accuracy: 0.7802 - val_loss: 0.8704 - val_accuracy: 0.7063 - lr: 0.0100\n",
            "Epoch 192/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6202 - accuracy: 0.7776 - val_loss: 0.8202 - val_accuracy: 0.7208 - lr: 0.0100\n",
            "Epoch 193/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6191 - accuracy: 0.7798 - val_loss: 0.8382 - val_accuracy: 0.7179 - lr: 0.0100\n",
            "Epoch 194/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6161 - accuracy: 0.7817 - val_loss: 0.8355 - val_accuracy: 0.7181 - lr: 0.0100\n",
            "Epoch 195/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6250 - accuracy: 0.7795 - val_loss: 0.8303 - val_accuracy: 0.7188 - lr: 0.0100\n",
            "Epoch 196/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6176 - accuracy: 0.7810 - val_loss: 0.8247 - val_accuracy: 0.7203 - lr: 0.0100\n",
            "Epoch 197/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6177 - accuracy: 0.7813 - val_loss: 0.8243 - val_accuracy: 0.7181 - lr: 0.0100\n",
            "Epoch 198/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6128 - accuracy: 0.7812 - val_loss: 0.8193 - val_accuracy: 0.7192 - lr: 0.0100\n",
            "Epoch 199/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6167 - accuracy: 0.7818 - val_loss: 0.8232 - val_accuracy: 0.7229 - lr: 0.0100\n",
            "Epoch 200/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6149 - accuracy: 0.7817 - val_loss: 0.8420 - val_accuracy: 0.7119 - lr: 0.0100\n",
            "Epoch 201/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6063 - accuracy: 0.7853 - val_loss: 0.8194 - val_accuracy: 0.7236 - lr: 0.0050\n",
            "Epoch 202/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6006 - accuracy: 0.7862 - val_loss: 0.8174 - val_accuracy: 0.7251 - lr: 0.0050\n",
            "Epoch 203/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5987 - accuracy: 0.7858 - val_loss: 0.8212 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 204/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6005 - accuracy: 0.7860 - val_loss: 0.8227 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 205/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5982 - accuracy: 0.7872 - val_loss: 0.8170 - val_accuracy: 0.7251 - lr: 0.0050\n",
            "Epoch 206/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5946 - accuracy: 0.7893 - val_loss: 0.8174 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 207/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5986 - accuracy: 0.7880 - val_loss: 0.8159 - val_accuracy: 0.7241 - lr: 0.0050\n",
            "Epoch 208/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5964 - accuracy: 0.7870 - val_loss: 0.8165 - val_accuracy: 0.7252 - lr: 0.0050\n",
            "Epoch 209/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5950 - accuracy: 0.7887 - val_loss: 0.8267 - val_accuracy: 0.7213 - lr: 0.0050\n",
            "Epoch 210/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5968 - accuracy: 0.7883 - val_loss: 0.8167 - val_accuracy: 0.7252 - lr: 0.0050\n",
            "Epoch 211/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5926 - accuracy: 0.7882 - val_loss: 0.8183 - val_accuracy: 0.7226 - lr: 0.0050\n",
            "Epoch 212/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5935 - accuracy: 0.7892 - val_loss: 0.8180 - val_accuracy: 0.7251 - lr: 0.0050\n",
            "Epoch 213/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5959 - accuracy: 0.7900 - val_loss: 0.8248 - val_accuracy: 0.7214 - lr: 0.0050\n",
            "Epoch 214/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5962 - accuracy: 0.7879 - val_loss: 0.8211 - val_accuracy: 0.7223 - lr: 0.0050\n",
            "Epoch 215/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5962 - accuracy: 0.7871 - val_loss: 0.8336 - val_accuracy: 0.7172 - lr: 0.0050\n",
            "Epoch 216/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5924 - accuracy: 0.7880 - val_loss: 0.8202 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 217/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5941 - accuracy: 0.7904 - val_loss: 0.8184 - val_accuracy: 0.7242 - lr: 0.0050\n",
            "Epoch 218/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5927 - accuracy: 0.7900 - val_loss: 0.8258 - val_accuracy: 0.7237 - lr: 0.0050\n",
            "Epoch 219/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5940 - accuracy: 0.7885 - val_loss: 0.8146 - val_accuracy: 0.7231 - lr: 0.0050\n",
            "Epoch 220/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5966 - accuracy: 0.7891 - val_loss: 0.8313 - val_accuracy: 0.7188 - lr: 0.0050\n",
            "Epoch 221/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5929 - accuracy: 0.7902 - val_loss: 0.8274 - val_accuracy: 0.7205 - lr: 0.0050\n",
            "Epoch 222/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5896 - accuracy: 0.7908 - val_loss: 0.8254 - val_accuracy: 0.7201 - lr: 0.0050\n",
            "Epoch 223/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5867 - accuracy: 0.7906 - val_loss: 0.8219 - val_accuracy: 0.7238 - lr: 0.0050\n",
            "Epoch 224/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5918 - accuracy: 0.7878 - val_loss: 0.8285 - val_accuracy: 0.7194 - lr: 0.0050\n",
            "Epoch 225/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.5911 - accuracy: 0.7893 - val_loss: 0.8269 - val_accuracy: 0.7203 - lr: 0.0050\n",
            "Epoch 226/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5893 - accuracy: 0.7917 - val_loss: 0.8284 - val_accuracy: 0.7214 - lr: 0.0050\n",
            "Epoch 227/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5871 - accuracy: 0.7916 - val_loss: 0.8140 - val_accuracy: 0.7267 - lr: 0.0050\n",
            "Epoch 228/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5893 - accuracy: 0.7884 - val_loss: 0.8191 - val_accuracy: 0.7250 - lr: 0.0050\n",
            "Epoch 229/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5901 - accuracy: 0.7892 - val_loss: 0.8155 - val_accuracy: 0.7266 - lr: 0.0050\n",
            "Epoch 230/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5894 - accuracy: 0.7912 - val_loss: 0.8221 - val_accuracy: 0.7243 - lr: 0.0050\n",
            "Epoch 231/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5883 - accuracy: 0.7910 - val_loss: 0.8186 - val_accuracy: 0.7248 - lr: 0.0050\n",
            "Epoch 232/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5870 - accuracy: 0.7909 - val_loss: 0.8263 - val_accuracy: 0.7222 - lr: 0.0050\n",
            "Epoch 233/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5836 - accuracy: 0.7921 - val_loss: 0.8243 - val_accuracy: 0.7223 - lr: 0.0050\n",
            "Epoch 234/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5832 - accuracy: 0.7923 - val_loss: 0.8241 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 235/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5860 - accuracy: 0.7922 - val_loss: 0.8228 - val_accuracy: 0.7250 - lr: 0.0050\n",
            "Epoch 236/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5873 - accuracy: 0.7901 - val_loss: 0.8220 - val_accuracy: 0.7235 - lr: 0.0050\n",
            "Epoch 237/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5854 - accuracy: 0.7918 - val_loss: 0.8270 - val_accuracy: 0.7239 - lr: 0.0050\n",
            "Epoch 238/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5800 - accuracy: 0.7938 - val_loss: 0.8247 - val_accuracy: 0.7209 - lr: 0.0050\n",
            "Epoch 239/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5792 - accuracy: 0.7924 - val_loss: 0.8289 - val_accuracy: 0.7248 - lr: 0.0050\n",
            "Epoch 240/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5808 - accuracy: 0.7936 - val_loss: 0.8236 - val_accuracy: 0.7221 - lr: 0.0050\n",
            "Epoch 241/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5855 - accuracy: 0.7928 - val_loss: 0.8212 - val_accuracy: 0.7236 - lr: 0.0050\n",
            "Epoch 242/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5794 - accuracy: 0.7934 - val_loss: 0.8183 - val_accuracy: 0.7250 - lr: 0.0050\n",
            "Epoch 243/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5778 - accuracy: 0.7939 - val_loss: 0.8291 - val_accuracy: 0.7197 - lr: 0.0050\n",
            "Epoch 244/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5819 - accuracy: 0.7926 - val_loss: 0.8326 - val_accuracy: 0.7198 - lr: 0.0050\n",
            "Epoch 245/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5784 - accuracy: 0.7948 - val_loss: 0.8240 - val_accuracy: 0.7238 - lr: 0.0050\n",
            "Epoch 246/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5782 - accuracy: 0.7932 - val_loss: 0.8269 - val_accuracy: 0.7203 - lr: 0.0050\n",
            "Epoch 247/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5793 - accuracy: 0.7935 - val_loss: 0.8269 - val_accuracy: 0.7219 - lr: 0.0050\n",
            "Epoch 248/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5805 - accuracy: 0.7924 - val_loss: 0.8236 - val_accuracy: 0.7238 - lr: 0.0050\n",
            "Epoch 249/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5804 - accuracy: 0.7932 - val_loss: 0.8244 - val_accuracy: 0.7259 - lr: 0.0050\n",
            "Epoch 250/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5795 - accuracy: 0.7920 - val_loss: 0.8188 - val_accuracy: 0.7250 - lr: 0.0050\n",
            "Epoch 251/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5765 - accuracy: 0.7951 - val_loss: 0.8259 - val_accuracy: 0.7224 - lr: 0.0050\n",
            "Epoch 252/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5803 - accuracy: 0.7925 - val_loss: 0.8161 - val_accuracy: 0.7244 - lr: 0.0050\n",
            "Epoch 253/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5799 - accuracy: 0.7953 - val_loss: 0.8242 - val_accuracy: 0.7215 - lr: 0.0050\n",
            "Epoch 254/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5765 - accuracy: 0.7949 - val_loss: 0.8261 - val_accuracy: 0.7259 - lr: 0.0050\n",
            "Epoch 255/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5760 - accuracy: 0.7944 - val_loss: 0.8264 - val_accuracy: 0.7211 - lr: 0.0050\n",
            "Epoch 256/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5788 - accuracy: 0.7947 - val_loss: 0.8297 - val_accuracy: 0.7224 - lr: 0.0050\n",
            "Epoch 257/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5729 - accuracy: 0.7941 - val_loss: 0.8232 - val_accuracy: 0.7238 - lr: 0.0050\n",
            "Epoch 258/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5795 - accuracy: 0.7933 - val_loss: 0.8198 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 259/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5775 - accuracy: 0.7949 - val_loss: 0.8211 - val_accuracy: 0.7215 - lr: 0.0050\n",
            "Epoch 260/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5738 - accuracy: 0.7966 - val_loss: 0.8275 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 261/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5742 - accuracy: 0.7964 - val_loss: 0.8312 - val_accuracy: 0.7208 - lr: 0.0050\n",
            "Epoch 262/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5785 - accuracy: 0.7942 - val_loss: 0.8218 - val_accuracy: 0.7231 - lr: 0.0050\n",
            "Epoch 263/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5738 - accuracy: 0.7958 - val_loss: 0.8221 - val_accuracy: 0.7255 - lr: 0.0050\n",
            "Epoch 264/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5768 - accuracy: 0.7943 - val_loss: 0.8303 - val_accuracy: 0.7220 - lr: 0.0050\n",
            "Epoch 265/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5720 - accuracy: 0.7962 - val_loss: 0.8207 - val_accuracy: 0.7240 - lr: 0.0050\n",
            "Epoch 266/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5696 - accuracy: 0.7980 - val_loss: 0.8361 - val_accuracy: 0.7205 - lr: 0.0050\n",
            "Epoch 267/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5725 - accuracy: 0.7969 - val_loss: 0.8243 - val_accuracy: 0.7244 - lr: 0.0050\n",
            "Epoch 268/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5701 - accuracy: 0.7975 - val_loss: 0.8301 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 269/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5739 - accuracy: 0.7978 - val_loss: 0.8244 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 270/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5702 - accuracy: 0.7951 - val_loss: 0.8278 - val_accuracy: 0.7233 - lr: 0.0050\n",
            "Epoch 271/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5706 - accuracy: 0.7982 - val_loss: 0.8275 - val_accuracy: 0.7228 - lr: 0.0050\n",
            "Epoch 272/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5692 - accuracy: 0.7973 - val_loss: 0.8310 - val_accuracy: 0.7205 - lr: 0.0050\n",
            "Epoch 273/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5722 - accuracy: 0.7943 - val_loss: 0.8200 - val_accuracy: 0.7261 - lr: 0.0050\n",
            "Epoch 274/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5688 - accuracy: 0.7968 - val_loss: 0.8278 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 275/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5715 - accuracy: 0.7960 - val_loss: 0.8305 - val_accuracy: 0.7237 - lr: 0.0050\n",
            "Epoch 276/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5665 - accuracy: 0.7976 - val_loss: 0.8253 - val_accuracy: 0.7218 - lr: 0.0050\n",
            "Epoch 277/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5743 - accuracy: 0.7942 - val_loss: 0.8229 - val_accuracy: 0.7248 - lr: 0.0050\n",
            "Epoch 278/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5611 - accuracy: 0.8011 - val_loss: 0.8290 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 279/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5694 - accuracy: 0.7971 - val_loss: 0.8323 - val_accuracy: 0.7209 - lr: 0.0050\n",
            "Epoch 280/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5665 - accuracy: 0.7988 - val_loss: 0.8290 - val_accuracy: 0.7228 - lr: 0.0050\n",
            "Epoch 281/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5742 - accuracy: 0.7940 - val_loss: 0.8332 - val_accuracy: 0.7201 - lr: 0.0050\n",
            "Epoch 282/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5681 - accuracy: 0.7972 - val_loss: 0.8285 - val_accuracy: 0.7228 - lr: 0.0050\n",
            "Epoch 283/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5666 - accuracy: 0.7989 - val_loss: 0.8264 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 284/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5652 - accuracy: 0.7985 - val_loss: 0.8280 - val_accuracy: 0.7225 - lr: 0.0050\n",
            "Epoch 285/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5629 - accuracy: 0.7982 - val_loss: 0.8302 - val_accuracy: 0.7220 - lr: 0.0050\n",
            "Epoch 286/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5631 - accuracy: 0.7980 - val_loss: 0.8260 - val_accuracy: 0.7237 - lr: 0.0050\n",
            "Epoch 287/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5638 - accuracy: 0.7970 - val_loss: 0.8258 - val_accuracy: 0.7230 - lr: 0.0050\n",
            "Epoch 288/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5624 - accuracy: 0.7986 - val_loss: 0.8318 - val_accuracy: 0.7233 - lr: 0.0050\n",
            "Epoch 289/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5644 - accuracy: 0.7988 - val_loss: 0.8254 - val_accuracy: 0.7237 - lr: 0.0050\n",
            "Epoch 290/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5664 - accuracy: 0.7986 - val_loss: 0.8240 - val_accuracy: 0.7240 - lr: 0.0050\n",
            "Epoch 291/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5621 - accuracy: 0.7996 - val_loss: 0.8292 - val_accuracy: 0.7228 - lr: 0.0050\n",
            "Epoch 292/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5601 - accuracy: 0.8003 - val_loss: 0.8377 - val_accuracy: 0.7205 - lr: 0.0050\n",
            "Epoch 293/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5672 - accuracy: 0.7983 - val_loss: 0.8267 - val_accuracy: 0.7231 - lr: 0.0050\n",
            "Epoch 294/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5670 - accuracy: 0.7985 - val_loss: 0.8388 - val_accuracy: 0.7188 - lr: 0.0050\n",
            "Epoch 295/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5614 - accuracy: 0.7998 - val_loss: 0.8324 - val_accuracy: 0.7197 - lr: 0.0050\n",
            "Epoch 296/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5571 - accuracy: 0.8017 - val_loss: 0.8353 - val_accuracy: 0.7209 - lr: 0.0050\n",
            "Epoch 297/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5641 - accuracy: 0.7978 - val_loss: 0.8303 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 298/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5608 - accuracy: 0.7996 - val_loss: 0.8264 - val_accuracy: 0.7235 - lr: 0.0050\n",
            "Epoch 299/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5598 - accuracy: 0.8008 - val_loss: 0.8273 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 300/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5577 - accuracy: 0.7992 - val_loss: 0.8352 - val_accuracy: 0.7254 - lr: 0.0050\n",
            "Epoch 301/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5603 - accuracy: 0.8011 - val_loss: 0.8312 - val_accuracy: 0.7229 - lr: 0.0050\n",
            "Epoch 302/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5546 - accuracy: 0.8022 - val_loss: 0.8346 - val_accuracy: 0.7214 - lr: 0.0050\n",
            "Epoch 303/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5603 - accuracy: 0.8014 - val_loss: 0.8279 - val_accuracy: 0.7261 - lr: 0.0050\n",
            "Epoch 304/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5556 - accuracy: 0.7992 - val_loss: 0.8364 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 305/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5614 - accuracy: 0.8003 - val_loss: 0.8272 - val_accuracy: 0.7259 - lr: 0.0050\n",
            "Epoch 306/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5611 - accuracy: 0.7998 - val_loss: 0.8346 - val_accuracy: 0.7200 - lr: 0.0050\n",
            "Epoch 307/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5614 - accuracy: 0.7985 - val_loss: 0.8289 - val_accuracy: 0.7243 - lr: 0.0050\n",
            "Epoch 308/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5591 - accuracy: 0.8017 - val_loss: 0.8333 - val_accuracy: 0.7204 - lr: 0.0050\n",
            "Epoch 309/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5615 - accuracy: 0.7993 - val_loss: 0.8419 - val_accuracy: 0.7161 - lr: 0.0050\n",
            "Epoch 310/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5545 - accuracy: 0.8028 - val_loss: 0.8356 - val_accuracy: 0.7226 - lr: 0.0050\n",
            "Epoch 311/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5534 - accuracy: 0.8032 - val_loss: 0.8245 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 312/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5553 - accuracy: 0.8009 - val_loss: 0.8321 - val_accuracy: 0.7219 - lr: 0.0050\n",
            "Epoch 313/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5556 - accuracy: 0.8020 - val_loss: 0.8395 - val_accuracy: 0.7178 - lr: 0.0050\n",
            "Epoch 314/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5615 - accuracy: 0.8001 - val_loss: 0.8364 - val_accuracy: 0.7203 - lr: 0.0050\n",
            "Epoch 315/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5541 - accuracy: 0.8016 - val_loss: 0.8284 - val_accuracy: 0.7233 - lr: 0.0050\n",
            "Epoch 316/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5594 - accuracy: 0.7991 - val_loss: 0.8312 - val_accuracy: 0.7199 - lr: 0.0050\n",
            "Epoch 317/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5528 - accuracy: 0.8008 - val_loss: 0.8310 - val_accuracy: 0.7205 - lr: 0.0050\n",
            "Epoch 318/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5486 - accuracy: 0.8031 - val_loss: 0.8307 - val_accuracy: 0.7202 - lr: 0.0050\n",
            "Epoch 319/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5555 - accuracy: 0.8018 - val_loss: 0.8309 - val_accuracy: 0.7221 - lr: 0.0050\n",
            "Epoch 320/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5498 - accuracy: 0.8040 - val_loss: 0.8342 - val_accuracy: 0.7233 - lr: 0.0050\n",
            "Epoch 321/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5535 - accuracy: 0.8022 - val_loss: 0.8299 - val_accuracy: 0.7213 - lr: 0.0050\n",
            "Epoch 322/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5484 - accuracy: 0.8040 - val_loss: 0.8343 - val_accuracy: 0.7226 - lr: 0.0050\n",
            "Epoch 323/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5558 - accuracy: 0.7999 - val_loss: 0.8371 - val_accuracy: 0.7208 - lr: 0.0050\n",
            "Epoch 324/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5534 - accuracy: 0.8025 - val_loss: 0.8309 - val_accuracy: 0.7257 - lr: 0.0050\n",
            "Epoch 325/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5473 - accuracy: 0.8057 - val_loss: 0.8359 - val_accuracy: 0.7219 - lr: 0.0050\n",
            "Epoch 326/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5520 - accuracy: 0.8022 - val_loss: 0.8324 - val_accuracy: 0.7239 - lr: 0.0050\n",
            "Epoch 327/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5532 - accuracy: 0.8042 - val_loss: 0.8345 - val_accuracy: 0.7240 - lr: 0.0050\n",
            "Epoch 328/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5523 - accuracy: 0.8028 - val_loss: 0.8299 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 329/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5518 - accuracy: 0.8052 - val_loss: 0.8290 - val_accuracy: 0.7214 - lr: 0.0050\n",
            "Epoch 330/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5555 - accuracy: 0.8005 - val_loss: 0.8367 - val_accuracy: 0.7202 - lr: 0.0050\n",
            "Epoch 331/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5495 - accuracy: 0.8035 - val_loss: 0.8352 - val_accuracy: 0.7220 - lr: 0.0050\n",
            "Epoch 332/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5461 - accuracy: 0.8026 - val_loss: 0.8356 - val_accuracy: 0.7240 - lr: 0.0050\n",
            "Epoch 333/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5471 - accuracy: 0.8039 - val_loss: 0.8368 - val_accuracy: 0.7226 - lr: 0.0050\n",
            "Epoch 334/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5475 - accuracy: 0.8039 - val_loss: 0.8454 - val_accuracy: 0.7202 - lr: 0.0050\n",
            "Epoch 335/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5489 - accuracy: 0.8038 - val_loss: 0.8422 - val_accuracy: 0.7202 - lr: 0.0050\n",
            "Epoch 336/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5493 - accuracy: 0.8028 - val_loss: 0.8336 - val_accuracy: 0.7221 - lr: 0.0050\n",
            "Epoch 337/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5466 - accuracy: 0.8052 - val_loss: 0.8327 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 338/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5480 - accuracy: 0.8055 - val_loss: 0.8431 - val_accuracy: 0.7170 - lr: 0.0050\n",
            "Epoch 339/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5441 - accuracy: 0.8057 - val_loss: 0.8311 - val_accuracy: 0.7245 - lr: 0.0050\n",
            "Epoch 340/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5451 - accuracy: 0.8047 - val_loss: 0.8433 - val_accuracy: 0.7222 - lr: 0.0050\n",
            "Epoch 341/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5436 - accuracy: 0.8066 - val_loss: 0.8382 - val_accuracy: 0.7247 - lr: 0.0050\n",
            "Epoch 342/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5475 - accuracy: 0.8049 - val_loss: 0.8397 - val_accuracy: 0.7228 - lr: 0.0050\n",
            "Epoch 343/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5416 - accuracy: 0.8055 - val_loss: 0.8298 - val_accuracy: 0.7249 - lr: 0.0050\n",
            "Epoch 344/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5422 - accuracy: 0.8057 - val_loss: 0.8408 - val_accuracy: 0.7225 - lr: 0.0050\n",
            "Epoch 345/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5414 - accuracy: 0.8058 - val_loss: 0.8333 - val_accuracy: 0.7227 - lr: 0.0050\n",
            "Epoch 346/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5491 - accuracy: 0.8034 - val_loss: 0.8445 - val_accuracy: 0.7189 - lr: 0.0050\n",
            "Epoch 347/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5477 - accuracy: 0.8038 - val_loss: 0.8363 - val_accuracy: 0.7230 - lr: 0.0050\n",
            "Epoch 348/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5448 - accuracy: 0.8055 - val_loss: 0.8359 - val_accuracy: 0.7193 - lr: 0.0050\n",
            "Epoch 349/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5417 - accuracy: 0.8058 - val_loss: 0.8392 - val_accuracy: 0.7235 - lr: 0.0050\n",
            "Epoch 350/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5444 - accuracy: 0.8037 - val_loss: 0.8370 - val_accuracy: 0.7190 - lr: 0.0050\n",
            "Epoch 351/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5461 - accuracy: 0.8047 - val_loss: 0.8373 - val_accuracy: 0.7220 - lr: 0.0050\n",
            "Epoch 352/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5441 - accuracy: 0.8051 - val_loss: 0.8341 - val_accuracy: 0.7230 - lr: 0.0050\n",
            "Epoch 353/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5417 - accuracy: 0.8088 - val_loss: 0.8390 - val_accuracy: 0.7196 - lr: 0.0050\n",
            "Epoch 354/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5404 - accuracy: 0.8050 - val_loss: 0.8361 - val_accuracy: 0.7204 - lr: 0.0050\n",
            "Epoch 355/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5378 - accuracy: 0.8077 - val_loss: 0.8398 - val_accuracy: 0.7229 - lr: 0.0050\n",
            "Epoch 356/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5396 - accuracy: 0.8069 - val_loss: 0.8423 - val_accuracy: 0.7233 - lr: 0.0050\n",
            "Epoch 357/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5428 - accuracy: 0.8067 - val_loss: 0.8508 - val_accuracy: 0.7153 - lr: 0.0050\n",
            "Epoch 358/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5428 - accuracy: 0.8068 - val_loss: 0.8368 - val_accuracy: 0.7231 - lr: 0.0050\n",
            "Epoch 359/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5409 - accuracy: 0.8075 - val_loss: 0.8404 - val_accuracy: 0.7198 - lr: 0.0050\n",
            "Epoch 360/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5398 - accuracy: 0.8073 - val_loss: 0.8414 - val_accuracy: 0.7232 - lr: 0.0050\n",
            "Epoch 361/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5422 - accuracy: 0.8056 - val_loss: 0.8517 - val_accuracy: 0.7183 - lr: 0.0050\n",
            "Epoch 362/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5416 - accuracy: 0.8088 - val_loss: 0.8473 - val_accuracy: 0.7192 - lr: 0.0050\n",
            "Epoch 363/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5407 - accuracy: 0.8066 - val_loss: 0.8378 - val_accuracy: 0.7204 - lr: 0.0050\n",
            "Epoch 364/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5408 - accuracy: 0.8065 - val_loss: 0.8359 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 365/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5441 - accuracy: 0.8048 - val_loss: 0.8464 - val_accuracy: 0.7191 - lr: 0.0050\n",
            "Epoch 366/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5370 - accuracy: 0.8069 - val_loss: 0.8386 - val_accuracy: 0.7224 - lr: 0.0050\n",
            "Epoch 367/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5372 - accuracy: 0.8072 - val_loss: 0.8409 - val_accuracy: 0.7197 - lr: 0.0050\n",
            "Epoch 368/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5400 - accuracy: 0.8070 - val_loss: 0.8296 - val_accuracy: 0.7254 - lr: 0.0050\n",
            "Epoch 369/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5376 - accuracy: 0.8061 - val_loss: 0.8330 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 370/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5400 - accuracy: 0.8076 - val_loss: 0.8426 - val_accuracy: 0.7181 - lr: 0.0050\n",
            "Epoch 371/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5366 - accuracy: 0.8064 - val_loss: 0.8335 - val_accuracy: 0.7246 - lr: 0.0050\n",
            "Epoch 372/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5396 - accuracy: 0.8066 - val_loss: 0.8387 - val_accuracy: 0.7222 - lr: 0.0050\n",
            "Epoch 373/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5396 - accuracy: 0.8067 - val_loss: 0.8446 - val_accuracy: 0.7195 - lr: 0.0050\n",
            "Epoch 374/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5333 - accuracy: 0.8103 - val_loss: 0.8322 - val_accuracy: 0.7236 - lr: 0.0050\n",
            "Epoch 375/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5356 - accuracy: 0.8072 - val_loss: 0.8410 - val_accuracy: 0.7214 - lr: 0.0050\n",
            "Epoch 376/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5313 - accuracy: 0.8106 - val_loss: 0.8402 - val_accuracy: 0.7224 - lr: 0.0050\n",
            "Epoch 377/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5333 - accuracy: 0.8088 - val_loss: 0.8421 - val_accuracy: 0.7209 - lr: 0.0050\n",
            "Epoch 378/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5314 - accuracy: 0.8105 - val_loss: 0.8501 - val_accuracy: 0.7186 - lr: 0.0050\n",
            "Epoch 379/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5326 - accuracy: 0.8100 - val_loss: 0.8409 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 380/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5313 - accuracy: 0.8093 - val_loss: 0.8466 - val_accuracy: 0.7203 - lr: 0.0050\n",
            "Epoch 381/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5313 - accuracy: 0.8099 - val_loss: 0.8552 - val_accuracy: 0.7192 - lr: 0.0050\n",
            "Epoch 382/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5382 - accuracy: 0.8082 - val_loss: 0.8475 - val_accuracy: 0.7231 - lr: 0.0050\n",
            "Epoch 383/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5353 - accuracy: 0.8075 - val_loss: 0.8367 - val_accuracy: 0.7202 - lr: 0.0050\n",
            "Epoch 384/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5330 - accuracy: 0.8088 - val_loss: 0.8473 - val_accuracy: 0.7225 - lr: 0.0050\n",
            "Epoch 385/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5308 - accuracy: 0.8090 - val_loss: 0.8474 - val_accuracy: 0.7201 - lr: 0.0050\n",
            "Epoch 386/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5325 - accuracy: 0.8098 - val_loss: 0.8404 - val_accuracy: 0.7207 - lr: 0.0050\n",
            "Epoch 387/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5347 - accuracy: 0.8079 - val_loss: 0.8504 - val_accuracy: 0.7203 - lr: 0.0050\n",
            "Epoch 388/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5317 - accuracy: 0.8087 - val_loss: 0.8352 - val_accuracy: 0.7235 - lr: 0.0050\n",
            "Epoch 389/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5296 - accuracy: 0.8095 - val_loss: 0.8492 - val_accuracy: 0.7210 - lr: 0.0050\n",
            "Epoch 390/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5291 - accuracy: 0.8111 - val_loss: 0.8435 - val_accuracy: 0.7212 - lr: 0.0050\n",
            "Epoch 391/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5308 - accuracy: 0.8098 - val_loss: 0.8572 - val_accuracy: 0.7188 - lr: 0.0050\n",
            "Epoch 392/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5332 - accuracy: 0.8075 - val_loss: 0.8536 - val_accuracy: 0.7224 - lr: 0.0050\n",
            "Epoch 393/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5315 - accuracy: 0.8076 - val_loss: 0.8444 - val_accuracy: 0.7215 - lr: 0.0050\n",
            "Epoch 394/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5280 - accuracy: 0.8131 - val_loss: 0.8548 - val_accuracy: 0.7210 - lr: 0.0050\n",
            "Epoch 395/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5282 - accuracy: 0.8103 - val_loss: 0.8554 - val_accuracy: 0.7196 - lr: 0.0050\n",
            "Epoch 396/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5320 - accuracy: 0.8094 - val_loss: 0.8541 - val_accuracy: 0.7204 - lr: 0.0050\n",
            "Epoch 397/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5293 - accuracy: 0.8102 - val_loss: 0.8526 - val_accuracy: 0.7190 - lr: 0.0050\n",
            "Epoch 398/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5337 - accuracy: 0.8074 - val_loss: 0.8419 - val_accuracy: 0.7225 - lr: 0.0050\n",
            "Epoch 399/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5299 - accuracy: 0.8094 - val_loss: 0.8410 - val_accuracy: 0.7228 - lr: 0.0050\n",
            "Epoch 400/1000\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5258 - accuracy: 0.8113 - val_loss: 0.8494 - val_accuracy: 0.7234 - lr: 0.0050\n",
            "Epoch 401/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5209 - accuracy: 0.8127 - val_loss: 0.8444 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 402/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5233 - accuracy: 0.8132 - val_loss: 0.8433 - val_accuracy: 0.7236 - lr: 0.0030\n",
            "Epoch 403/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5204 - accuracy: 0.8145 - val_loss: 0.8403 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 404/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5243 - accuracy: 0.8124 - val_loss: 0.8472 - val_accuracy: 0.7219 - lr: 0.0030\n",
            "Epoch 405/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5251 - accuracy: 0.8120 - val_loss: 0.8488 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 406/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5196 - accuracy: 0.8156 - val_loss: 0.8447 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 407/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5248 - accuracy: 0.8126 - val_loss: 0.8471 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 408/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5254 - accuracy: 0.8116 - val_loss: 0.8464 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 409/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5210 - accuracy: 0.8117 - val_loss: 0.8437 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 410/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5257 - accuracy: 0.8114 - val_loss: 0.8416 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 411/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5185 - accuracy: 0.8153 - val_loss: 0.8439 - val_accuracy: 0.7212 - lr: 0.0030\n",
            "Epoch 412/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5198 - accuracy: 0.8147 - val_loss: 0.8428 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 413/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5185 - accuracy: 0.8137 - val_loss: 0.8394 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 414/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5212 - accuracy: 0.8136 - val_loss: 0.8493 - val_accuracy: 0.7206 - lr: 0.0030\n",
            "Epoch 415/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5202 - accuracy: 0.8143 - val_loss: 0.8439 - val_accuracy: 0.7242 - lr: 0.0030\n",
            "Epoch 416/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5192 - accuracy: 0.8151 - val_loss: 0.8458 - val_accuracy: 0.7213 - lr: 0.0030\n",
            "Epoch 417/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5194 - accuracy: 0.8140 - val_loss: 0.8417 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 418/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5206 - accuracy: 0.8131 - val_loss: 0.8437 - val_accuracy: 0.7222 - lr: 0.0030\n",
            "Epoch 419/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5164 - accuracy: 0.8148 - val_loss: 0.8519 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 420/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5162 - accuracy: 0.8153 - val_loss: 0.8442 - val_accuracy: 0.7237 - lr: 0.0030\n",
            "Epoch 421/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5207 - accuracy: 0.8140 - val_loss: 0.8429 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 422/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5192 - accuracy: 0.8144 - val_loss: 0.8501 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 423/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5226 - accuracy: 0.8126 - val_loss: 0.8495 - val_accuracy: 0.7204 - lr: 0.0030\n",
            "Epoch 424/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5155 - accuracy: 0.8165 - val_loss: 0.8459 - val_accuracy: 0.7241 - lr: 0.0030\n",
            "Epoch 425/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5199 - accuracy: 0.8157 - val_loss: 0.8421 - val_accuracy: 0.7237 - lr: 0.0030\n",
            "Epoch 426/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5164 - accuracy: 0.8170 - val_loss: 0.8494 - val_accuracy: 0.7217 - lr: 0.0030\n",
            "Epoch 427/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5209 - accuracy: 0.8118 - val_loss: 0.8484 - val_accuracy: 0.7207 - lr: 0.0030\n",
            "Epoch 428/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5202 - accuracy: 0.8130 - val_loss: 0.8480 - val_accuracy: 0.7208 - lr: 0.0030\n",
            "Epoch 429/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5175 - accuracy: 0.8154 - val_loss: 0.8507 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 430/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5177 - accuracy: 0.8162 - val_loss: 0.8446 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 431/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5148 - accuracy: 0.8149 - val_loss: 0.8476 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 432/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5191 - accuracy: 0.8147 - val_loss: 0.8504 - val_accuracy: 0.7207 - lr: 0.0030\n",
            "Epoch 433/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5170 - accuracy: 0.8172 - val_loss: 0.8460 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 434/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5178 - accuracy: 0.8150 - val_loss: 0.8496 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 435/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5186 - accuracy: 0.8144 - val_loss: 0.8430 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 436/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5203 - accuracy: 0.8129 - val_loss: 0.8463 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 437/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5164 - accuracy: 0.8147 - val_loss: 0.8421 - val_accuracy: 0.7238 - lr: 0.0030\n",
            "Epoch 438/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5191 - accuracy: 0.8131 - val_loss: 0.8476 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 439/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5210 - accuracy: 0.8140 - val_loss: 0.8430 - val_accuracy: 0.7250 - lr: 0.0030\n",
            "Epoch 440/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5146 - accuracy: 0.8150 - val_loss: 0.8480 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 441/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5198 - accuracy: 0.8146 - val_loss: 0.8540 - val_accuracy: 0.7192 - lr: 0.0030\n",
            "Epoch 442/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5125 - accuracy: 0.8164 - val_loss: 0.8494 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 443/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5137 - accuracy: 0.8148 - val_loss: 0.8468 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 444/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5106 - accuracy: 0.8175 - val_loss: 0.8503 - val_accuracy: 0.7227 - lr: 0.0030\n",
            "Epoch 445/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5173 - accuracy: 0.8147 - val_loss: 0.8505 - val_accuracy: 0.7209 - lr: 0.0030\n",
            "Epoch 446/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5178 - accuracy: 0.8147 - val_loss: 0.8439 - val_accuracy: 0.7227 - lr: 0.0030\n",
            "Epoch 447/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5138 - accuracy: 0.8150 - val_loss: 0.8448 - val_accuracy: 0.7239 - lr: 0.0030\n",
            "Epoch 448/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5141 - accuracy: 0.8165 - val_loss: 0.8469 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 449/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5108 - accuracy: 0.8169 - val_loss: 0.8551 - val_accuracy: 0.7192 - lr: 0.0030\n",
            "Epoch 450/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5125 - accuracy: 0.8169 - val_loss: 0.8464 - val_accuracy: 0.7246 - lr: 0.0030\n",
            "Epoch 451/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5192 - accuracy: 0.8151 - val_loss: 0.8421 - val_accuracy: 0.7251 - lr: 0.0030\n",
            "Epoch 452/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5112 - accuracy: 0.8166 - val_loss: 0.8479 - val_accuracy: 0.7222 - lr: 0.0030\n",
            "Epoch 453/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5103 - accuracy: 0.8169 - val_loss: 0.8466 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 454/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5151 - accuracy: 0.8154 - val_loss: 0.8438 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 455/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5157 - accuracy: 0.8137 - val_loss: 0.8459 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 456/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5154 - accuracy: 0.8142 - val_loss: 0.8456 - val_accuracy: 0.7211 - lr: 0.0030\n",
            "Epoch 457/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5123 - accuracy: 0.8158 - val_loss: 0.8397 - val_accuracy: 0.7273 - lr: 0.0030\n",
            "Epoch 458/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5124 - accuracy: 0.8157 - val_loss: 0.8449 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 459/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5113 - accuracy: 0.8176 - val_loss: 0.8431 - val_accuracy: 0.7246 - lr: 0.0030\n",
            "Epoch 460/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5133 - accuracy: 0.8167 - val_loss: 0.8455 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 461/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5083 - accuracy: 0.8168 - val_loss: 0.8479 - val_accuracy: 0.7208 - lr: 0.0030\n",
            "Epoch 462/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5161 - accuracy: 0.8157 - val_loss: 0.8479 - val_accuracy: 0.7238 - lr: 0.0030\n",
            "Epoch 463/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5153 - accuracy: 0.8156 - val_loss: 0.8485 - val_accuracy: 0.7220 - lr: 0.0030\n",
            "Epoch 464/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5171 - accuracy: 0.8152 - val_loss: 0.8476 - val_accuracy: 0.7237 - lr: 0.0030\n",
            "Epoch 465/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5134 - accuracy: 0.8166 - val_loss: 0.8500 - val_accuracy: 0.7208 - lr: 0.0030\n",
            "Epoch 466/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5132 - accuracy: 0.8161 - val_loss: 0.8480 - val_accuracy: 0.7213 - lr: 0.0030\n",
            "Epoch 467/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5166 - accuracy: 0.8145 - val_loss: 0.8448 - val_accuracy: 0.7255 - lr: 0.0030\n",
            "Epoch 468/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5072 - accuracy: 0.8181 - val_loss: 0.8481 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 469/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5026 - accuracy: 0.8216 - val_loss: 0.8461 - val_accuracy: 0.7219 - lr: 0.0030\n",
            "Epoch 470/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5095 - accuracy: 0.8159 - val_loss: 0.8564 - val_accuracy: 0.7180 - lr: 0.0030\n",
            "Epoch 471/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5089 - accuracy: 0.8163 - val_loss: 0.8504 - val_accuracy: 0.7199 - lr: 0.0030\n",
            "Epoch 472/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5118 - accuracy: 0.8156 - val_loss: 0.8486 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 473/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5148 - accuracy: 0.8158 - val_loss: 0.8478 - val_accuracy: 0.7238 - lr: 0.0030\n",
            "Epoch 474/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5130 - accuracy: 0.8171 - val_loss: 0.8482 - val_accuracy: 0.7217 - lr: 0.0030\n",
            "Epoch 475/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5108 - accuracy: 0.8153 - val_loss: 0.8553 - val_accuracy: 0.7213 - lr: 0.0030\n",
            "Epoch 476/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5060 - accuracy: 0.8179 - val_loss: 0.8454 - val_accuracy: 0.7208 - lr: 0.0030\n",
            "Epoch 477/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5074 - accuracy: 0.8193 - val_loss: 0.8437 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 478/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5063 - accuracy: 0.8187 - val_loss: 0.8471 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 479/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5084 - accuracy: 0.8170 - val_loss: 0.8519 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 480/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5137 - accuracy: 0.8148 - val_loss: 0.8513 - val_accuracy: 0.7212 - lr: 0.0030\n",
            "Epoch 481/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5035 - accuracy: 0.8172 - val_loss: 0.8557 - val_accuracy: 0.7195 - lr: 0.0030\n",
            "Epoch 482/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5066 - accuracy: 0.8180 - val_loss: 0.8499 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 483/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5067 - accuracy: 0.8187 - val_loss: 0.8585 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 484/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5078 - accuracy: 0.8187 - val_loss: 0.8492 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 485/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5076 - accuracy: 0.8191 - val_loss: 0.8449 - val_accuracy: 0.7241 - lr: 0.0030\n",
            "Epoch 486/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5094 - accuracy: 0.8170 - val_loss: 0.8460 - val_accuracy: 0.7252 - lr: 0.0030\n",
            "Epoch 487/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5113 - accuracy: 0.8175 - val_loss: 0.8507 - val_accuracy: 0.7253 - lr: 0.0030\n",
            "Epoch 488/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5025 - accuracy: 0.8204 - val_loss: 0.8502 - val_accuracy: 0.7251 - lr: 0.0030\n",
            "Epoch 489/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5095 - accuracy: 0.8177 - val_loss: 0.8493 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 490/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5062 - accuracy: 0.8190 - val_loss: 0.8497 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 491/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5108 - accuracy: 0.8176 - val_loss: 0.8508 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 492/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5093 - accuracy: 0.8167 - val_loss: 0.8571 - val_accuracy: 0.7211 - lr: 0.0030\n",
            "Epoch 493/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5041 - accuracy: 0.8190 - val_loss: 0.8495 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 494/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5080 - accuracy: 0.8177 - val_loss: 0.8542 - val_accuracy: 0.7203 - lr: 0.0030\n",
            "Epoch 495/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5090 - accuracy: 0.8183 - val_loss: 0.8574 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 496/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5100 - accuracy: 0.8180 - val_loss: 0.8538 - val_accuracy: 0.7204 - lr: 0.0030\n",
            "Epoch 497/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5066 - accuracy: 0.8171 - val_loss: 0.8504 - val_accuracy: 0.7204 - lr: 0.0030\n",
            "Epoch 498/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5077 - accuracy: 0.8185 - val_loss: 0.8511 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 499/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5053 - accuracy: 0.8199 - val_loss: 0.8553 - val_accuracy: 0.7197 - lr: 0.0030\n",
            "Epoch 500/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5061 - accuracy: 0.8196 - val_loss: 0.8581 - val_accuracy: 0.7186 - lr: 0.0030\n",
            "Epoch 501/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5036 - accuracy: 0.8194 - val_loss: 0.8507 - val_accuracy: 0.7209 - lr: 0.0030\n",
            "Epoch 502/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5103 - accuracy: 0.8158 - val_loss: 0.8622 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 503/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5050 - accuracy: 0.8181 - val_loss: 0.8509 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 504/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5059 - accuracy: 0.8193 - val_loss: 0.8558 - val_accuracy: 0.7205 - lr: 0.0030\n",
            "Epoch 505/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5020 - accuracy: 0.8216 - val_loss: 0.8567 - val_accuracy: 0.7213 - lr: 0.0030\n",
            "Epoch 506/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5035 - accuracy: 0.8191 - val_loss: 0.8516 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 507/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5072 - accuracy: 0.8185 - val_loss: 0.8572 - val_accuracy: 0.7206 - lr: 0.0030\n",
            "Epoch 508/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5077 - accuracy: 0.8173 - val_loss: 0.8571 - val_accuracy: 0.7206 - lr: 0.0030\n",
            "Epoch 509/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5079 - accuracy: 0.8161 - val_loss: 0.8517 - val_accuracy: 0.7220 - lr: 0.0030\n",
            "Epoch 510/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5061 - accuracy: 0.8181 - val_loss: 0.8525 - val_accuracy: 0.7217 - lr: 0.0030\n",
            "Epoch 511/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5063 - accuracy: 0.8183 - val_loss: 0.8590 - val_accuracy: 0.7199 - lr: 0.0030\n",
            "Epoch 512/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5031 - accuracy: 0.8195 - val_loss: 0.8523 - val_accuracy: 0.7235 - lr: 0.0030\n",
            "Epoch 513/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5051 - accuracy: 0.8190 - val_loss: 0.8495 - val_accuracy: 0.7226 - lr: 0.0030\n",
            "Epoch 514/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5053 - accuracy: 0.8207 - val_loss: 0.8513 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 515/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5062 - accuracy: 0.8193 - val_loss: 0.8524 - val_accuracy: 0.7234 - lr: 0.0030\n",
            "Epoch 516/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5013 - accuracy: 0.8188 - val_loss: 0.8630 - val_accuracy: 0.7175 - lr: 0.0030\n",
            "Epoch 517/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5009 - accuracy: 0.8214 - val_loss: 0.8487 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 518/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4998 - accuracy: 0.8203 - val_loss: 0.8542 - val_accuracy: 0.7201 - lr: 0.0030\n",
            "Epoch 519/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5052 - accuracy: 0.8189 - val_loss: 0.8518 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 520/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5055 - accuracy: 0.8195 - val_loss: 0.8484 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 521/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5009 - accuracy: 0.8202 - val_loss: 0.8642 - val_accuracy: 0.7183 - lr: 0.0030\n",
            "Epoch 522/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5049 - accuracy: 0.8200 - val_loss: 0.8527 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 523/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5007 - accuracy: 0.8204 - val_loss: 0.8572 - val_accuracy: 0.7200 - lr: 0.0030\n",
            "Epoch 524/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5074 - accuracy: 0.8179 - val_loss: 0.8604 - val_accuracy: 0.7219 - lr: 0.0030\n",
            "Epoch 525/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5053 - accuracy: 0.8188 - val_loss: 0.8546 - val_accuracy: 0.7241 - lr: 0.0030\n",
            "Epoch 526/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5053 - accuracy: 0.8193 - val_loss: 0.8575 - val_accuracy: 0.7212 - lr: 0.0030\n",
            "Epoch 527/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4999 - accuracy: 0.8197 - val_loss: 0.8525 - val_accuracy: 0.7247 - lr: 0.0030\n",
            "Epoch 528/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5017 - accuracy: 0.8195 - val_loss: 0.8569 - val_accuracy: 0.7214 - lr: 0.0030\n",
            "Epoch 529/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5055 - accuracy: 0.8180 - val_loss: 0.8537 - val_accuracy: 0.7209 - lr: 0.0030\n",
            "Epoch 530/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5023 - accuracy: 0.8210 - val_loss: 0.8543 - val_accuracy: 0.7239 - lr: 0.0030\n",
            "Epoch 531/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4991 - accuracy: 0.8231 - val_loss: 0.8548 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 532/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5041 - accuracy: 0.8197 - val_loss: 0.8567 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 533/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5026 - accuracy: 0.8175 - val_loss: 0.8474 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 534/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5067 - accuracy: 0.8198 - val_loss: 0.8574 - val_accuracy: 0.7220 - lr: 0.0030\n",
            "Epoch 535/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5019 - accuracy: 0.8208 - val_loss: 0.8563 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 536/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5001 - accuracy: 0.8215 - val_loss: 0.8629 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 537/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4992 - accuracy: 0.8212 - val_loss: 0.8558 - val_accuracy: 0.7239 - lr: 0.0030\n",
            "Epoch 538/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5011 - accuracy: 0.8211 - val_loss: 0.8595 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 539/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5000 - accuracy: 0.8202 - val_loss: 0.8536 - val_accuracy: 0.7252 - lr: 0.0030\n",
            "Epoch 540/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5044 - accuracy: 0.8212 - val_loss: 0.8528 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 541/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5005 - accuracy: 0.8192 - val_loss: 0.8540 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 542/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4997 - accuracy: 0.8210 - val_loss: 0.8607 - val_accuracy: 0.7213 - lr: 0.0030\n",
            "Epoch 543/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4992 - accuracy: 0.8201 - val_loss: 0.8572 - val_accuracy: 0.7207 - lr: 0.0030\n",
            "Epoch 544/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5000 - accuracy: 0.8197 - val_loss: 0.8572 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 545/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4985 - accuracy: 0.8206 - val_loss: 0.8523 - val_accuracy: 0.7231 - lr: 0.0030\n",
            "Epoch 546/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4974 - accuracy: 0.8209 - val_loss: 0.8531 - val_accuracy: 0.7239 - lr: 0.0030\n",
            "Epoch 547/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5009 - accuracy: 0.8198 - val_loss: 0.8628 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 548/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5007 - accuracy: 0.8186 - val_loss: 0.8514 - val_accuracy: 0.7211 - lr: 0.0030\n",
            "Epoch 549/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4969 - accuracy: 0.8216 - val_loss: 0.8598 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 550/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4982 - accuracy: 0.8229 - val_loss: 0.8604 - val_accuracy: 0.7210 - lr: 0.0030\n",
            "Epoch 551/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4960 - accuracy: 0.8232 - val_loss: 0.8586 - val_accuracy: 0.7227 - lr: 0.0030\n",
            "Epoch 552/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4975 - accuracy: 0.8221 - val_loss: 0.8567 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 553/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4994 - accuracy: 0.8198 - val_loss: 0.8603 - val_accuracy: 0.7202 - lr: 0.0030\n",
            "Epoch 554/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4975 - accuracy: 0.8209 - val_loss: 0.8585 - val_accuracy: 0.7231 - lr: 0.0030\n",
            "Epoch 555/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4975 - accuracy: 0.8216 - val_loss: 0.8520 - val_accuracy: 0.7214 - lr: 0.0030\n",
            "Epoch 556/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5005 - accuracy: 0.8201 - val_loss: 0.8597 - val_accuracy: 0.7203 - lr: 0.0030\n",
            "Epoch 557/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.5026 - accuracy: 0.8181 - val_loss: 0.8584 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 558/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4963 - accuracy: 0.8220 - val_loss: 0.8554 - val_accuracy: 0.7226 - lr: 0.0030\n",
            "Epoch 559/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5032 - accuracy: 0.8196 - val_loss: 0.8643 - val_accuracy: 0.7197 - lr: 0.0030\n",
            "Epoch 560/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4983 - accuracy: 0.8212 - val_loss: 0.8548 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 561/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5016 - accuracy: 0.8197 - val_loss: 0.8546 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 562/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4979 - accuracy: 0.8210 - val_loss: 0.8526 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 563/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4980 - accuracy: 0.8222 - val_loss: 0.8517 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 564/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4994 - accuracy: 0.8201 - val_loss: 0.8571 - val_accuracy: 0.7211 - lr: 0.0030\n",
            "Epoch 565/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4959 - accuracy: 0.8224 - val_loss: 0.8529 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 566/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4957 - accuracy: 0.8213 - val_loss: 0.8618 - val_accuracy: 0.7205 - lr: 0.0030\n",
            "Epoch 567/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4965 - accuracy: 0.8215 - val_loss: 0.8572 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 568/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4955 - accuracy: 0.8214 - val_loss: 0.8542 - val_accuracy: 0.7227 - lr: 0.0030\n",
            "Epoch 569/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4966 - accuracy: 0.8228 - val_loss: 0.8514 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 570/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5001 - accuracy: 0.8201 - val_loss: 0.8596 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 571/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4984 - accuracy: 0.8214 - val_loss: 0.8628 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 572/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4999 - accuracy: 0.8215 - val_loss: 0.8555 - val_accuracy: 0.7198 - lr: 0.0030\n",
            "Epoch 573/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5013 - accuracy: 0.8197 - val_loss: 0.8572 - val_accuracy: 0.7219 - lr: 0.0030\n",
            "Epoch 574/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4972 - accuracy: 0.8220 - val_loss: 0.8546 - val_accuracy: 0.7231 - lr: 0.0030\n",
            "Epoch 575/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4955 - accuracy: 0.8224 - val_loss: 0.8605 - val_accuracy: 0.7198 - lr: 0.0030\n",
            "Epoch 576/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4951 - accuracy: 0.8213 - val_loss: 0.8592 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 577/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4984 - accuracy: 0.8209 - val_loss: 0.8607 - val_accuracy: 0.7210 - lr: 0.0030\n",
            "Epoch 578/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4948 - accuracy: 0.8219 - val_loss: 0.8583 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 579/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4937 - accuracy: 0.8228 - val_loss: 0.8590 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 580/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4945 - accuracy: 0.8233 - val_loss: 0.8636 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 581/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4908 - accuracy: 0.8254 - val_loss: 0.8600 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 582/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5004 - accuracy: 0.8222 - val_loss: 0.8632 - val_accuracy: 0.7197 - lr: 0.0030\n",
            "Epoch 583/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4941 - accuracy: 0.8226 - val_loss: 0.8618 - val_accuracy: 0.7220 - lr: 0.0030\n",
            "Epoch 584/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4916 - accuracy: 0.8228 - val_loss: 0.8563 - val_accuracy: 0.7242 - lr: 0.0030\n",
            "Epoch 585/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4951 - accuracy: 0.8222 - val_loss: 0.8623 - val_accuracy: 0.7227 - lr: 0.0030\n",
            "Epoch 586/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4945 - accuracy: 0.8233 - val_loss: 0.8609 - val_accuracy: 0.7222 - lr: 0.0030\n",
            "Epoch 587/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4965 - accuracy: 0.8210 - val_loss: 0.8589 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 588/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4960 - accuracy: 0.8234 - val_loss: 0.8590 - val_accuracy: 0.7214 - lr: 0.0030\n",
            "Epoch 589/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4950 - accuracy: 0.8208 - val_loss: 0.8575 - val_accuracy: 0.7257 - lr: 0.0030\n",
            "Epoch 590/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4906 - accuracy: 0.8237 - val_loss: 0.8598 - val_accuracy: 0.7234 - lr: 0.0030\n",
            "Epoch 591/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4918 - accuracy: 0.8237 - val_loss: 0.8592 - val_accuracy: 0.7242 - lr: 0.0030\n",
            "Epoch 592/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4885 - accuracy: 0.8242 - val_loss: 0.8598 - val_accuracy: 0.7222 - lr: 0.0030\n",
            "Epoch 593/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4959 - accuracy: 0.8228 - val_loss: 0.8577 - val_accuracy: 0.7252 - lr: 0.0030\n",
            "Epoch 594/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4947 - accuracy: 0.8249 - val_loss: 0.8652 - val_accuracy: 0.7204 - lr: 0.0030\n",
            "Epoch 595/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4900 - accuracy: 0.8246 - val_loss: 0.8584 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 596/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4966 - accuracy: 0.8212 - val_loss: 0.8571 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 597/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4931 - accuracy: 0.8240 - val_loss: 0.8714 - val_accuracy: 0.7186 - lr: 0.0030\n",
            "Epoch 598/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4877 - accuracy: 0.8237 - val_loss: 0.8584 - val_accuracy: 0.7210 - lr: 0.0030\n",
            "Epoch 599/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4938 - accuracy: 0.8226 - val_loss: 0.8656 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 600/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4921 - accuracy: 0.8236 - val_loss: 0.8637 - val_accuracy: 0.7210 - lr: 0.0030\n",
            "Epoch 601/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4958 - accuracy: 0.8211 - val_loss: 0.8573 - val_accuracy: 0.7217 - lr: 0.0030\n",
            "Epoch 602/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4947 - accuracy: 0.8223 - val_loss: 0.8612 - val_accuracy: 0.7210 - lr: 0.0030\n",
            "Epoch 603/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4930 - accuracy: 0.8230 - val_loss: 0.8536 - val_accuracy: 0.7234 - lr: 0.0030\n",
            "Epoch 604/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4930 - accuracy: 0.8226 - val_loss: 0.8556 - val_accuracy: 0.7206 - lr: 0.0030\n",
            "Epoch 605/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4972 - accuracy: 0.8211 - val_loss: 0.8579 - val_accuracy: 0.7199 - lr: 0.0030\n",
            "Epoch 606/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4931 - accuracy: 0.8222 - val_loss: 0.8595 - val_accuracy: 0.7226 - lr: 0.0030\n",
            "Epoch 607/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4917 - accuracy: 0.8242 - val_loss: 0.8600 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 608/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4895 - accuracy: 0.8256 - val_loss: 0.8592 - val_accuracy: 0.7215 - lr: 0.0030\n",
            "Epoch 609/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4941 - accuracy: 0.8242 - val_loss: 0.8624 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 610/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4921 - accuracy: 0.8231 - val_loss: 0.8610 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 611/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4936 - accuracy: 0.8207 - val_loss: 0.8588 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 612/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4880 - accuracy: 0.8248 - val_loss: 0.8644 - val_accuracy: 0.7234 - lr: 0.0030\n",
            "Epoch 613/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4866 - accuracy: 0.8259 - val_loss: 0.8611 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 614/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4918 - accuracy: 0.8242 - val_loss: 0.8617 - val_accuracy: 0.7208 - lr: 0.0030\n",
            "Epoch 615/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4884 - accuracy: 0.8241 - val_loss: 0.8565 - val_accuracy: 0.7219 - lr: 0.0030\n",
            "Epoch 616/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4978 - accuracy: 0.8217 - val_loss: 0.8536 - val_accuracy: 0.7248 - lr: 0.0030\n",
            "Epoch 617/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4856 - accuracy: 0.8273 - val_loss: 0.8614 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 618/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4930 - accuracy: 0.8215 - val_loss: 0.8623 - val_accuracy: 0.7202 - lr: 0.0030\n",
            "Epoch 619/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4854 - accuracy: 0.8262 - val_loss: 0.8598 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 620/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4855 - accuracy: 0.8244 - val_loss: 0.8636 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 621/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4878 - accuracy: 0.8247 - val_loss: 0.8639 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 622/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4930 - accuracy: 0.8227 - val_loss: 0.8592 - val_accuracy: 0.7219 - lr: 0.0030\n",
            "Epoch 623/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4870 - accuracy: 0.8248 - val_loss: 0.8598 - val_accuracy: 0.7248 - lr: 0.0030\n",
            "Epoch 624/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4848 - accuracy: 0.8257 - val_loss: 0.8620 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 625/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4871 - accuracy: 0.8240 - val_loss: 0.8601 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 626/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4865 - accuracy: 0.8252 - val_loss: 0.8670 - val_accuracy: 0.7204 - lr: 0.0030\n",
            "Epoch 627/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4972 - accuracy: 0.8213 - val_loss: 0.8611 - val_accuracy: 0.7217 - lr: 0.0030\n",
            "Epoch 628/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4866 - accuracy: 0.8242 - val_loss: 0.8584 - val_accuracy: 0.7205 - lr: 0.0030\n",
            "Epoch 629/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4886 - accuracy: 0.8236 - val_loss: 0.8576 - val_accuracy: 0.7234 - lr: 0.0030\n",
            "Epoch 630/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4899 - accuracy: 0.8248 - val_loss: 0.8631 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 631/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4889 - accuracy: 0.8240 - val_loss: 0.8638 - val_accuracy: 0.7242 - lr: 0.0030\n",
            "Epoch 632/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4903 - accuracy: 0.8231 - val_loss: 0.8566 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 633/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4903 - accuracy: 0.8244 - val_loss: 0.8637 - val_accuracy: 0.7227 - lr: 0.0030\n",
            "Epoch 634/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4873 - accuracy: 0.8259 - val_loss: 0.8627 - val_accuracy: 0.7223 - lr: 0.0030\n",
            "Epoch 635/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4906 - accuracy: 0.8236 - val_loss: 0.8573 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 636/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4851 - accuracy: 0.8269 - val_loss: 0.8604 - val_accuracy: 0.7226 - lr: 0.0030\n",
            "Epoch 637/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4879 - accuracy: 0.8247 - val_loss: 0.8615 - val_accuracy: 0.7236 - lr: 0.0030\n",
            "Epoch 638/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4849 - accuracy: 0.8251 - val_loss: 0.8611 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 639/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4875 - accuracy: 0.8255 - val_loss: 0.8687 - val_accuracy: 0.7214 - lr: 0.0030\n",
            "Epoch 640/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4870 - accuracy: 0.8251 - val_loss: 0.8626 - val_accuracy: 0.7235 - lr: 0.0030\n",
            "Epoch 641/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4837 - accuracy: 0.8254 - val_loss: 0.8636 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 642/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4884 - accuracy: 0.8246 - val_loss: 0.8665 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 643/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4862 - accuracy: 0.8250 - val_loss: 0.8649 - val_accuracy: 0.7236 - lr: 0.0030\n",
            "Epoch 644/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4900 - accuracy: 0.8236 - val_loss: 0.8621 - val_accuracy: 0.7222 - lr: 0.0030\n",
            "Epoch 645/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4861 - accuracy: 0.8271 - val_loss: 0.8650 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 646/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4867 - accuracy: 0.8253 - val_loss: 0.8639 - val_accuracy: 0.7226 - lr: 0.0030\n",
            "Epoch 647/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4901 - accuracy: 0.8257 - val_loss: 0.8663 - val_accuracy: 0.7218 - lr: 0.0030\n",
            "Epoch 648/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4802 - accuracy: 0.8279 - val_loss: 0.8615 - val_accuracy: 0.7237 - lr: 0.0030\n",
            "Epoch 649/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4825 - accuracy: 0.8286 - val_loss: 0.8692 - val_accuracy: 0.7241 - lr: 0.0030\n",
            "Epoch 650/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4859 - accuracy: 0.8247 - val_loss: 0.8646 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 651/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4880 - accuracy: 0.8240 - val_loss: 0.8648 - val_accuracy: 0.7226 - lr: 0.0030\n",
            "Epoch 652/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4833 - accuracy: 0.8281 - val_loss: 0.8708 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 653/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4842 - accuracy: 0.8253 - val_loss: 0.8676 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 654/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4843 - accuracy: 0.8266 - val_loss: 0.8686 - val_accuracy: 0.7277 - lr: 0.0030\n",
            "Epoch 655/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4832 - accuracy: 0.8258 - val_loss: 0.8664 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 656/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4888 - accuracy: 0.8241 - val_loss: 0.8681 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 657/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4845 - accuracy: 0.8256 - val_loss: 0.8611 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 658/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4814 - accuracy: 0.8280 - val_loss: 0.8666 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 659/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4873 - accuracy: 0.8243 - val_loss: 0.8631 - val_accuracy: 0.7234 - lr: 0.0030\n",
            "Epoch 660/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4888 - accuracy: 0.8239 - val_loss: 0.8649 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 661/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4818 - accuracy: 0.8272 - val_loss: 0.8642 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 662/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4860 - accuracy: 0.8232 - val_loss: 0.8638 - val_accuracy: 0.7249 - lr: 0.0030\n",
            "Epoch 663/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4844 - accuracy: 0.8241 - val_loss: 0.8602 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 664/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4855 - accuracy: 0.8265 - val_loss: 0.8642 - val_accuracy: 0.7261 - lr: 0.0030\n",
            "Epoch 665/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4832 - accuracy: 0.8268 - val_loss: 0.8636 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 666/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4836 - accuracy: 0.8252 - val_loss: 0.8650 - val_accuracy: 0.7228 - lr: 0.0030\n",
            "Epoch 667/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4823 - accuracy: 0.8277 - val_loss: 0.8628 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 668/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4812 - accuracy: 0.8270 - val_loss: 0.8635 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 669/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4795 - accuracy: 0.8264 - val_loss: 0.8701 - val_accuracy: 0.7205 - lr: 0.0030\n",
            "Epoch 670/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4908 - accuracy: 0.8229 - val_loss: 0.8660 - val_accuracy: 0.7237 - lr: 0.0030\n",
            "Epoch 671/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4829 - accuracy: 0.8280 - val_loss: 0.8685 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 672/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4860 - accuracy: 0.8262 - val_loss: 0.8692 - val_accuracy: 0.7235 - lr: 0.0030\n",
            "Epoch 673/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4780 - accuracy: 0.8289 - val_loss: 0.8687 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 674/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4857 - accuracy: 0.8245 - val_loss: 0.8675 - val_accuracy: 0.7216 - lr: 0.0030\n",
            "Epoch 675/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4843 - accuracy: 0.8258 - val_loss: 0.8621 - val_accuracy: 0.7246 - lr: 0.0030\n",
            "Epoch 676/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4824 - accuracy: 0.8271 - val_loss: 0.8661 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 677/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4826 - accuracy: 0.8277 - val_loss: 0.8683 - val_accuracy: 0.7229 - lr: 0.0030\n",
            "Epoch 678/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4808 - accuracy: 0.8279 - val_loss: 0.8601 - val_accuracy: 0.7252 - lr: 0.0030\n",
            "Epoch 679/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4856 - accuracy: 0.8241 - val_loss: 0.8602 - val_accuracy: 0.7242 - lr: 0.0030\n",
            "Epoch 680/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4853 - accuracy: 0.8265 - val_loss: 0.8700 - val_accuracy: 0.7195 - lr: 0.0030\n",
            "Epoch 681/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4769 - accuracy: 0.8282 - val_loss: 0.8655 - val_accuracy: 0.7225 - lr: 0.0030\n",
            "Epoch 682/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4864 - accuracy: 0.8253 - val_loss: 0.8737 - val_accuracy: 0.7224 - lr: 0.0030\n",
            "Epoch 683/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4866 - accuracy: 0.8263 - val_loss: 0.8643 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 684/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4837 - accuracy: 0.8263 - val_loss: 0.8668 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 685/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4808 - accuracy: 0.8273 - val_loss: 0.8715 - val_accuracy: 0.7204 - lr: 0.0030\n",
            "Epoch 686/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4786 - accuracy: 0.8281 - val_loss: 0.8694 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 687/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4826 - accuracy: 0.8261 - val_loss: 0.8656 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 688/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4812 - accuracy: 0.8271 - val_loss: 0.8662 - val_accuracy: 0.7242 - lr: 0.0030\n",
            "Epoch 689/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4891 - accuracy: 0.8230 - val_loss: 0.8668 - val_accuracy: 0.7240 - lr: 0.0030\n",
            "Epoch 690/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4799 - accuracy: 0.8289 - val_loss: 0.8619 - val_accuracy: 0.7236 - lr: 0.0030\n",
            "Epoch 691/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4792 - accuracy: 0.8281 - val_loss: 0.8662 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 692/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4800 - accuracy: 0.8273 - val_loss: 0.8625 - val_accuracy: 0.7232 - lr: 0.0030\n",
            "Epoch 693/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4813 - accuracy: 0.8246 - val_loss: 0.8675 - val_accuracy: 0.7260 - lr: 0.0030\n",
            "Epoch 694/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4794 - accuracy: 0.8288 - val_loss: 0.8712 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 695/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4826 - accuracy: 0.8265 - val_loss: 0.8727 - val_accuracy: 0.7221 - lr: 0.0030\n",
            "Epoch 696/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4811 - accuracy: 0.8274 - val_loss: 0.8679 - val_accuracy: 0.7241 - lr: 0.0030\n",
            "Epoch 697/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4758 - accuracy: 0.8283 - val_loss: 0.8694 - val_accuracy: 0.7233 - lr: 0.0030\n",
            "Epoch 698/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4805 - accuracy: 0.8275 - val_loss: 0.8721 - val_accuracy: 0.7238 - lr: 0.0030\n",
            "Epoch 699/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4799 - accuracy: 0.8293 - val_loss: 0.8709 - val_accuracy: 0.7230 - lr: 0.0030\n",
            "Epoch 700/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4799 - accuracy: 0.8273 - val_loss: 0.8682 - val_accuracy: 0.7245 - lr: 0.0030\n",
            "Epoch 701/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4710 - accuracy: 0.8322 - val_loss: 0.8697 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 702/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4762 - accuracy: 0.8272 - val_loss: 0.8655 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 703/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4717 - accuracy: 0.8304 - val_loss: 0.8652 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 704/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4752 - accuracy: 0.8288 - val_loss: 0.8644 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 705/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4787 - accuracy: 0.8285 - val_loss: 0.8641 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 706/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4744 - accuracy: 0.8291 - val_loss: 0.8662 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 707/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4698 - accuracy: 0.8309 - val_loss: 0.8653 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 708/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4742 - accuracy: 0.8291 - val_loss: 0.8637 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 709/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4754 - accuracy: 0.8289 - val_loss: 0.8641 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 710/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4737 - accuracy: 0.8304 - val_loss: 0.8669 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 711/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4704 - accuracy: 0.8287 - val_loss: 0.8655 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 712/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4761 - accuracy: 0.8285 - val_loss: 0.8671 - val_accuracy: 0.7219 - lr: 0.0010\n",
            "Epoch 713/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4754 - accuracy: 0.8275 - val_loss: 0.8694 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 714/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4690 - accuracy: 0.8319 - val_loss: 0.8643 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 715/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4762 - accuracy: 0.8285 - val_loss: 0.8643 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 716/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4760 - accuracy: 0.8298 - val_loss: 0.8651 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 717/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4736 - accuracy: 0.8315 - val_loss: 0.8675 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 718/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4693 - accuracy: 0.8326 - val_loss: 0.8622 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 719/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4724 - accuracy: 0.8304 - val_loss: 0.8655 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 720/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4737 - accuracy: 0.8292 - val_loss: 0.8661 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 721/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4759 - accuracy: 0.8293 - val_loss: 0.8657 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 722/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4751 - accuracy: 0.8287 - val_loss: 0.8622 - val_accuracy: 0.7264 - lr: 0.0010\n",
            "Epoch 723/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4693 - accuracy: 0.8311 - val_loss: 0.8677 - val_accuracy: 0.7234 - lr: 0.0010\n",
            "Epoch 724/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4718 - accuracy: 0.8296 - val_loss: 0.8679 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 725/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4715 - accuracy: 0.8286 - val_loss: 0.8668 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 726/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4710 - accuracy: 0.8295 - val_loss: 0.8681 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 727/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4742 - accuracy: 0.8300 - val_loss: 0.8676 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 728/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4740 - accuracy: 0.8294 - val_loss: 0.8646 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 729/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4714 - accuracy: 0.8308 - val_loss: 0.8656 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 730/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4713 - accuracy: 0.8308 - val_loss: 0.8631 - val_accuracy: 0.7253 - lr: 0.0010\n",
            "Epoch 731/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4747 - accuracy: 0.8307 - val_loss: 0.8646 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 732/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4735 - accuracy: 0.8312 - val_loss: 0.8663 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 733/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4781 - accuracy: 0.8288 - val_loss: 0.8681 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 734/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4693 - accuracy: 0.8295 - val_loss: 0.8693 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 735/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4707 - accuracy: 0.8319 - val_loss: 0.8671 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 736/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4769 - accuracy: 0.8294 - val_loss: 0.8685 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 737/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4750 - accuracy: 0.8280 - val_loss: 0.8663 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 738/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4682 - accuracy: 0.8298 - val_loss: 0.8697 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 739/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4743 - accuracy: 0.8305 - val_loss: 0.8680 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 740/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4763 - accuracy: 0.8292 - val_loss: 0.8684 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 741/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4737 - accuracy: 0.8292 - val_loss: 0.8655 - val_accuracy: 0.7257 - lr: 0.0010\n",
            "Epoch 742/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4736 - accuracy: 0.8283 - val_loss: 0.8702 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 743/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4728 - accuracy: 0.8314 - val_loss: 0.8643 - val_accuracy: 0.7257 - lr: 0.0010\n",
            "Epoch 744/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4773 - accuracy: 0.8288 - val_loss: 0.8645 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 745/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4763 - accuracy: 0.8298 - val_loss: 0.8678 - val_accuracy: 0.7259 - lr: 0.0010\n",
            "Epoch 746/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4708 - accuracy: 0.8295 - val_loss: 0.8657 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 747/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4713 - accuracy: 0.8309 - val_loss: 0.8645 - val_accuracy: 0.7268 - lr: 0.0010\n",
            "Epoch 748/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4728 - accuracy: 0.8302 - val_loss: 0.8665 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 749/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4719 - accuracy: 0.8297 - val_loss: 0.8661 - val_accuracy: 0.7236 - lr: 0.0010\n",
            "Epoch 750/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4713 - accuracy: 0.8298 - val_loss: 0.8643 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 751/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4750 - accuracy: 0.8274 - val_loss: 0.8679 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 752/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4761 - accuracy: 0.8274 - val_loss: 0.8686 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 753/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4711 - accuracy: 0.8298 - val_loss: 0.8653 - val_accuracy: 0.7259 - lr: 0.0010\n",
            "Epoch 754/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4686 - accuracy: 0.8321 - val_loss: 0.8665 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 755/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4733 - accuracy: 0.8315 - val_loss: 0.8688 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 756/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4736 - accuracy: 0.8310 - val_loss: 0.8651 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 757/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4751 - accuracy: 0.8294 - val_loss: 0.8662 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 758/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4732 - accuracy: 0.8315 - val_loss: 0.8676 - val_accuracy: 0.7264 - lr: 0.0010\n",
            "Epoch 759/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4704 - accuracy: 0.8313 - val_loss: 0.8655 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 760/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4706 - accuracy: 0.8310 - val_loss: 0.8647 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 761/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4732 - accuracy: 0.8302 - val_loss: 0.8663 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 762/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4699 - accuracy: 0.8308 - val_loss: 0.8684 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 763/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4678 - accuracy: 0.8320 - val_loss: 0.8681 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 764/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4706 - accuracy: 0.8303 - val_loss: 0.8674 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 765/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4697 - accuracy: 0.8315 - val_loss: 0.8669 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 766/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4716 - accuracy: 0.8309 - val_loss: 0.8678 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 767/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4723 - accuracy: 0.8290 - val_loss: 0.8675 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 768/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4733 - accuracy: 0.8296 - val_loss: 0.8656 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 769/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4721 - accuracy: 0.8289 - val_loss: 0.8665 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 770/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4739 - accuracy: 0.8309 - val_loss: 0.8652 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 771/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4743 - accuracy: 0.8299 - val_loss: 0.8683 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 772/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4729 - accuracy: 0.8305 - val_loss: 0.8662 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 773/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4694 - accuracy: 0.8306 - val_loss: 0.8649 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 774/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4741 - accuracy: 0.8300 - val_loss: 0.8648 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 775/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4697 - accuracy: 0.8308 - val_loss: 0.8664 - val_accuracy: 0.7267 - lr: 0.0010\n",
            "Epoch 776/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4721 - accuracy: 0.8277 - val_loss: 0.8641 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 777/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4730 - accuracy: 0.8290 - val_loss: 0.8666 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 778/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4685 - accuracy: 0.8319 - val_loss: 0.8698 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 779/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4739 - accuracy: 0.8292 - val_loss: 0.8661 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 780/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4701 - accuracy: 0.8315 - val_loss: 0.8695 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 781/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4638 - accuracy: 0.8337 - val_loss: 0.8653 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 782/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4722 - accuracy: 0.8301 - val_loss: 0.8687 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 783/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4676 - accuracy: 0.8319 - val_loss: 0.8688 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 784/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4682 - accuracy: 0.8308 - val_loss: 0.8633 - val_accuracy: 0.7264 - lr: 0.0010\n",
            "Epoch 785/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4729 - accuracy: 0.8302 - val_loss: 0.8683 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 786/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4671 - accuracy: 0.8327 - val_loss: 0.8693 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 787/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4730 - accuracy: 0.8302 - val_loss: 0.8671 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 788/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4698 - accuracy: 0.8325 - val_loss: 0.8657 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 789/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4674 - accuracy: 0.8315 - val_loss: 0.8676 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 790/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4723 - accuracy: 0.8317 - val_loss: 0.8676 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 791/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4760 - accuracy: 0.8272 - val_loss: 0.8695 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 792/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4692 - accuracy: 0.8316 - val_loss: 0.8682 - val_accuracy: 0.7233 - lr: 0.0010\n",
            "Epoch 793/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4731 - accuracy: 0.8300 - val_loss: 0.8695 - val_accuracy: 0.7233 - lr: 0.0010\n",
            "Epoch 794/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4708 - accuracy: 0.8309 - val_loss: 0.8634 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 795/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4729 - accuracy: 0.8314 - val_loss: 0.8680 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 796/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4727 - accuracy: 0.8287 - val_loss: 0.8698 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 797/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4676 - accuracy: 0.8328 - val_loss: 0.8707 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 798/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4776 - accuracy: 0.8290 - val_loss: 0.8699 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 799/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4733 - accuracy: 0.8301 - val_loss: 0.8666 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 800/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4702 - accuracy: 0.8316 - val_loss: 0.8683 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 801/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4692 - accuracy: 0.8312 - val_loss: 0.8709 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 802/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4724 - accuracy: 0.8305 - val_loss: 0.8664 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 803/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4722 - accuracy: 0.8293 - val_loss: 0.8669 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 804/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4694 - accuracy: 0.8313 - val_loss: 0.8675 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 805/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4680 - accuracy: 0.8334 - val_loss: 0.8662 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 806/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4733 - accuracy: 0.8309 - val_loss: 0.8688 - val_accuracy: 0.7227 - lr: 0.0010\n",
            "Epoch 807/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4711 - accuracy: 0.8300 - val_loss: 0.8675 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 808/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4693 - accuracy: 0.8317 - val_loss: 0.8681 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 809/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4691 - accuracy: 0.8311 - val_loss: 0.8672 - val_accuracy: 0.7257 - lr: 0.0010\n",
            "Epoch 810/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4733 - accuracy: 0.8292 - val_loss: 0.8677 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 811/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4710 - accuracy: 0.8270 - val_loss: 0.8698 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 812/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4714 - accuracy: 0.8304 - val_loss: 0.8717 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 813/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4751 - accuracy: 0.8318 - val_loss: 0.8683 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 814/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4702 - accuracy: 0.8307 - val_loss: 0.8680 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 815/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4685 - accuracy: 0.8315 - val_loss: 0.8693 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 816/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4708 - accuracy: 0.8329 - val_loss: 0.8652 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 817/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4697 - accuracy: 0.8313 - val_loss: 0.8660 - val_accuracy: 0.7253 - lr: 0.0010\n",
            "Epoch 818/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4691 - accuracy: 0.8317 - val_loss: 0.8707 - val_accuracy: 0.7234 - lr: 0.0010\n",
            "Epoch 819/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4718 - accuracy: 0.8315 - val_loss: 0.8643 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 820/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4722 - accuracy: 0.8311 - val_loss: 0.8689 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 821/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4682 - accuracy: 0.8320 - val_loss: 0.8700 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 822/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4672 - accuracy: 0.8314 - val_loss: 0.8703 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 823/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8316 - val_loss: 0.8690 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 824/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4685 - accuracy: 0.8318 - val_loss: 0.8726 - val_accuracy: 0.7263 - lr: 0.0010\n",
            "Epoch 825/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4705 - accuracy: 0.8291 - val_loss: 0.8702 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 826/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4724 - accuracy: 0.8302 - val_loss: 0.8693 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 827/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4697 - accuracy: 0.8325 - val_loss: 0.8669 - val_accuracy: 0.7263 - lr: 0.0010\n",
            "Epoch 828/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4643 - accuracy: 0.8331 - val_loss: 0.8679 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 829/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4677 - accuracy: 0.8312 - val_loss: 0.8689 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 830/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4711 - accuracy: 0.8329 - val_loss: 0.8677 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 831/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4679 - accuracy: 0.8329 - val_loss: 0.8696 - val_accuracy: 0.7226 - lr: 0.0010\n",
            "Epoch 832/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4688 - accuracy: 0.8308 - val_loss: 0.8700 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 833/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4687 - accuracy: 0.8303 - val_loss: 0.8685 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 834/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4722 - accuracy: 0.8300 - val_loss: 0.8689 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 835/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4650 - accuracy: 0.8336 - val_loss: 0.8680 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 836/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4679 - accuracy: 0.8323 - val_loss: 0.8705 - val_accuracy: 0.7227 - lr: 0.0010\n",
            "Epoch 837/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4687 - accuracy: 0.8328 - val_loss: 0.8690 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 838/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4685 - accuracy: 0.8311 - val_loss: 0.8696 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 839/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4700 - accuracy: 0.8315 - val_loss: 0.8690 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 840/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4667 - accuracy: 0.8320 - val_loss: 0.8660 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 841/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4671 - accuracy: 0.8317 - val_loss: 0.8699 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 842/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4675 - accuracy: 0.8331 - val_loss: 0.8722 - val_accuracy: 0.7236 - lr: 0.0010\n",
            "Epoch 843/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4716 - accuracy: 0.8303 - val_loss: 0.8689 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 844/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4651 - accuracy: 0.8330 - val_loss: 0.8700 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 845/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4707 - accuracy: 0.8302 - val_loss: 0.8705 - val_accuracy: 0.7233 - lr: 0.0010\n",
            "Epoch 846/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4705 - accuracy: 0.8286 - val_loss: 0.8685 - val_accuracy: 0.7226 - lr: 0.0010\n",
            "Epoch 847/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4672 - accuracy: 0.8317 - val_loss: 0.8700 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 848/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4713 - accuracy: 0.8299 - val_loss: 0.8744 - val_accuracy: 0.7227 - lr: 0.0010\n",
            "Epoch 849/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4729 - accuracy: 0.8297 - val_loss: 0.8718 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 850/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4672 - accuracy: 0.8322 - val_loss: 0.8703 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 851/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4685 - accuracy: 0.8312 - val_loss: 0.8710 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 852/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4711 - accuracy: 0.8288 - val_loss: 0.8676 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 853/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4700 - accuracy: 0.8310 - val_loss: 0.8707 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 854/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4683 - accuracy: 0.8330 - val_loss: 0.8735 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 855/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4665 - accuracy: 0.8326 - val_loss: 0.8683 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 856/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4683 - accuracy: 0.8311 - val_loss: 0.8703 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 857/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4661 - accuracy: 0.8324 - val_loss: 0.8698 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 858/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4705 - accuracy: 0.8287 - val_loss: 0.8696 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 859/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4682 - accuracy: 0.8308 - val_loss: 0.8702 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 860/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8334 - val_loss: 0.8678 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 861/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4699 - accuracy: 0.8306 - val_loss: 0.8687 - val_accuracy: 0.7233 - lr: 0.0010\n",
            "Epoch 862/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4679 - accuracy: 0.8325 - val_loss: 0.8710 - val_accuracy: 0.7237 - lr: 0.0010\n",
            "Epoch 863/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4664 - accuracy: 0.8328 - val_loss: 0.8713 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 864/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4607 - accuracy: 0.8337 - val_loss: 0.8733 - val_accuracy: 0.7224 - lr: 0.0010\n",
            "Epoch 865/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4697 - accuracy: 0.8313 - val_loss: 0.8719 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 866/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4704 - accuracy: 0.8322 - val_loss: 0.8729 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 867/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4687 - accuracy: 0.8320 - val_loss: 0.8695 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 868/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4659 - accuracy: 0.8338 - val_loss: 0.8683 - val_accuracy: 0.7268 - lr: 0.0010\n",
            "Epoch 869/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4667 - accuracy: 0.8314 - val_loss: 0.8679 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 870/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4653 - accuracy: 0.8332 - val_loss: 0.8720 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 871/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4695 - accuracy: 0.8312 - val_loss: 0.8677 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 872/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4685 - accuracy: 0.8319 - val_loss: 0.8714 - val_accuracy: 0.7233 - lr: 0.0010\n",
            "Epoch 873/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4661 - accuracy: 0.8321 - val_loss: 0.8699 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 874/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4654 - accuracy: 0.8321 - val_loss: 0.8701 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 875/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4666 - accuracy: 0.8305 - val_loss: 0.8679 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 876/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4711 - accuracy: 0.8300 - val_loss: 0.8727 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 877/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4702 - accuracy: 0.8305 - val_loss: 0.8688 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 878/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4630 - accuracy: 0.8344 - val_loss: 0.8692 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 879/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4655 - accuracy: 0.8317 - val_loss: 0.8701 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 880/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4682 - accuracy: 0.8321 - val_loss: 0.8716 - val_accuracy: 0.7257 - lr: 0.0010\n",
            "Epoch 881/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4666 - accuracy: 0.8331 - val_loss: 0.8694 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 882/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4696 - accuracy: 0.8306 - val_loss: 0.8731 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 883/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4650 - accuracy: 0.8342 - val_loss: 0.8705 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 884/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4697 - accuracy: 0.8294 - val_loss: 0.8717 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 885/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4689 - accuracy: 0.8325 - val_loss: 0.8704 - val_accuracy: 0.7229 - lr: 0.0010\n",
            "Epoch 886/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4646 - accuracy: 0.8328 - val_loss: 0.8707 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 887/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4683 - accuracy: 0.8298 - val_loss: 0.8724 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 888/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4691 - accuracy: 0.8301 - val_loss: 0.8729 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 889/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4642 - accuracy: 0.8333 - val_loss: 0.8703 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 890/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4679 - accuracy: 0.8311 - val_loss: 0.8719 - val_accuracy: 0.7253 - lr: 0.0010\n",
            "Epoch 891/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4671 - accuracy: 0.8318 - val_loss: 0.8712 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 892/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8324 - val_loss: 0.8735 - val_accuracy: 0.7243 - lr: 0.0010\n",
            "Epoch 893/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4726 - accuracy: 0.8307 - val_loss: 0.8715 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 894/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4731 - accuracy: 0.8298 - val_loss: 0.8698 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 895/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4663 - accuracy: 0.8328 - val_loss: 0.8687 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 896/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4670 - accuracy: 0.8321 - val_loss: 0.8708 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 897/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4686 - accuracy: 0.8327 - val_loss: 0.8719 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 898/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4650 - accuracy: 0.8324 - val_loss: 0.8691 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 899/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4640 - accuracy: 0.8326 - val_loss: 0.8704 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 900/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4663 - accuracy: 0.8320 - val_loss: 0.8741 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 901/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4663 - accuracy: 0.8311 - val_loss: 0.8719 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 902/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4705 - accuracy: 0.8314 - val_loss: 0.8710 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 903/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4685 - accuracy: 0.8314 - val_loss: 0.8725 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 904/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4629 - accuracy: 0.8338 - val_loss: 0.8699 - val_accuracy: 0.7247 - lr: 0.0010\n",
            "Epoch 905/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4690 - accuracy: 0.8315 - val_loss: 0.8720 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 906/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4686 - accuracy: 0.8312 - val_loss: 0.8717 - val_accuracy: 0.7265 - lr: 0.0010\n",
            "Epoch 907/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4641 - accuracy: 0.8326 - val_loss: 0.8713 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 908/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4680 - accuracy: 0.8317 - val_loss: 0.8692 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 909/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4616 - accuracy: 0.8348 - val_loss: 0.8685 - val_accuracy: 0.7259 - lr: 0.0010\n",
            "Epoch 910/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4674 - accuracy: 0.8336 - val_loss: 0.8693 - val_accuracy: 0.7266 - lr: 0.0010\n",
            "Epoch 911/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4651 - accuracy: 0.8315 - val_loss: 0.8712 - val_accuracy: 0.7262 - lr: 0.0010\n",
            "Epoch 912/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4638 - accuracy: 0.8318 - val_loss: 0.8736 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 913/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4646 - accuracy: 0.8344 - val_loss: 0.8734 - val_accuracy: 0.7229 - lr: 0.0010\n",
            "Epoch 914/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4661 - accuracy: 0.8326 - val_loss: 0.8729 - val_accuracy: 0.7266 - lr: 0.0010\n",
            "Epoch 915/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4691 - accuracy: 0.8324 - val_loss: 0.8697 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 916/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8316 - val_loss: 0.8713 - val_accuracy: 0.7230 - lr: 0.0010\n",
            "Epoch 917/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4640 - accuracy: 0.8327 - val_loss: 0.8693 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 918/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4661 - accuracy: 0.8301 - val_loss: 0.8687 - val_accuracy: 0.7253 - lr: 0.0010\n",
            "Epoch 919/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4654 - accuracy: 0.8308 - val_loss: 0.8724 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 920/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4693 - accuracy: 0.8318 - val_loss: 0.8697 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 921/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4699 - accuracy: 0.8314 - val_loss: 0.8689 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 922/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4631 - accuracy: 0.8340 - val_loss: 0.8720 - val_accuracy: 0.7233 - lr: 0.0010\n",
            "Epoch 923/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4644 - accuracy: 0.8330 - val_loss: 0.8716 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 924/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4679 - accuracy: 0.8317 - val_loss: 0.8715 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 925/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4665 - accuracy: 0.8309 - val_loss: 0.8698 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 926/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4684 - accuracy: 0.8308 - val_loss: 0.8726 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 927/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4685 - accuracy: 0.8329 - val_loss: 0.8663 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 928/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4635 - accuracy: 0.8338 - val_loss: 0.8713 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 929/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4642 - accuracy: 0.8314 - val_loss: 0.8742 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 930/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4664 - accuracy: 0.8333 - val_loss: 0.8731 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 931/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4639 - accuracy: 0.8337 - val_loss: 0.8728 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 932/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4687 - accuracy: 0.8310 - val_loss: 0.8717 - val_accuracy: 0.7236 - lr: 0.0010\n",
            "Epoch 933/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4660 - accuracy: 0.8336 - val_loss: 0.8723 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 934/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4676 - accuracy: 0.8304 - val_loss: 0.8692 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 935/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4648 - accuracy: 0.8336 - val_loss: 0.8714 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 936/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4627 - accuracy: 0.8335 - val_loss: 0.8719 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 937/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4643 - accuracy: 0.8317 - val_loss: 0.8734 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 938/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4669 - accuracy: 0.8304 - val_loss: 0.8728 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 939/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4708 - accuracy: 0.8300 - val_loss: 0.8704 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 940/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4673 - accuracy: 0.8332 - val_loss: 0.8723 - val_accuracy: 0.7257 - lr: 0.0010\n",
            "Epoch 941/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4629 - accuracy: 0.8329 - val_loss: 0.8721 - val_accuracy: 0.7231 - lr: 0.0010\n",
            "Epoch 942/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4686 - accuracy: 0.8316 - val_loss: 0.8752 - val_accuracy: 0.7223 - lr: 0.0010\n",
            "Epoch 943/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4660 - accuracy: 0.8323 - val_loss: 0.8720 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 944/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4663 - accuracy: 0.8336 - val_loss: 0.8710 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 945/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4603 - accuracy: 0.8338 - val_loss: 0.8734 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 946/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4586 - accuracy: 0.8337 - val_loss: 0.8719 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 947/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4636 - accuracy: 0.8332 - val_loss: 0.8726 - val_accuracy: 0.7270 - lr: 0.0010\n",
            "Epoch 948/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4638 - accuracy: 0.8305 - val_loss: 0.8734 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 949/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4649 - accuracy: 0.8340 - val_loss: 0.8695 - val_accuracy: 0.7261 - lr: 0.0010\n",
            "Epoch 950/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8327 - val_loss: 0.8728 - val_accuracy: 0.7264 - lr: 0.0010\n",
            "Epoch 951/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4680 - accuracy: 0.8305 - val_loss: 0.8738 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 952/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4637 - accuracy: 0.8334 - val_loss: 0.8707 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 953/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4645 - accuracy: 0.8326 - val_loss: 0.8689 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 954/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4671 - accuracy: 0.8322 - val_loss: 0.8730 - val_accuracy: 0.7234 - lr: 0.0010\n",
            "Epoch 955/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4652 - accuracy: 0.8325 - val_loss: 0.8732 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 956/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4623 - accuracy: 0.8337 - val_loss: 0.8731 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 957/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4633 - accuracy: 0.8319 - val_loss: 0.8713 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 958/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4670 - accuracy: 0.8327 - val_loss: 0.8728 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 959/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4695 - accuracy: 0.8307 - val_loss: 0.8753 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 960/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4644 - accuracy: 0.8335 - val_loss: 0.8702 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 961/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4604 - accuracy: 0.8344 - val_loss: 0.8721 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 962/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4624 - accuracy: 0.8335 - val_loss: 0.8711 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 963/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4651 - accuracy: 0.8339 - val_loss: 0.8727 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 964/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4672 - accuracy: 0.8311 - val_loss: 0.8735 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 965/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4628 - accuracy: 0.8324 - val_loss: 0.8704 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 966/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4668 - accuracy: 0.8321 - val_loss: 0.8710 - val_accuracy: 0.7253 - lr: 0.0010\n",
            "Epoch 967/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4631 - accuracy: 0.8341 - val_loss: 0.8718 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 968/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4655 - accuracy: 0.8321 - val_loss: 0.8758 - val_accuracy: 0.7244 - lr: 0.0010\n",
            "Epoch 969/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8326 - val_loss: 0.8702 - val_accuracy: 0.7258 - lr: 0.0010\n",
            "Epoch 970/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4616 - accuracy: 0.8334 - val_loss: 0.8729 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 971/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4685 - accuracy: 0.8313 - val_loss: 0.8740 - val_accuracy: 0.7265 - lr: 0.0010\n",
            "Epoch 972/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4616 - accuracy: 0.8351 - val_loss: 0.8742 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 973/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4666 - accuracy: 0.8324 - val_loss: 0.8717 - val_accuracy: 0.7245 - lr: 0.0010\n",
            "Epoch 974/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4629 - accuracy: 0.8327 - val_loss: 0.8729 - val_accuracy: 0.7266 - lr: 0.0010\n",
            "Epoch 975/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4608 - accuracy: 0.8335 - val_loss: 0.8739 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 976/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4646 - accuracy: 0.8326 - val_loss: 0.8752 - val_accuracy: 0.7235 - lr: 0.0010\n",
            "Epoch 977/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4640 - accuracy: 0.8330 - val_loss: 0.8757 - val_accuracy: 0.7225 - lr: 0.0010\n",
            "Epoch 978/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4605 - accuracy: 0.8357 - val_loss: 0.8721 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 979/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4622 - accuracy: 0.8353 - val_loss: 0.8756 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 980/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4643 - accuracy: 0.8340 - val_loss: 0.8712 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 981/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4630 - accuracy: 0.8327 - val_loss: 0.8754 - val_accuracy: 0.7251 - lr: 0.0010\n",
            "Epoch 982/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8316 - val_loss: 0.8732 - val_accuracy: 0.7240 - lr: 0.0010\n",
            "Epoch 983/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4604 - accuracy: 0.8354 - val_loss: 0.8766 - val_accuracy: 0.7226 - lr: 0.0010\n",
            "Epoch 984/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4646 - accuracy: 0.8341 - val_loss: 0.8760 - val_accuracy: 0.7228 - lr: 0.0010\n",
            "Epoch 985/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4679 - accuracy: 0.8325 - val_loss: 0.8758 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 986/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4621 - accuracy: 0.8344 - val_loss: 0.8716 - val_accuracy: 0.7236 - lr: 0.0010\n",
            "Epoch 987/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4654 - accuracy: 0.8334 - val_loss: 0.8758 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 988/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4600 - accuracy: 0.8324 - val_loss: 0.8744 - val_accuracy: 0.7254 - lr: 0.0010\n",
            "Epoch 989/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4636 - accuracy: 0.8324 - val_loss: 0.8741 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 990/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4614 - accuracy: 0.8338 - val_loss: 0.8769 - val_accuracy: 0.7253 - lr: 0.0010\n",
            "Epoch 991/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4634 - accuracy: 0.8329 - val_loss: 0.8763 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 992/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4631 - accuracy: 0.8332 - val_loss: 0.8773 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 993/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4591 - accuracy: 0.8354 - val_loss: 0.8749 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 994/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4607 - accuracy: 0.8337 - val_loss: 0.8749 - val_accuracy: 0.7239 - lr: 0.0010\n",
            "Epoch 995/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8311 - val_loss: 0.8761 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 996/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4598 - accuracy: 0.8346 - val_loss: 0.8737 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 997/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4584 - accuracy: 0.8371 - val_loss: 0.8758 - val_accuracy: 0.7242 - lr: 0.0010\n",
            "Epoch 998/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4646 - accuracy: 0.8325 - val_loss: 0.8745 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 999/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4648 - accuracy: 0.8318 - val_loss: 0.8781 - val_accuracy: 0.7249 - lr: 0.0010\n",
            "Epoch 1000/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.4617 - accuracy: 0.8332 - val_loss: 0.8759 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.7248\n",
            "Testset Loss: 0.875910\n",
            "Testset Accuracy: 0.724800\n"
          ]
        }
      ],
      "source": [
        "# Keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Python Std Lib\n",
        "import os\n",
        "\n",
        "# User Lib\n",
        "dropout = 0.2\n",
        "\n",
        "# get the training and test data\n",
        "(input_train, output_train), (input_test, output_test) = cifar10.load_data()\n",
        "\n",
        "# creating the basic model\n",
        "model = Sequential()\n",
        "\n",
        "# 30 Conv Layer\n",
        "model.add(Conv2D(30, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(32, 32, 3)))\n",
        "# 15 Max Pool Layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(Dropout(dropout))\n",
        "# 13 Conv Layer\n",
        "model.add(Conv2D(13, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "# 6 Max Pool Layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(Dropout(dropout))\n",
        "# Flatten the Layer for transitioning to the Fully Connected Layers\n",
        "model.add(Flatten())\n",
        "# 120 Fully Connected Layer\n",
        "model.add(Dense(120, activation='relu'))\n",
        "# 84 Fully Connected Layer\n",
        "model.add(Dense(86, activation='relu'))\n",
        "# 10 Output\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "initial_learning_rate = 0.001\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 100:\n",
        "    return 0.02\n",
        "  elif epoch < 200:\n",
        "    return 0.01\n",
        "  elif epoch < 400:\n",
        "    return 0.005\n",
        "  elif epoch < 700:\n",
        "    return 0.003\n",
        "  else: \n",
        "    return 0.001    \n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "save_dir = '/content/drive/MyDrive/ECE6930/Lenet-0222-01/changelr/2dropout/1'\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(os.path.join(save_dir, '{epoch:03d}.h5'), monitor='val_loss', verbose=0,\t\t\t\t\t\tsave_best_only=False, \n",
        " \t\t\t\t\t\t\t\tsave_weights_only=False, mode='auto', \n",
        " \t\t\t\t\t\t\t\tperiod=10)\n",
        "\n",
        "\n",
        "# train the model\n",
        "history = model.fit(input_train/255, to_categorical(output_train), epochs=1000, \n",
        "           validation_data=(input_test/255, to_categorical(output_test)),\n",
        "                    batch_size=128,callbacks=[callback,checkpointer])\n",
        "\n",
        "\n",
        "# test\n",
        "score = model.evaluate(input_test/255, to_categorical(output_test), batch_size=128)\n",
        "\n",
        "# print test set results\n",
        "print(\"Testset Loss: %f\" % score[0])\n",
        "print(\"Testset Accuracy: %f\" % score[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"test\"],loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hIWjK9z7YU-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6254f066-fe8b-4811-b42f-5ca75c41efc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history)"
      ],
      "metadata": {
        "id": "RHc1aneQaOGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9a7d91-f902-4610-87b6-d96e07bbb285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [2.2568275928497314, 2.0187478065490723, 1.8821609020233154, 1.7741612195968628, 1.6855067014694214, 1.612359881401062, 1.5579721927642822, 1.5130057334899902, 1.472480058670044, 1.4384562969207764, 1.4155408143997192, 1.3919692039489746, 1.3627246618270874, 1.3418868780136108, 1.3255743980407715, 1.3077983856201172, 1.2887122631072998, 1.274728775024414, 1.2535940408706665, 1.2386972904205322, 1.2273558378219604, 1.213835597038269, 1.199421763420105, 1.1910488605499268, 1.1778266429901123, 1.170521855354309, 1.1575671434402466, 1.1467872858047485, 1.136304259300232, 1.1273730993270874, 1.1217951774597168, 1.1135224103927612, 1.101225733757019, 1.0929956436157227, 1.0909584760665894, 1.0788575410842896, 1.0683594942092896, 1.0642516613006592, 1.0581707954406738, 1.0459805727005005, 1.0433465242385864, 1.0332286357879639, 1.0298786163330078, 1.0205284357070923, 1.0143532752990723, 1.00676691532135, 1.0032908916473389, 0.9955878257751465, 0.9938363432884216, 0.9796774387359619, 0.9742578864097595, 0.9676671028137207, 0.964069128036499, 0.9604494571685791, 0.9536201357841492, 0.9449695944786072, 0.9409231543540955, 0.9319440126419067, 0.9293502569198608, 0.923681378364563, 0.9204580187797546, 0.914862871170044, 0.9100587368011475, 0.9005342125892639, 0.8956166505813599, 0.8895528316497803, 0.8878672122955322, 0.884712278842926, 0.881016731262207, 0.872290313243866, 0.868228018283844, 0.8718248605728149, 0.859480619430542, 0.8529967069625854, 0.8506882786750793, 0.847075879573822, 0.843280553817749, 0.8357335925102234, 0.8353835940361023, 0.828260064125061, 0.8238238096237183, 0.8191991448402405, 0.8160399198532104, 0.8128059506416321, 0.8133451342582703, 0.8035444617271423, 0.8048083782196045, 0.8039127588272095, 0.7978419661521912, 0.7904866337776184, 0.7914378046989441, 0.7796624898910522, 0.7748206257820129, 0.7763254046440125, 0.7787236571311951, 0.7721596360206604, 0.7732250690460205, 0.7633751630783081, 0.7602784633636475, 0.7617685794830322, 0.7323102355003357, 0.7314282059669495, 0.7280567288398743, 0.727964460849762, 0.7256126403808594, 0.7211277484893799, 0.7174782752990723, 0.7240757942199707, 0.7190690040588379, 0.7164430618286133, 0.7104200124740601, 0.7127042412757874, 0.7115116119384766, 0.7079572081565857, 0.7100114226341248, 0.7076040506362915, 0.7080183625221252, 0.6999858617782593, 0.7046273350715637, 0.7081428170204163, 0.7019520998001099, 0.7016283869743347, 0.6984073519706726, 0.700364351272583, 0.6969118714332581, 0.6889106035232544, 0.694628119468689, 0.6906609535217285, 0.6914767026901245, 0.6867883801460266, 0.6899054646492004, 0.6828392744064331, 0.6865286231040955, 0.6851271986961365, 0.6805698275566101, 0.6793952584266663, 0.6812034249305725, 0.6799637675285339, 0.6754762530326843, 0.6743349432945251, 0.6750122904777527, 0.6760616302490234, 0.6719375848770142, 0.6730484962463379, 0.6691148281097412, 0.6684277057647705, 0.666657567024231, 0.6700114607810974, 0.6642395257949829, 0.6654139757156372, 0.6631696224212646, 0.6631790399551392, 0.6609846949577332, 0.6592085361480713, 0.6569417715072632, 0.6600265502929688, 0.6523109078407288, 0.6560624837875366, 0.6527650952339172, 0.653357207775116, 0.6542682647705078, 0.6481424570083618, 0.6483293175697327, 0.6477077603340149, 0.6469453573226929, 0.6516764163970947, 0.6443009376525879, 0.6455095410346985, 0.6397021412849426, 0.6390758156776428, 0.6417464017868042, 0.6365511417388916, 0.6408218145370483, 0.6393304467201233, 0.6388683915138245, 0.637925922870636, 0.6360930800437927, 0.6331931948661804, 0.6323859691619873, 0.630859911441803, 0.6309323310852051, 0.6318296194076538, 0.6311795115470886, 0.6285321712493896, 0.6224719285964966, 0.6215651035308838, 0.6227464079856873, 0.6291613578796387, 0.6239377856254578, 0.6211931109428406, 0.6194602847099304, 0.6202009916305542, 0.6191497445106506, 0.6161136031150818, 0.6250210404396057, 0.6175553202629089, 0.6177247166633606, 0.6127585172653198, 0.6167499423027039, 0.6148571372032166, 0.6062561869621277, 0.6006023287773132, 0.5987029075622559, 0.6005329489707947, 0.5982147455215454, 0.5945571064949036, 0.5985997915267944, 0.596367359161377, 0.5949566960334778, 0.5967678427696228, 0.5926192402839661, 0.5934902429580688, 0.5958710312843323, 0.5961593389511108, 0.5961583852767944, 0.5923658013343811, 0.5940502882003784, 0.5926651954650879, 0.5939719676971436, 0.5965834856033325, 0.5929062366485596, 0.5896495580673218, 0.5867488384246826, 0.5918301939964294, 0.59112149477005, 0.5893163084983826, 0.5871450901031494, 0.5892536044120789, 0.5901303887367249, 0.5893723964691162, 0.5883073210716248, 0.5869720578193665, 0.5835824012756348, 0.5831648707389832, 0.5860294103622437, 0.5873075127601624, 0.5854294300079346, 0.5799711346626282, 0.5792208313941956, 0.5808365941047668, 0.5854761600494385, 0.579365074634552, 0.577805757522583, 0.5819301009178162, 0.5784283876419067, 0.5782116055488586, 0.5793249011039734, 0.5805498957633972, 0.5803519487380981, 0.5794532299041748, 0.5764979124069214, 0.5803388953208923, 0.579925000667572, 0.5765298008918762, 0.5760369896888733, 0.5787701606750488, 0.5729347467422485, 0.5795369744300842, 0.5775322914123535, 0.573797345161438, 0.5741968750953674, 0.5785386562347412, 0.5738312602043152, 0.576820969581604, 0.5719764232635498, 0.5695579648017883, 0.572516918182373, 0.5701249241828918, 0.57387775182724, 0.5701983571052551, 0.5705828070640564, 0.5692306756973267, 0.5722193717956543, 0.568817138671875, 0.5715407133102417, 0.5664647221565247, 0.5743465423583984, 0.5610649585723877, 0.5694373846054077, 0.5664584636688232, 0.5741603970527649, 0.5681288242340088, 0.566632091999054, 0.5651803016662598, 0.5629370808601379, 0.5630558729171753, 0.5638101696968079, 0.5623735189437866, 0.5644190907478333, 0.5664377808570862, 0.5620850324630737, 0.5600976347923279, 0.5672275424003601, 0.5669705271720886, 0.5614008903503418, 0.5571166276931763, 0.5641313791275024, 0.5608497858047485, 0.5598393082618713, 0.5577114224433899, 0.5603158473968506, 0.5545575618743896, 0.5603295564651489, 0.5556153059005737, 0.5613555312156677, 0.561133623123169, 0.5614253878593445, 0.5591340661048889, 0.5614550709724426, 0.5544873476028442, 0.5534318089485168, 0.5552666187286377, 0.5556223392486572, 0.5614950656890869, 0.554111659526825, 0.5593899488449097, 0.5528079867362976, 0.5485801100730896, 0.5555455684661865, 0.5497816801071167, 0.5535159111022949, 0.548359751701355, 0.5557511448860168, 0.5534477233886719, 0.54730623960495, 0.5519598126411438, 0.553237795829773, 0.5522535443305969, 0.5518041253089905, 0.5554690957069397, 0.5494911074638367, 0.5460523962974548, 0.5470812320709229, 0.5474711656570435, 0.5489239692687988, 0.5493414998054504, 0.5465928316116333, 0.5480266213417053, 0.5441315770149231, 0.5450505018234253, 0.5436220169067383, 0.5474820137023926, 0.5415924191474915, 0.5422160029411316, 0.541398286819458, 0.5491105318069458, 0.5477142930030823, 0.5447508096694946, 0.5416577458381653, 0.5443704128265381, 0.5461369752883911, 0.5440739989280701, 0.5417492389678955, 0.5403679013252258, 0.5377563834190369, 0.5395767688751221, 0.5428302884101868, 0.5427735447883606, 0.5408796072006226, 0.5397707223892212, 0.5421603918075562, 0.5415508151054382, 0.5407484769821167, 0.5408101677894592, 0.5440698266029358, 0.5369526743888855, 0.5371729135513306, 0.5400359630584717, 0.5376219749450684, 0.5399770140647888, 0.5365826487541199, 0.5395670533180237, 0.5395503640174866, 0.533324658870697, 0.535591185092926, 0.5312682390213013, 0.5332944393157959, 0.5313800573348999, 0.5326161980628967, 0.5312986969947815, 0.5313340425491333, 0.538211464881897, 0.5352615714073181, 0.5329936742782593, 0.5308072566986084, 0.5325425267219543, 0.5346836447715759, 0.5316997766494751, 0.5295525193214417, 0.5291026830673218, 0.5307989120483398, 0.5331610441207886, 0.5314990878105164, 0.528021514415741, 0.5281780958175659, 0.532020628452301, 0.5292608141899109, 0.5336506366729736, 0.529931366443634, 0.5258276462554932, 0.5208544135093689, 0.5233341455459595, 0.5204450488090515, 0.5242855548858643, 0.5251339673995972, 0.5196083784103394, 0.524847149848938, 0.525407612323761, 0.5209861993789673, 0.525671660900116, 0.5185193419456482, 0.5198081731796265, 0.518487811088562, 0.5211523175239563, 0.5201804041862488, 0.5191702842712402, 0.519382119178772, 0.5205703377723694, 0.5163787007331848, 0.5162162184715271, 0.5207244157791138, 0.5191953778266907, 0.5226077437400818, 0.5154740810394287, 0.5199090242385864, 0.5163591504096985, 0.5208637714385986, 0.5201611518859863, 0.5175283551216125, 0.517675518989563, 0.5147895216941833, 0.5191149115562439, 0.516988217830658, 0.5177685022354126, 0.5186483860015869, 0.52032071352005, 0.5163973569869995, 0.5191372036933899, 0.5209647417068481, 0.5146125555038452, 0.5197591185569763, 0.5124557018280029, 0.5137479305267334, 0.5106292366981506, 0.5172670483589172, 0.5177774429321289, 0.5138190984725952, 0.5140570998191833, 0.5107999444007874, 0.5124732255935669, 0.5192372798919678, 0.5111866593360901, 0.5102756023406982, 0.5151051878929138, 0.5157409310340881, 0.515416145324707, 0.5123481750488281, 0.5123947858810425, 0.511265754699707, 0.513279914855957, 0.5083203315734863, 0.5160953402519226, 0.5152871608734131, 0.5171110033988953, 0.5134193301200867, 0.5131847858428955, 0.5166410207748413, 0.507211446762085, 0.5025926232337952, 0.5095459222793579, 0.5089148283004761, 0.5117934346199036, 0.5147777795791626, 0.5130107998847961, 0.510795533657074, 0.5059773921966553, 0.5073634386062622, 0.5063165426254272, 0.5084298253059387, 0.513709545135498, 0.5035005211830139, 0.5065599679946899, 0.5067397952079773, 0.5078073143959045, 0.5075819492340088, 0.5094026327133179, 0.5113206505775452, 0.5025323629379272, 0.5094685554504395, 0.506215512752533, 0.5107638239860535, 0.5093235373497009, 0.5041136741638184, 0.5079846382141113, 0.5089810490608215, 0.5100137591362, 0.5065608024597168, 0.5077085494995117, 0.5053471326828003, 0.5060513615608215, 0.5035505294799805, 0.5103397965431213, 0.5049811601638794, 0.5058708786964417, 0.5020458102226257, 0.503548264503479, 0.5072216987609863, 0.5077285170555115, 0.5078795552253723, 0.5060931444168091, 0.5063096284866333, 0.5031253695487976, 0.5050763487815857, 0.5053427219390869, 0.5061636567115784, 0.5013296604156494, 0.5008774399757385, 0.49983397126197815, 0.5051885843276978, 0.5054858326911926, 0.5009487867355347, 0.5048965215682983, 0.5007193088531494, 0.5074201822280884, 0.5052596926689148, 0.5052947402000427, 0.49986112117767334, 0.5016788244247437, 0.5055403113365173, 0.5022905468940735, 0.4991101026535034, 0.5041052103042603, 0.5026304125785828, 0.5067380666732788, 0.5018838047981262, 0.5000840425491333, 0.499196320772171, 0.5011034607887268, 0.49997496604919434, 0.5044359564781189, 0.5004686117172241, 0.49968868494033813, 0.49919211864471436, 0.49995750188827515, 0.4985465705394745, 0.4973756670951843, 0.5009404420852661, 0.5006701350212097, 0.4969414472579956, 0.4982333481311798, 0.49604278802871704, 0.4974657893180847, 0.49943187832832336, 0.49745839834213257, 0.49752920866012573, 0.5005433559417725, 0.5026489496231079, 0.49630144238471985, 0.5031855702400208, 0.49825319647789, 0.5016231536865234, 0.49791961908340454, 0.49801671504974365, 0.49936240911483765, 0.4958835244178772, 0.495663583278656, 0.49651116132736206, 0.4955228865146637, 0.4966367185115814, 0.5000947117805481, 0.49843308329582214, 0.4999217092990875, 0.5012896656990051, 0.4972051680088043, 0.4954543709754944, 0.49508363008499146, 0.49837300181388855, 0.49481406807899475, 0.4937346875667572, 0.4945043623447418, 0.4907650649547577, 0.5004458427429199, 0.4941258132457733, 0.49158793687820435, 0.49506276845932007, 0.4945175051689148, 0.49651703238487244, 0.49603432416915894, 0.4949721395969391, 0.49059054255485535, 0.49180757999420166, 0.48851311206817627, 0.49589434266090393, 0.4947061836719513, 0.4899945557117462, 0.49662187695503235, 0.4930912256240845, 0.48766306042671204, 0.4938421845436096, 0.49210092425346375, 0.4958226978778839, 0.49468547105789185, 0.49295350909233093, 0.4930284023284912, 0.4971652328968048, 0.49312371015548706, 0.49170276522636414, 0.48947641253471375, 0.494126558303833, 0.4920905530452728, 0.4936087131500244, 0.4879968464374542, 0.4866119623184204, 0.4918017089366913, 0.4884152412414551, 0.4978330433368683, 0.4856066107749939, 0.492972731590271, 0.4854254722595215, 0.48554375767707825, 0.4878396987915039, 0.4929908514022827, 0.4869774580001831, 0.4848020672798157, 0.4871167838573456, 0.4864822328090668, 0.49719303846359253, 0.48655593395233154, 0.4885597229003906, 0.4898548126220703, 0.4888627827167511, 0.490285187959671, 0.49028342962265015, 0.4873459041118622, 0.49063485860824585, 0.4851282835006714, 0.48791268467903137, 0.4848553240299225, 0.4875117838382721, 0.4870104193687439, 0.4836941659450531, 0.48842430114746094, 0.4861616790294647, 0.48998188972473145, 0.4860970377922058, 0.486719012260437, 0.49009472131729126, 0.4802200496196747, 0.4824681580066681, 0.4858969449996948, 0.48802947998046875, 0.4833357036113739, 0.48416760563850403, 0.48432856798171997, 0.4832473397254944, 0.4887753427028656, 0.4844851493835449, 0.4813711643218994, 0.4873277246952057, 0.48880884051322937, 0.4818170964717865, 0.48595768213272095, 0.48438793420791626, 0.48549413681030273, 0.48321762681007385, 0.48357585072517395, 0.48226398229599, 0.4812144935131073, 0.4795243740081787, 0.4908253252506256, 0.4828527867794037, 0.48604971170425415, 0.47798871994018555, 0.48569566011428833, 0.4842609465122223, 0.4823721945285797, 0.4825769066810608, 0.48084208369255066, 0.4855511784553528, 0.4852917194366455, 0.47688421607017517, 0.4864395558834076, 0.486571729183197, 0.48368382453918457, 0.48080533742904663, 0.47858384251594543, 0.4825928509235382, 0.4812452793121338, 0.48912301659584045, 0.47991907596588135, 0.47917941212654114, 0.47998055815696716, 0.4813399612903595, 0.4793851971626282, 0.48259034752845764, 0.4810883700847626, 0.47584763169288635, 0.4805345833301544, 0.4799334704875946, 0.4798557460308075, 0.4710206985473633, 0.47624263167381287, 0.4716835618019104, 0.4752155542373657, 0.47867000102996826, 0.47442081570625305, 0.46984928846359253, 0.47419264912605286, 0.4754303991794586, 0.4736729562282562, 0.4704453945159912, 0.4760776460170746, 0.47541362047195435, 0.4689899682998657, 0.4762098491191864, 0.4760211706161499, 0.4736047685146332, 0.469253271818161, 0.47243088483810425, 0.4737369120121002, 0.4758627414703369, 0.4750765264034271, 0.4692963659763336, 0.47184550762176514, 0.471504807472229, 0.47104838490486145, 0.47420504689216614, 0.4739551842212677, 0.471426397562027, 0.47129637002944946, 0.47470977902412415, 0.47348636388778687, 0.47805139422416687, 0.46934157609939575, 0.47066089510917664, 0.47691071033477783, 0.47495973110198975, 0.46824878454208374, 0.4743131995201111, 0.47634586691856384, 0.473702609539032, 0.47356975078582764, 0.472804993391037, 0.47728800773620605, 0.4763420820236206, 0.47079190611839294, 0.47127577662467957, 0.4728434383869171, 0.47188350558280945, 0.471302330493927, 0.4749934673309326, 0.47609981894493103, 0.4711184799671173, 0.4685882329940796, 0.4732555150985718, 0.47358715534210205, 0.4750595688819885, 0.4731588363647461, 0.47041934728622437, 0.47060397267341614, 0.4732035994529724, 0.4699085056781769, 0.46781885623931885, 0.4705739915370941, 0.4696533679962158, 0.4715869128704071, 0.4722793698310852, 0.47332698106765747, 0.47213903069496155, 0.4739478528499603, 0.47434887290000916, 0.47293588519096375, 0.46940070390701294, 0.4740758240222931, 0.4696853458881378, 0.47214004397392273, 0.4730205535888672, 0.46850258111953735, 0.47394508123397827, 0.47011250257492065, 0.46378588676452637, 0.4722196161746979, 0.46763065457344055, 0.46819940209388733, 0.4729451537132263, 0.467144250869751, 0.4729520380496979, 0.4697939157485962, 0.46742984652519226, 0.47232821583747864, 0.4760177433490753, 0.46924659609794617, 0.47306913137435913, 0.47084036469459534, 0.4728985130786896, 0.4727475345134735, 0.4675579369068146, 0.4775964319705963, 0.4732521176338196, 0.4702347218990326, 0.46923625469207764, 0.4724363386631012, 0.4721505045890808, 0.46936169266700745, 0.4679676294326782, 0.47327813506126404, 0.47114333510398865, 0.4692586660385132, 0.46907153725624084, 0.4732995331287384, 0.47100934386253357, 0.47135475277900696, 0.47506386041641235, 0.4701930582523346, 0.46854808926582336, 0.470824658870697, 0.46970993280410767, 0.46912479400634766, 0.4717625677585602, 0.47221776843070984, 0.46816590428352356, 0.46719250082969666, 0.4656940996646881, 0.4684603214263916, 0.4705074727535248, 0.47238171100616455, 0.4697152376174927, 0.4643366038799286, 0.46765291690826416, 0.47110694646835327, 0.46787229180336, 0.46883171796798706, 0.46873387694358826, 0.4721600413322449, 0.4649888575077057, 0.46790334582328796, 0.46866655349731445, 0.4684613347053528, 0.4699746072292328, 0.4667188227176666, 0.46712151169776917, 0.4674670696258545, 0.4716300070285797, 0.465054452419281, 0.4707089364528656, 0.47045406699180603, 0.46724802255630493, 0.47130370140075684, 0.472913920879364, 0.46724897623062134, 0.4685032367706299, 0.4711439311504364, 0.46995440125465393, 0.4683486819267273, 0.46653640270233154, 0.4683390259742737, 0.46611061692237854, 0.47050365805625916, 0.4681958854198456, 0.4656875729560852, 0.46988147497177124, 0.46786460280418396, 0.46635398268699646, 0.4606730043888092, 0.4697248041629791, 0.4703623354434967, 0.46872687339782715, 0.4659245014190674, 0.46667495369911194, 0.46532315015792847, 0.4694744646549225, 0.4685121476650238, 0.4660623073577881, 0.465429425239563, 0.46658632159233093, 0.47105690836906433, 0.47015491127967834, 0.46297937631607056, 0.46549877524375916, 0.4682002663612366, 0.4665640592575073, 0.46959376335144043, 0.4649534523487091, 0.4696847200393677, 0.4688880741596222, 0.4645858705043793, 0.4682808518409729, 0.469094455242157, 0.4641653597354889, 0.4678971469402313, 0.46710407733917236, 0.4656662046909332, 0.4725555181503296, 0.47311726212501526, 0.4662567675113678, 0.4669524133205414, 0.4685813784599304, 0.46495336294174194, 0.46402445435523987, 0.46630775928497314, 0.46634504199028015, 0.47045308351516724, 0.46848610043525696, 0.462868869304657, 0.4689755141735077, 0.4686426520347595, 0.46411237120628357, 0.4680010676383972, 0.4616056978702545, 0.46741557121276855, 0.4651181697845459, 0.46380969882011414, 0.464566171169281, 0.4661324918270111, 0.4691287875175476, 0.4657071530818939, 0.4639732539653778, 0.4661303460597992, 0.4653627872467041, 0.4693412184715271, 0.4698601961135864, 0.4631035625934601, 0.4644014537334442, 0.4678855538368225, 0.4664965867996216, 0.4683787226676941, 0.4684810936450958, 0.46349141001701355, 0.46415674686431885, 0.46637487411499023, 0.46388480067253113, 0.4686603546142578, 0.46601980924606323, 0.4675716161727905, 0.4648358225822449, 0.46272924542427063, 0.4643298387527466, 0.46690288186073303, 0.470774382352829, 0.4673067331314087, 0.4629390239715576, 0.4686294496059418, 0.46602362394332886, 0.4663271903991699, 0.4603322148323059, 0.45859506726264954, 0.4636341333389282, 0.46379411220550537, 0.4649096131324768, 0.4656776189804077, 0.46801847219467163, 0.4637145698070526, 0.4645085632801056, 0.4671161472797394, 0.4651523530483246, 0.4623356759548187, 0.4633426070213318, 0.46699386835098267, 0.4695078134536743, 0.4643896222114563, 0.4603632092475891, 0.4623958468437195, 0.4651169776916504, 0.46724483370780945, 0.4627721607685089, 0.46683746576309204, 0.46308374404907227, 0.4655068814754486, 0.4656846523284912, 0.4616205096244812, 0.46853896975517273, 0.46156013011932373, 0.4666344225406647, 0.4629109501838684, 0.46077316999435425, 0.4646134674549103, 0.4640170633792877, 0.4605160653591156, 0.46216338872909546, 0.4642682373523712, 0.46303558349609375, 0.46571558713912964, 0.4604347348213196, 0.464556485414505, 0.4678892493247986, 0.4620562195777893, 0.46537959575653076, 0.4600251615047455, 0.46356284618377686, 0.461392879486084, 0.46336817741394043, 0.46306777000427246, 0.4590683877468109, 0.4606604278087616, 0.46570098400115967, 0.45975372195243835, 0.4584304392337799, 0.4646152853965759, 0.4647764563560486, 0.4616878926753998], 'accuracy': [0.1489199995994568, 0.2610799968242645, 0.3154999911785126, 0.35690000653266907, 0.3880000114440918, 0.41290000081062317, 0.4365200102329254, 0.45399999618530273, 0.46873998641967773, 0.4827199876308441, 0.4874599874019623, 0.5008999705314636, 0.5132799744606018, 0.5200999975204468, 0.5245000123977661, 0.534280002117157, 0.54093998670578, 0.5446199774742126, 0.5548999905586243, 0.5594199895858765, 0.5616000294685364, 0.5687199831008911, 0.573140025138855, 0.5771999955177307, 0.5839599967002869, 0.5842999815940857, 0.5882999897003174, 0.5914400219917297, 0.5984399914741516, 0.6028199791908264, 0.6050999760627747, 0.6075599789619446, 0.6115999817848206, 0.6137999892234802, 0.6160600185394287, 0.6196799874305725, 0.6234599947929382, 0.625, 0.6294199824333191, 0.6310200095176697, 0.6327000260353088, 0.6375600099563599, 0.637719988822937, 0.6421999931335449, 0.6439399719238281, 0.6461600065231323, 0.6485199928283691, 0.6493600010871887, 0.6494600176811218, 0.6549000144004822, 0.6577200293540955, 0.6615599989891052, 0.6638399958610535, 0.6614800095558167, 0.6665599942207336, 0.6657400131225586, 0.6693800091743469, 0.6717000007629395, 0.6741799712181091, 0.6749600172042847, 0.6752600073814392, 0.6773800253868103, 0.6808800101280212, 0.6838399767875671, 0.6857600212097168, 0.686460018157959, 0.6880599856376648, 0.689520001411438, 0.6897199749946594, 0.6932200193405151, 0.6944000124931335, 0.6948999762535095, 0.6974400281906128, 0.6988400220870972, 0.6988800168037415, 0.7009599804878235, 0.7029200196266174, 0.7050999999046326, 0.7073799967765808, 0.7089999914169312, 0.7087799906730652, 0.7101399898529053, 0.7127799987792969, 0.712660014629364, 0.7138199806213379, 0.7163400053977966, 0.7178800106048584, 0.7136600017547607, 0.7176200151443481, 0.7227200269699097, 0.7196000218391418, 0.7239999771118164, 0.727400004863739, 0.7262200117111206, 0.7267199754714966, 0.7271999716758728, 0.7287200093269348, 0.7297599911689758, 0.7319200038909912, 0.7294999957084656, 0.7422000169754028, 0.7410600185394287, 0.7440599799156189, 0.7445399761199951, 0.7421000003814697, 0.7460799813270569, 0.7463200092315674, 0.7426199913024902, 0.7446799874305725, 0.7469199895858765, 0.7483199834823608, 0.7477999925613403, 0.7491000294685364, 0.7494800090789795, 0.7494999766349792, 0.7487599849700928, 0.7480000257492065, 0.7522000074386597, 0.7520400285720825, 0.7493199706077576, 0.750540018081665, 0.7508000135421753, 0.7527400255203247, 0.750540018081665, 0.754800021648407, 0.7546799778938293, 0.7523000240325928, 0.7558799982070923, 0.7534599900245667, 0.7589399814605713, 0.756600022315979, 0.7585999965667725, 0.758080005645752, 0.7568600177764893, 0.760420024394989, 0.7609599828720093, 0.7587599754333496, 0.7596200108528137, 0.7626399993896484, 0.7620800137519836, 0.7596200108528137, 0.7594000101089478, 0.7615600228309631, 0.7612800002098083, 0.7623800039291382, 0.761139988899231, 0.7633799910545349, 0.7641599774360657, 0.7643399834632874, 0.7651600241661072, 0.7661799788475037, 0.7639999985694885, 0.7642199993133545, 0.7653599977493286, 0.7673400044441223, 0.7662799954414368, 0.7685999870300293, 0.7649000287055969, 0.769860029220581, 0.7674400210380554, 0.766319990158081, 0.7702400088310242, 0.7700999975204468, 0.7707399725914001, 0.7716799974441528, 0.7685400247573853, 0.769760012626648, 0.7703999876976013, 0.774179995059967, 0.7736999988555908, 0.7727599740028381, 0.7727400064468384, 0.7704399824142456, 0.7720800042152405, 0.7717599868774414, 0.7748799920082092, 0.772819995880127, 0.7748799920082092, 0.7755200266838074, 0.7748000025749207, 0.7749599814414978, 0.7740799784660339, 0.7749000191688538, 0.7750200033187866, 0.7763199806213379, 0.7811999917030334, 0.7788800001144409, 0.776639997959137, 0.77920001745224, 0.7782599925994873, 0.7802000045776367, 0.7775599956512451, 0.7797600030899048, 0.7817000150680542, 0.77947998046875, 0.781000018119812, 0.781279981136322, 0.781220018863678, 0.7817999720573425, 0.7817400097846985, 0.7852799892425537, 0.7862200140953064, 0.7857599854469299, 0.7860199809074402, 0.7872400283813477, 0.7893199920654297, 0.7880200147628784, 0.7869799733161926, 0.7887399792671204, 0.7882999777793884, 0.7882000207901001, 0.7892400026321411, 0.7899799942970276, 0.7879400253295898, 0.78711998462677, 0.7879800200462341, 0.7904000282287598, 0.7900199890136719, 0.7884799838066101, 0.789139986038208, 0.7901600003242493, 0.7907800078392029, 0.7906200289726257, 0.7878199815750122, 0.7893000245094299, 0.7916799783706665, 0.7915999889373779, 0.7883599996566772, 0.7892400026321411, 0.7912399768829346, 0.7910199761390686, 0.7908599972724915, 0.792140007019043, 0.7922800183296204, 0.7922000288963318, 0.7900999784469604, 0.7917600274085999, 0.7937800288200378, 0.7924200296401978, 0.7936400175094604, 0.7927799820899963, 0.7933599948883057, 0.793940007686615, 0.7926200032234192, 0.7948399782180786, 0.7932199835777283, 0.7935400009155273, 0.7924399971961975, 0.7932199835777283, 0.7919999957084656, 0.7950800061225891, 0.7925400137901306, 0.7953000068664551, 0.7949399948120117, 0.794439971446991, 0.7946599721908569, 0.7940800189971924, 0.7932800054550171, 0.794920027256012, 0.7965999841690063, 0.7963600158691406, 0.794219970703125, 0.795799970626831, 0.7943000197410583, 0.796180009841919, 0.7980200052261353, 0.7969200015068054, 0.7975000143051147, 0.7978399991989136, 0.7950800061225891, 0.7981600165367126, 0.7972599864006042, 0.7943400144577026, 0.7968199849128723, 0.7959799766540527, 0.7976199984550476, 0.7942000031471252, 0.8011400103569031, 0.7971400022506714, 0.7987800240516663, 0.7940400242805481, 0.7971600294113159, 0.7988600134849548, 0.7984600067138672, 0.7982400059700012, 0.798039972782135, 0.7970399856567383, 0.7985600233078003, 0.798799991607666, 0.7986400127410889, 0.799560010433197, 0.8003000020980835, 0.7983199954032898, 0.7985399961471558, 0.7997599840164185, 0.8016600012779236, 0.7978000044822693, 0.7996000051498413, 0.8007799983024597, 0.7991600036621094, 0.8011400103569031, 0.8022000193595886, 0.8014000058174133, 0.7991799712181091, 0.8003000020980835, 0.799839973449707, 0.7985000014305115, 0.8016999959945679, 0.799340009689331, 0.8027600049972534, 0.8032000064849854, 0.8009399771690369, 0.8020200133323669, 0.8001000285148621, 0.8015599846839905, 0.7991200089454651, 0.8008400201797485, 0.803059995174408, 0.8018199801445007, 0.8040000200271606, 0.8021799921989441, 0.8039799928665161, 0.7999200224876404, 0.8025199770927429, 0.8057000041007996, 0.8021799921989441, 0.8042200207710266, 0.8027799725532532, 0.805180013179779, 0.8005200028419495, 0.8034600019454956, 0.8025599718093872, 0.8038600087165833, 0.8039199709892273, 0.8037800192832947, 0.8027600049972534, 0.8051599860191345, 0.8054999709129333, 0.8057399988174438, 0.8046799898147583, 0.8065599799156189, 0.8048800230026245, 0.8054599761962891, 0.805679976940155, 0.8057799935340881, 0.8034200072288513, 0.8037999868392944, 0.8054800033569336, 0.8058199882507324, 0.8036800026893616, 0.8047000169754028, 0.8050600290298462, 0.8087599873542786, 0.8049600124359131, 0.8077399730682373, 0.806879997253418, 0.8067399859428406, 0.8068199753761292, 0.807479977607727, 0.8072999715805054, 0.805620014667511, 0.8087999820709229, 0.8065999746322632, 0.8065400123596191, 0.8047599792480469, 0.806879997253418, 0.807200014591217, 0.8069800138473511, 0.8060799837112427, 0.8075799942016602, 0.8064200282096863, 0.8066200017929077, 0.8066999912261963, 0.8102800250053406, 0.8071600198745728, 0.8105800151824951, 0.8088200092315674, 0.8104599714279175, 0.8099799752235413, 0.8092600107192993, 0.8098599910736084, 0.8082000017166138, 0.8075399994850159, 0.8087800145149231, 0.8090400099754333, 0.8097599744796753, 0.8079400062561035, 0.8087199926376343, 0.8094800114631653, 0.8110600113868713, 0.8098000288009644, 0.8074600100517273, 0.807640016078949, 0.8130800127983093, 0.8102800250053406, 0.8093799948692322, 0.8101800084114075, 0.807420015335083, 0.8093600273132324, 0.8112800121307373, 0.8127400279045105, 0.8132200241088867, 0.8144599795341492, 0.8123999834060669, 0.8120399713516235, 0.8156399726867676, 0.8125799894332886, 0.8115800023078918, 0.8116999864578247, 0.8114399909973145, 0.8152599930763245, 0.8147199749946594, 0.8137400150299072, 0.8135799765586853, 0.814300000667572, 0.8151400089263916, 0.8140000104904175, 0.8131399750709534, 0.8148400187492371, 0.815339982509613, 0.8139600157737732, 0.8143799901008606, 0.8126199841499329, 0.8164799809455872, 0.8157399892807007, 0.8169599771499634, 0.8118199706077576, 0.8129799962043762, 0.8154000043869019, 0.8162400126457214, 0.8148999810218811, 0.8147000074386597, 0.8172399997711182, 0.8149799704551697, 0.8143799901008606, 0.8128600120544434, 0.8147000074386597, 0.8131399750709534, 0.8140400052070618, 0.8150399923324585, 0.8146399855613708, 0.8163599967956543, 0.8148199915885925, 0.8175399899482727, 0.814740002155304, 0.814740002155304, 0.8149799704551697, 0.8164600133895874, 0.8169000148773193, 0.8169000148773193, 0.8151199817657471, 0.8165599703788757, 0.8169000148773193, 0.8154399991035461, 0.8136600255966187, 0.8141599893569946, 0.8158199787139893, 0.8156999945640564, 0.817579984664917, 0.8167399764060974, 0.8167799711227417, 0.8156599998474121, 0.815559983253479, 0.8152199983596802, 0.8166400194168091, 0.8161399960517883, 0.8145400285720825, 0.8180800080299377, 0.8215600252151489, 0.8158599734306335, 0.8162999749183655, 0.8156399726867676, 0.8158199787139893, 0.817080020904541, 0.8152999877929688, 0.8179200291633606, 0.8193399906158447, 0.8187000155448914, 0.8169800043106079, 0.8148400187492371, 0.8172399997711182, 0.8180199861526489, 0.8186799883842468, 0.8186799883842468, 0.8190799951553345, 0.8169800043106079, 0.8175399899482727, 0.8203799724578857, 0.8177400231361389, 0.8189600110054016, 0.8176400065422058, 0.8166599869728088, 0.8190000057220459, 0.8177000284194946, 0.8182799816131592, 0.8180000185966492, 0.8171399831771851, 0.8184800148010254, 0.8198599815368652, 0.8196399807929993, 0.8194000124931335, 0.8158199787139893, 0.8180599808692932, 0.8193399906158447, 0.821619987487793, 0.8191400170326233, 0.8184800148010254, 0.8172600269317627, 0.8161399960517883, 0.818120002746582, 0.8182600140571594, 0.8195000290870667, 0.8190199732780457, 0.8206999897956848, 0.8193399906158447, 0.8187599778175354, 0.8213599920272827, 0.8202599883079529, 0.8189399838447571, 0.8194800019264221, 0.8202000260353088, 0.8200399875640869, 0.820360004901886, 0.8179200291633606, 0.8187800049781799, 0.8192600011825562, 0.8197399973869324, 0.8195400238037109, 0.8180199861526489, 0.8210200071334839, 0.823140025138855, 0.8196799755096436, 0.8174800276756287, 0.8197799921035767, 0.8208400011062622, 0.8215399980545044, 0.8212000131607056, 0.8210999965667725, 0.8202000260353088, 0.8212199807167053, 0.8192399740219116, 0.8210200071334839, 0.8201000094413757, 0.8197199702262878, 0.8205599784851074, 0.820900022983551, 0.8198000192642212, 0.8186399936676025, 0.821619987487793, 0.8229399919509888, 0.8232200145721436, 0.8221200108528137, 0.8197799921035767, 0.820900022983551, 0.8216400146484375, 0.8201199769973755, 0.8180599808692932, 0.8220400214195251, 0.8196399807929993, 0.8212400078773499, 0.8197199702262878, 0.8210200071334839, 0.8221799731254578, 0.8200600147247314, 0.8224200010299683, 0.8212599754333496, 0.8214600086212158, 0.8213800191879272, 0.8227999806404114, 0.8200799822807312, 0.8213800191879272, 0.8214799761772156, 0.8197399973869324, 0.8220199942588806, 0.822380006313324, 0.821340024471283, 0.8208799958229065, 0.8219199776649475, 0.8228200078010559, 0.8233199715614319, 0.8253999948501587, 0.8221799731254578, 0.8225799798965454, 0.8228399753570557, 0.8222200274467468, 0.8232799768447876, 0.8209800124168396, 0.8234400153160095, 0.8208000063896179, 0.8236600160598755, 0.8236799836158752, 0.8241599798202515, 0.8227800130844116, 0.8249199986457825, 0.8245800137519836, 0.8212000131607056, 0.82396000623703, 0.8237400054931641, 0.8226000070571899, 0.8236200213432312, 0.8211399912834167, 0.8222600221633911, 0.8229600191116333, 0.8225799798965454, 0.8210800290107727, 0.8222399950027466, 0.8242400288581848, 0.8256199955940247, 0.8241599798202515, 0.8230999708175659, 0.8206599950790405, 0.8247799873352051, 0.8259199857711792, 0.8241599798202515, 0.8241199851036072, 0.8216999769210815, 0.8272799849510193, 0.8214799761772156, 0.8262199759483337, 0.8244400024414062, 0.8246600031852722, 0.8227199912071228, 0.8248199820518494, 0.825659990310669, 0.8239799737930298, 0.825160026550293, 0.8212800025939941, 0.8241999745368958, 0.8235999941825867, 0.8247600197792053, 0.8240200281143188, 0.8230599761009216, 0.8243799805641174, 0.8259400129318237, 0.823639988899231, 0.8268799781799316, 0.8246600031852722, 0.8250600099563599, 0.8255000114440918, 0.8251199722290039, 0.8254200220108032, 0.8245999813079834, 0.8250399827957153, 0.823639988899231, 0.8271399736404419, 0.8253200054168701, 0.8256800174713135, 0.8279200196266174, 0.8285599946975708, 0.8246600031852722, 0.8240000009536743, 0.8281199932098389, 0.8252599835395813, 0.8266400098800659, 0.8258399963378906, 0.8241000175476074, 0.8255800008773804, 0.8280199766159058, 0.8242999911308289, 0.8238999843597412, 0.8271999955177307, 0.823199987411499, 0.8241400122642517, 0.8265399932861328, 0.8267599940299988, 0.8252000212669373, 0.8277199864387512, 0.826960027217865, 0.8263800144195557, 0.8228800296783447, 0.8279600143432617, 0.8261799812316895, 0.8288800120353699, 0.8245199918746948, 0.8258000016212463, 0.8270999789237976, 0.8277400135993958, 0.8278999924659729, 0.8241400122642517, 0.8264999985694885, 0.8281599879264832, 0.8252999782562256, 0.8263400197029114, 0.8262799978256226, 0.8272600173950195, 0.8280799984931946, 0.8261399865150452, 0.8270599842071533, 0.8230000138282776, 0.8288999795913696, 0.8281199932098389, 0.8272799849510193, 0.8245999813079834, 0.828760027885437, 0.8265399932861328, 0.8273599743843079, 0.828279972076416, 0.8275200128555298, 0.8292999863624573, 0.8272799849510193, 0.8321999907493591, 0.8271600008010864, 0.8304200172424316, 0.8288000226020813, 0.8284599781036377, 0.8290600180625916, 0.8308600187301636, 0.8291400074958801, 0.8289399743080139, 0.8304399847984314, 0.8287400007247925, 0.828499972820282, 0.8274800181388855, 0.8318799734115601, 0.8284800052642822, 0.829800009727478, 0.8314599990844727, 0.8325799703598022, 0.8304200172424316, 0.8291800022125244, 0.829259991645813, 0.8286799788475037, 0.8310800194740295, 0.8295599818229675, 0.8286399841308594, 0.8294600248336792, 0.8299999833106995, 0.8294399976730347, 0.8308200240135193, 0.8308200240135193, 0.8307200074195862, 0.8311600089073181, 0.8287799954414368, 0.8295199871063232, 0.8319399952888489, 0.8294199705123901, 0.8279799818992615, 0.8297799825668335, 0.83051997423172, 0.829200029373169, 0.8292400240898132, 0.828279972076416, 0.8313999772071838, 0.8287799954414368, 0.8298400044441223, 0.8295199871063232, 0.8309000134468079, 0.8301799893379211, 0.8296999931335449, 0.829800009727478, 0.8274199962615967, 0.8273599743843079, 0.8298400044441223, 0.8321200013160706, 0.8314999938011169, 0.8309999704360962, 0.8294000029563904, 0.8314599990844727, 0.8313199877738953, 0.8309599757194519, 0.8302000164985657, 0.8308200240135193, 0.832040011882782, 0.8303400278091431, 0.8314599990844727, 0.8308600187301636, 0.8289600014686584, 0.8296399712562561, 0.8288800120353699, 0.8308799862861633, 0.8298799991607666, 0.8304600119590759, 0.8306199908256531, 0.8299999833106995, 0.830780029296875, 0.8276600241661072, 0.8289999961853027, 0.8318799734115601, 0.8291599750518799, 0.8314999938011169, 0.8336600065231323, 0.8300999999046326, 0.8318799734115601, 0.8307600021362305, 0.8302199840545654, 0.8326600193977356, 0.8301600217819214, 0.832539975643158, 0.8315399885177612, 0.8317400217056274, 0.827180027961731, 0.8315600156784058, 0.8299800157546997, 0.8308799862861633, 0.8314200043678284, 0.8286799788475037, 0.8328199982643127, 0.8289999961853027, 0.8301200270652771, 0.83160001039505, 0.8312199711799622, 0.8305400013923645, 0.8292999863624573, 0.8313400149345398, 0.8334199786186218, 0.8309199810028076, 0.8299599885940552, 0.8316799998283386, 0.8311200141906738, 0.8291599750518799, 0.8269799947738647, 0.8303800225257874, 0.8317999839782715, 0.8307399749755859, 0.8314999938011169, 0.8328999876976013, 0.8312600255012512, 0.8317199945449829, 0.8314800262451172, 0.8310999870300293, 0.832040011882782, 0.8313800096511841, 0.8316400051116943, 0.8318399786949158, 0.8290799856185913, 0.8301600217819214, 0.8325200080871582, 0.8331000208854675, 0.8311799764633179, 0.8328999876976013, 0.8329200148582458, 0.8307999968528748, 0.830299973487854, 0.8299599885940552, 0.8336399793624878, 0.8323400020599365, 0.8328199982643127, 0.8310999870300293, 0.8315399885177612, 0.8319600224494934, 0.8317000269889832, 0.8330600261688232, 0.830299973487854, 0.8329600095748901, 0.8301600217819214, 0.8285800218582153, 0.8317000269889832, 0.8299000263214111, 0.8296599984169006, 0.8322399854660034, 0.8312199711799622, 0.828760027885437, 0.8309599757194519, 0.8330399990081787, 0.8325799703598022, 0.8311399817466736, 0.8324000239372253, 0.8286799788475037, 0.8307600021362305, 0.8334000110626221, 0.8305799961090088, 0.8324800133705139, 0.8328400254249573, 0.8337399959564209, 0.8313000202178955, 0.8321800231933594, 0.8320000171661377, 0.833840012550354, 0.8314200043678284, 0.8331599831581116, 0.8312199711799622, 0.8318799734115601, 0.8320800065994263, 0.8321400284767151, 0.83051997423172, 0.8300399780273438, 0.83051997423172, 0.8344399929046631, 0.8317400217056274, 0.8321200013160706, 0.8331000208854675, 0.8305799961090088, 0.8341599702835083, 0.8294199705123901, 0.8324999809265137, 0.8327800035476685, 0.8297600150108337, 0.8301399946212769, 0.8332800269126892, 0.8310800194740295, 0.8317800164222717, 0.8324400186538696, 0.8307200074195862, 0.8297600150108337, 0.8328199982643127, 0.8320800065994263, 0.8327000141143799, 0.8324199914932251, 0.8326399922370911, 0.8320000171661377, 0.8311200141906738, 0.8314399719238281, 0.8314399719238281, 0.833840012550354, 0.8315200209617615, 0.8312399983406067, 0.8326200246810913, 0.8317000269889832, 0.8347799777984619, 0.8335800170898438, 0.8314999938011169, 0.8317599892616272, 0.8344399929046631, 0.8325999975204468, 0.832360029220581, 0.8316199779510498, 0.8327000141143799, 0.8301399946212769, 0.8308200240135193, 0.8317999839782715, 0.8314399719238281, 0.8340200185775757, 0.8330000042915344, 0.8316599726676941, 0.8308600187301636, 0.8307999968528748, 0.8328800201416016, 0.8337799906730652, 0.8314200043678284, 0.8332800269126892, 0.8337399959564209, 0.8310199975967407, 0.833620011806488, 0.8303599953651428, 0.833620011806488, 0.8335400223731995, 0.8317400217056274, 0.8303800225257874, 0.8299599885940552, 0.8331599831581116, 0.8329200148582458, 0.83160001039505, 0.832319974899292, 0.8336399793624878, 0.8338199853897095, 0.8337399959564209, 0.8332200050354004, 0.8304799795150757, 0.8339599967002869, 0.8327199816703796, 0.83051997423172, 0.8333600163459778, 0.8325999975204468, 0.8322200179100037, 0.8325200080871582, 0.8337200284004211, 0.8318600058555603, 0.8326600193977356, 0.8307200074195862, 0.8335400223731995, 0.8344200253486633, 0.8334800004959106, 0.8339400291442871, 0.831059992313385, 0.8324199914932251, 0.8321400284767151, 0.83406001329422, 0.832099974155426, 0.8326200246810913, 0.8334199786186218, 0.831279993057251, 0.8350800275802612, 0.8323799967765808, 0.8326799869537354, 0.8334800004959106, 0.8326200246810913, 0.8330000042915344, 0.8356800079345703, 0.8353400230407715, 0.8339800238609314, 0.8327000141143799, 0.8316199779510498, 0.8353599905967712, 0.8341400027275085, 0.8324999809265137, 0.8344399929046631, 0.8333799839019775, 0.8324400186538696, 0.8323799967765808, 0.8338199853897095, 0.832859992980957, 0.8332399725914001, 0.8353800177574158, 0.8337200284004211, 0.8311399817466736, 0.834559977054596, 0.8370800018310547, 0.8325200080871582, 0.831820011138916, 0.8332399725914001], 'val_loss': [2.1263318061828613, 1.923344373703003, 1.858394742012024, 1.6521556377410889, 1.6150622367858887, 1.5183205604553223, 1.4819217920303345, 1.454342246055603, 1.3962891101837158, 1.3452030420303345, 1.3251197338104248, 1.3608704805374146, 1.2970329523086548, 1.2717665433883667, 1.2979469299316406, 1.2227818965911865, 1.2258789539337158, 1.2343424558639526, 1.204026222229004, 1.1901930570602417, 1.1703587770462036, 1.153584361076355, 1.2148737907409668, 1.149856686592102, 1.271299958229065, 1.1397324800491333, 1.1020151376724243, 1.1029881238937378, 1.0967010259628296, 1.0925363302230835, 1.073824167251587, 1.0590519905090332, 1.0678130388259888, 1.0383299589157104, 1.0374780893325806, 1.0539494752883911, 1.0846260786056519, 1.035934329032898, 1.0540876388549805, 1.0173922777175903, 1.0121359825134277, 1.037289023399353, 1.0248873233795166, 1.05206298828125, 1.0143378973007202, 0.9834777116775513, 0.9701321125030518, 0.9619793891906738, 0.9817314743995667, 0.9738993048667908, 0.975618839263916, 0.965740442276001, 0.9627698063850403, 0.9866406321525574, 0.9427779316902161, 0.934942364692688, 0.9469924569129944, 0.9592767357826233, 0.919814944267273, 0.9318797588348389, 0.9325029253959656, 0.9294478297233582, 0.955012321472168, 0.9117003083229065, 0.9157678484916687, 0.929668664932251, 0.9167068600654602, 0.9276211857795715, 0.8971923589706421, 0.9086577296257019, 0.8934442400932312, 0.9124355316162109, 0.8883565664291382, 0.9279448390007019, 0.9061273336410522, 0.9467019438743591, 0.8922932744026184, 0.8824641704559326, 0.8877260684967041, 0.8766424655914307, 0.8935751914978027, 0.8812373876571655, 0.863103985786438, 0.8761717081069946, 0.8905474543571472, 0.8745929598808289, 0.8846482634544373, 0.8754185438156128, 0.8593025207519531, 0.8490854501724243, 0.8805964589118958, 0.887744128704071, 0.8722176551818848, 0.92080157995224, 0.8794662952423096, 0.8801748156547546, 0.8448083996772766, 0.8459607362747192, 0.8661543130874634, 0.8958702087402344, 0.83894944190979, 0.8298655152320862, 0.8367167711257935, 0.8317911028862, 0.8373514413833618, 0.8361082077026367, 0.8279768824577332, 0.8337131142616272, 0.8522262573242188, 0.8241188526153564, 0.8325685262680054, 0.8425683379173279, 0.8365507125854492, 0.8208350539207458, 0.8300805687904358, 0.8177835941314697, 0.8230562210083008, 0.8338956236839294, 0.8207417130470276, 0.8393612504005432, 0.8389033079147339, 0.8213468790054321, 0.8405656218528748, 0.8256787061691284, 0.8166564106941223, 0.8207933306694031, 0.8277228474617004, 0.8280110359191895, 0.8244842886924744, 0.8188256621360779, 0.818935215473175, 0.8276914954185486, 0.8204301595687866, 0.8218346834182739, 0.8418649435043335, 0.8233129978179932, 0.8224853277206421, 0.8200646638870239, 0.8209081888198853, 0.8282530307769775, 0.8359076380729675, 0.8219468593597412, 0.8215846419334412, 0.828736424446106, 0.8202022314071655, 0.8523083925247192, 0.826316773891449, 0.8281624913215637, 0.819233775138855, 0.825387716293335, 0.8231450915336609, 0.8294102549552917, 0.819309651851654, 0.8453000783920288, 0.8193700909614563, 0.8158084750175476, 0.8230299949645996, 0.8156259655952454, 0.8181977272033691, 0.8280652165412903, 0.8431440591812134, 0.8452470898628235, 0.8403022289276123, 0.8407572507858276, 0.8194043040275574, 0.8639355301856995, 0.8160158395767212, 0.8143098950386047, 0.8230056762695312, 0.831224799156189, 0.8320510983467102, 0.8285366892814636, 0.8253235220909119, 0.8308833837509155, 0.8266108632087708, 0.8177734613418579, 0.819145917892456, 0.8382354378700256, 0.8183530569076538, 0.8194315433502197, 0.851572573184967, 0.8420044779777527, 0.829405665397644, 0.8315726518630981, 0.8313124775886536, 0.8321002721786499, 0.8268767595291138, 0.8222696185112, 0.8186771273612976, 0.8348371982574463, 0.8704029321670532, 0.8202261924743652, 0.8382449150085449, 0.8354605436325073, 0.8302791714668274, 0.8247263431549072, 0.8243386745452881, 0.8192697167396545, 0.8231804966926575, 0.841978907585144, 0.8193740248680115, 0.8173651695251465, 0.8211727738380432, 0.822723925113678, 0.816986083984375, 0.8173753023147583, 0.8158984184265137, 0.816468358039856, 0.8266529440879822, 0.8167165517807007, 0.8182640671730042, 0.8179771304130554, 0.8247549533843994, 0.8210801482200623, 0.8336039781570435, 0.8201667070388794, 0.8183918595314026, 0.825774610042572, 0.8146023154258728, 0.8312802910804749, 0.8273954391479492, 0.8254390358924866, 0.8219013810157776, 0.8284563422203064, 0.8268796801567078, 0.8283534049987793, 0.8139855265617371, 0.8190557956695557, 0.8154942989349365, 0.8221427798271179, 0.8185726404190063, 0.8263217806816101, 0.8243491053581238, 0.8241416811943054, 0.8227554559707642, 0.8220278024673462, 0.8270347714424133, 0.8246999979019165, 0.8289448022842407, 0.8235727548599243, 0.8211628198623657, 0.818328857421875, 0.8290908932685852, 0.8325650095939636, 0.8240063190460205, 0.8269203305244446, 0.8269481658935547, 0.8235975503921509, 0.8243622183799744, 0.818832278251648, 0.8258532285690308, 0.8161004185676575, 0.8241514563560486, 0.826082706451416, 0.8264432549476624, 0.8296911120414734, 0.8232179880142212, 0.819765031337738, 0.8211206793785095, 0.8274791240692139, 0.8312076330184937, 0.8217722773551941, 0.822133481502533, 0.8303216695785522, 0.8206794857978821, 0.8360939621925354, 0.8243178725242615, 0.8300857543945312, 0.8243601322174072, 0.8278143405914307, 0.827503502368927, 0.8309752941131592, 0.8199530243873596, 0.8277662992477417, 0.830520510673523, 0.825337290763855, 0.8228512406349182, 0.8289603590965271, 0.8323091864585876, 0.8290072083473206, 0.833182692527771, 0.8284843564033508, 0.8263779282569885, 0.8280335664749146, 0.8301595449447632, 0.8259937763214111, 0.8258414268493652, 0.8318369388580322, 0.8254490494728088, 0.8240081071853638, 0.8291898369789124, 0.8377338647842407, 0.8267177939414978, 0.8387553691864014, 0.8323630094528198, 0.8353343605995178, 0.830295205116272, 0.8264016509056091, 0.8272796869277954, 0.8351593613624573, 0.8311861157417297, 0.8345798850059509, 0.8278941512107849, 0.8363831043243408, 0.8271759748458862, 0.8345944285392761, 0.8288738131523132, 0.8333045840263367, 0.8419414758682251, 0.8355554938316345, 0.8245095610618591, 0.8320944309234619, 0.8394806385040283, 0.8363863229751587, 0.8284107446670532, 0.8311804533004761, 0.8310190439224243, 0.8306707739830017, 0.8308812379837036, 0.8341655135154724, 0.8298899531364441, 0.8343085646629333, 0.8371387720108032, 0.8308786153793335, 0.8359012603759766, 0.832363486289978, 0.8345061540603638, 0.8299285173416138, 0.8290137648582458, 0.8366523385047913, 0.8351655006408691, 0.8356416821479797, 0.8368048667907715, 0.8453898429870605, 0.8421909213066101, 0.8336308598518372, 0.8326721787452698, 0.8430966734886169, 0.8311302661895752, 0.8433120250701904, 0.8381512761116028, 0.8396915197372437, 0.8297843933105469, 0.8407676815986633, 0.8333114981651306, 0.8444744944572449, 0.8363155126571655, 0.835946261882782, 0.8392095565795898, 0.8370265364646912, 0.8373250961303711, 0.8340739011764526, 0.8389546871185303, 0.8361437320709229, 0.8398148417472839, 0.8423386812210083, 0.850823163986206, 0.8368300795555115, 0.8403815627098083, 0.8413821458816528, 0.8516620397567749, 0.8472555875778198, 0.8377878069877625, 0.8359359502792358, 0.8463916778564453, 0.8385618925094604, 0.8409359455108643, 0.8296172022819519, 0.8330422639846802, 0.8426389694213867, 0.8334638476371765, 0.8387388586997986, 0.8445954322814941, 0.832169234752655, 0.8410059809684753, 0.8401504755020142, 0.8420849442481995, 0.8500720858573914, 0.8409144282341003, 0.8465655446052551, 0.8551515340805054, 0.8475309610366821, 0.8366716504096985, 0.8472517728805542, 0.8473982214927673, 0.84035325050354, 0.8504341840744019, 0.8351846933364868, 0.8491885662078857, 0.8435347676277161, 0.8571975827217102, 0.8536032438278198, 0.8444125056266785, 0.8548097610473633, 0.8553884625434875, 0.8541262745857239, 0.8525756597518921, 0.8418574333190918, 0.8410277366638184, 0.8494327068328857, 0.8444495797157288, 0.8433305621147156, 0.8403211832046509, 0.8472163081169128, 0.8488055467605591, 0.8446928858757019, 0.847053587436676, 0.8464375734329224, 0.8437209129333496, 0.8416492938995361, 0.8438976407051086, 0.8427592515945435, 0.8394390344619751, 0.8493486046791077, 0.8438760638237, 0.8458201885223389, 0.8416824340820312, 0.8436970710754395, 0.8518875241279602, 0.8442388772964478, 0.8429425954818726, 0.8501163125038147, 0.8494885563850403, 0.8458741307258606, 0.8420552015304565, 0.8493806719779968, 0.8483594655990601, 0.8479553461074829, 0.8506624102592468, 0.8445948958396912, 0.8475975394248962, 0.8503627181053162, 0.8459987044334412, 0.8495544195175171, 0.8429949283599854, 0.846336841583252, 0.8420767784118652, 0.8475785851478577, 0.843014657497406, 0.8480440378189087, 0.8540364503860474, 0.8494107127189636, 0.8467829823493958, 0.850297749042511, 0.8504528999328613, 0.843894898891449, 0.8448333144187927, 0.8468855619430542, 0.8551190495491028, 0.8464300632476807, 0.8420624732971191, 0.8479439616203308, 0.8466491103172302, 0.8437515497207642, 0.8458505868911743, 0.8455830216407776, 0.8396881818771362, 0.8449041843414307, 0.8431372046470642, 0.8454715013504028, 0.8478981256484985, 0.8478649258613586, 0.8485224843025208, 0.8475529551506042, 0.8500233292579651, 0.848046600818634, 0.8448111414909363, 0.8480926752090454, 0.8461447954177856, 0.8563662171363831, 0.8504301905632019, 0.8486173748970032, 0.8477541208267212, 0.8481873273849487, 0.8553255796432495, 0.8453999757766724, 0.8437307476997375, 0.8471245169639587, 0.8518510460853577, 0.851338267326355, 0.8557054400444031, 0.8499463796615601, 0.8584997057914734, 0.8491591811180115, 0.8449010848999023, 0.8459770679473877, 0.8506590723991394, 0.8502270579338074, 0.849313497543335, 0.8496626019477844, 0.8508450388908386, 0.8570822477340698, 0.8495471477508545, 0.8542255759239197, 0.8573787212371826, 0.8537863492965698, 0.8504069447517395, 0.8511017560958862, 0.8552574515342712, 0.8581139445304871, 0.8507344722747803, 0.8622263669967651, 0.850945234298706, 0.855765700340271, 0.856665849685669, 0.8515915274620056, 0.8572039008140564, 0.8570786118507385, 0.8516843914985657, 0.8524800539016724, 0.8589575886726379, 0.8522813320159912, 0.8494629859924316, 0.8512798547744751, 0.8524149656295776, 0.8629716038703918, 0.8486606478691101, 0.8541571497917175, 0.8517507910728455, 0.8484401106834412, 0.8642368912696838, 0.8527109622955322, 0.857153594493866, 0.8603595495223999, 0.8545980453491211, 0.8575237393379211, 0.8524760603904724, 0.8569253087043762, 0.8537247180938721, 0.8542783260345459, 0.8548238277435303, 0.8566652536392212, 0.8473560810089111, 0.8574190139770508, 0.8563469648361206, 0.8628643751144409, 0.8558467030525208, 0.8595272302627563, 0.8536133766174316, 0.8527523279190063, 0.8540103435516357, 0.860659658908844, 0.857187807559967, 0.8571653366088867, 0.852321982383728, 0.8530787229537964, 0.8627577424049377, 0.8513706922531128, 0.8598194122314453, 0.8604409098625183, 0.858570396900177, 0.856741726398468, 0.8602935671806335, 0.8585088849067688, 0.8520327210426331, 0.8596804738044739, 0.8583922982215881, 0.855420708656311, 0.8643313646316528, 0.8547817468643188, 0.8546380996704102, 0.8526436686515808, 0.851665735244751, 0.8571003675460815, 0.8529468774795532, 0.861800491809845, 0.8571748733520508, 0.8541810512542725, 0.8513779044151306, 0.8595542907714844, 0.8628154397010803, 0.8555406332015991, 0.8572309613227844, 0.8546435832977295, 0.8605325222015381, 0.8592468500137329, 0.8606771230697632, 0.8583340048789978, 0.8590161204338074, 0.8636341691017151, 0.8600097894668579, 0.8631653189659119, 0.861808180809021, 0.8563479781150818, 0.8622735142707825, 0.8609304428100586, 0.8589072227478027, 0.8590140342712402, 0.857533872127533, 0.8598424792289734, 0.8592446446418762, 0.8598270416259766, 0.8577345609664917, 0.8651601672172546, 0.8583704233169556, 0.857074499130249, 0.8713845014572144, 0.8583639860153198, 0.8656101822853088, 0.8636884689331055, 0.8572881817817688, 0.8612386584281921, 0.8536381721496582, 0.8555510640144348, 0.8579295873641968, 0.8594582080841064, 0.8599937558174133, 0.8592042922973633, 0.8623631000518799, 0.8609958291053772, 0.8587687611579895, 0.8644464612007141, 0.8611249923706055, 0.8617308735847473, 0.8564860224723816, 0.8535932898521423, 0.8613870143890381, 0.8623493313789368, 0.8597953915596008, 0.8636317253112793, 0.8638871312141418, 0.8591580986976624, 0.8598027229309082, 0.8620175719261169, 0.8600592017173767, 0.8669883012771606, 0.8610662221908569, 0.8584120869636536, 0.8576032519340515, 0.8631482124328613, 0.8637953996658325, 0.8566089868545532, 0.8636643290519714, 0.862720787525177, 0.8573161959648132, 0.8604061603546143, 0.8614810705184937, 0.8611171841621399, 0.86871737241745, 0.8625757098197937, 0.8636441230773926, 0.8664624094963074, 0.8649059534072876, 0.8620643615722656, 0.8649767637252808, 0.8638632893562317, 0.8662707805633545, 0.8614884614944458, 0.8692148327827454, 0.86458420753479, 0.8647786378860474, 0.8708375692367554, 0.8676101565361023, 0.8686292767524719, 0.866413950920105, 0.8680738210678101, 0.8610523343086243, 0.8665604591369629, 0.8631300926208496, 0.8648666143417358, 0.8641796112060547, 0.8637599349021912, 0.860161304473877, 0.8642292022705078, 0.8635798096656799, 0.8650190234184265, 0.8628187775611877, 0.863456666469574, 0.87008136510849, 0.8659983277320862, 0.8685269355773926, 0.8691864013671875, 0.868661642074585, 0.8675360083580017, 0.8621219992637634, 0.8660995364189148, 0.868317186832428, 0.8601361513137817, 0.8601510524749756, 0.8700109124183655, 0.8655117154121399, 0.8736677765846252, 0.8642539978027344, 0.8667871952056885, 0.8714591860771179, 0.8694436550140381, 0.8656303882598877, 0.8661608695983887, 0.8667575120925903, 0.8619344830513, 0.8662034273147583, 0.8624935746192932, 0.8675430417060852, 0.8712167739868164, 0.8727248311042786, 0.8678997755050659, 0.8694121837615967, 0.872056245803833, 0.8709101676940918, 0.8681735396385193, 0.8697306513786316, 0.8654721975326538, 0.8651805520057678, 0.8643707036972046, 0.8641175031661987, 0.8662219047546387, 0.8652858138084412, 0.863696277141571, 0.8641435503959656, 0.8669291138648987, 0.8654694557189941, 0.8671430945396423, 0.869408369064331, 0.8643049597740173, 0.8642711043357849, 0.8650795817375183, 0.8674709796905518, 0.8621527552604675, 0.8655308485031128, 0.8661009669303894, 0.8657232522964478, 0.8621760010719299, 0.8676779270172119, 0.8679149150848389, 0.8668044209480286, 0.8681357502937317, 0.8676429390907288, 0.864565908908844, 0.865552544593811, 0.8631376028060913, 0.8645594716072083, 0.866266131401062, 0.8680689334869385, 0.8693116903305054, 0.8671343922615051, 0.8685269355773926, 0.8662620186805725, 0.8696693181991577, 0.8679789900779724, 0.8683731555938721, 0.8654544949531555, 0.8701667189598083, 0.8643282055854797, 0.8645484447479248, 0.8678226470947266, 0.8656972646713257, 0.8644618391990662, 0.8665137887001038, 0.8661031126976013, 0.8643217086791992, 0.8679255843162537, 0.8686190247535706, 0.8652945160865784, 0.8665215969085693, 0.8688033223152161, 0.865058183670044, 0.8661646246910095, 0.8675724864006042, 0.865520715713501, 0.8647273182868958, 0.8663010001182556, 0.8683688640594482, 0.8680566549301147, 0.8674117922782898, 0.8669089674949646, 0.8677793145179749, 0.8675130605697632, 0.8656057715415955, 0.8665483593940735, 0.8652344942092896, 0.8683491945266724, 0.8662322163581848, 0.8648872971534729, 0.8648408055305481, 0.8663886785507202, 0.8640684485435486, 0.8665673136711121, 0.8697804808616638, 0.866125762462616, 0.8695428967475891, 0.8652923107147217, 0.8686791062355042, 0.8688148260116577, 0.8633301854133606, 0.8682590126991272, 0.8692823052406311, 0.8670694231987, 0.8657118082046509, 0.8676326274871826, 0.867584764957428, 0.8695383667945862, 0.8681512475013733, 0.8695481419563293, 0.8633644580841064, 0.8679843544960022, 0.8697577118873596, 0.8707015514373779, 0.8699219822883606, 0.8666210770606995, 0.8683138489723206, 0.8709105253219604, 0.8664056658744812, 0.8669132590293884, 0.8674740195274353, 0.8662052750587463, 0.8688274621963501, 0.8674955368041992, 0.8680612444877625, 0.867240309715271, 0.8676737546920776, 0.8698253035545349, 0.8717063665390015, 0.8682844638824463, 0.8679974675178528, 0.8693087697029114, 0.8651540875434875, 0.8660178780555725, 0.8706803917884827, 0.864319920539856, 0.8688769340515137, 0.8699561357498169, 0.8703020215034485, 0.8690106272697449, 0.8725562691688538, 0.8701907396316528, 0.8693196177482605, 0.8668884038925171, 0.8678685426712036, 0.8688617944717407, 0.867683470249176, 0.8696134686470032, 0.8700451254844666, 0.8685382008552551, 0.8689179420471191, 0.8680196404457092, 0.8704543113708496, 0.8689689636230469, 0.8695993423461914, 0.8689730763435364, 0.8659710884094238, 0.8698955178260803, 0.8722217679023743, 0.8688659071922302, 0.8700226545333862, 0.8705453872680664, 0.8685407042503357, 0.8700119853019714, 0.874411940574646, 0.8718244433403015, 0.8703198432922363, 0.8709731698036194, 0.8676038980484009, 0.870686411857605, 0.8735253214836121, 0.8683249950408936, 0.8702628016471863, 0.8698083162307739, 0.8696111440658569, 0.8701967000961304, 0.8677961826324463, 0.8687108159065247, 0.8709768652915955, 0.8713085055351257, 0.8733428716659546, 0.8719315528869629, 0.8728639483451843, 0.8694915175437927, 0.8682758808135986, 0.8679066300392151, 0.8719653487205505, 0.8676800727844238, 0.8714128136634827, 0.8698707818984985, 0.8701078295707703, 0.8679463863372803, 0.8727167844772339, 0.8687812685966492, 0.8691504597663879, 0.8700588941574097, 0.8716164827346802, 0.8694054484367371, 0.8731475472450256, 0.8705183863639832, 0.8716947436332703, 0.8703992962837219, 0.8707447052001953, 0.8724499940872192, 0.8728811740875244, 0.8703001737594604, 0.8718582987785339, 0.871203601360321, 0.8735334873199463, 0.8714995980262756, 0.8698498010635376, 0.8687005639076233, 0.8707897663116455, 0.8718521595001221, 0.8691057562828064, 0.8704302906990051, 0.8740875720977783, 0.8719046711921692, 0.8709719777107239, 0.8724793195724487, 0.8698598742485046, 0.8720120191574097, 0.8716574907302856, 0.8712733387947083, 0.8692080974578857, 0.8684759736061096, 0.8692859411239624, 0.871192455291748, 0.8735843896865845, 0.8733667731285095, 0.8728790879249573, 0.8697352409362793, 0.8712781071662903, 0.8693232536315918, 0.8687278032302856, 0.8724342584609985, 0.8696741461753845, 0.8688985109329224, 0.8719511032104492, 0.871627151966095, 0.8714844584465027, 0.8698267340660095, 0.8725568652153015, 0.8663327097892761, 0.8713222742080688, 0.874182939529419, 0.873095691204071, 0.8727776408195496, 0.8716909289360046, 0.8722642660140991, 0.8691610097885132, 0.8714210987091064, 0.8718740344047546, 0.8734208941459656, 0.8727848529815674, 0.8703505992889404, 0.8722701072692871, 0.8720512986183167, 0.8752394318580627, 0.8720458745956421, 0.8709918856620789, 0.8734236359596252, 0.8718661069869995, 0.8726281523704529, 0.8733759522438049, 0.869513988494873, 0.8727987408638, 0.8737710118293762, 0.8706519603729248, 0.8688626885414124, 0.8730089068412781, 0.8731928467750549, 0.873124897480011, 0.8712888956069946, 0.8728318214416504, 0.8752796053886414, 0.8702148199081421, 0.8721420168876648, 0.8710867166519165, 0.8727198243141174, 0.8735281229019165, 0.8703579306602478, 0.8710191249847412, 0.8717736601829529, 0.8758264780044556, 0.8702147603034973, 0.8729084134101868, 0.8740222454071045, 0.8741980195045471, 0.8717265725135803, 0.8729211688041687, 0.8738582134246826, 0.8752338886260986, 0.8757318258285522, 0.8720836043357849, 0.8755837082862854, 0.871239185333252, 0.8754098415374756, 0.873235821723938, 0.876635730266571, 0.8759699463844299, 0.8757696151733398, 0.8716196417808533, 0.8758108615875244, 0.8743790984153748, 0.8740648627281189, 0.8768572211265564, 0.8763331174850464, 0.8772875070571899, 0.8749080300331116, 0.8748574256896973, 0.8761270642280579, 0.8737067580223083, 0.8758102655410767, 0.8745456337928772, 0.878091037273407, 0.8759095668792725], 'val_accuracy': [0.20319999754428864, 0.3098999857902527, 0.3294999897480011, 0.41339999437332153, 0.41769999265670776, 0.4440999925136566, 0.47040000557899475, 0.4779999852180481, 0.49559998512268066, 0.5152000188827515, 0.5254999995231628, 0.5138999819755554, 0.5353000164031982, 0.5450000166893005, 0.5371000170707703, 0.569599986076355, 0.5644000172615051, 0.5598999857902527, 0.5706999897956848, 0.5802000164985657, 0.5879999995231628, 0.5928000211715698, 0.573199987411499, 0.588100016117096, 0.5435000061988831, 0.604200005531311, 0.6152999997138977, 0.6092000007629395, 0.6105999946594238, 0.609000027179718, 0.6222000122070312, 0.6308000087738037, 0.6205000281333923, 0.6335999965667725, 0.6370999813079834, 0.6276000142097473, 0.6169000267982483, 0.6348999738693237, 0.6266000270843506, 0.6416000127792358, 0.6462000012397766, 0.6306999921798706, 0.6363000273704529, 0.625, 0.6432999968528748, 0.6539000272750854, 0.6590999960899353, 0.661899983882904, 0.6553000211715698, 0.6552000045776367, 0.6539999842643738, 0.6581000089645386, 0.6599000096321106, 0.6495000123977661, 0.6654999852180481, 0.6690999865531921, 0.6608999967575073, 0.6626999974250793, 0.673799991607666, 0.6675999760627747, 0.6700000166893005, 0.6690999865531921, 0.6606000065803528, 0.6797999739646912, 0.6747000217437744, 0.6762999892234802, 0.6780999898910522, 0.6708999872207642, 0.6847000122070312, 0.6786999702453613, 0.6872000098228455, 0.675599992275238, 0.6830000281333923, 0.6690000295639038, 0.6841999888420105, 0.6690999865531921, 0.6818000078201294, 0.6873000264167786, 0.6888999938964844, 0.6919000148773193, 0.6840999722480774, 0.6876999735832214, 0.694599986076355, 0.6912000179290771, 0.6898999810218811, 0.6901000142097473, 0.6880000233650208, 0.6905999779701233, 0.6956999897956848, 0.7006000280380249, 0.6916000247001648, 0.6841999888420105, 0.6926000118255615, 0.6744999885559082, 0.6919000148773193, 0.6947000026702881, 0.7059999704360962, 0.7045999765396118, 0.7008000016212463, 0.6858999729156494, 0.7059999704360962, 0.7092999815940857, 0.705299973487854, 0.7113000154495239, 0.7093999981880188, 0.7077000141143799, 0.7109000086784363, 0.7106000185012817, 0.7024000287055969, 0.711899995803833, 0.7075999975204468, 0.7074000239372253, 0.7105000019073486, 0.7128000259399414, 0.7103000283241272, 0.7131999731063843, 0.7172999978065491, 0.7124999761581421, 0.7156999707221985, 0.7121000289916992, 0.7106000185012817, 0.714900016784668, 0.710099995136261, 0.7164000272750854, 0.7171000242233276, 0.7170000076293945, 0.7156000137329102, 0.7117999792098999, 0.7160000205039978, 0.7170000076293945, 0.7166000008583069, 0.713699996471405, 0.7156000137329102, 0.7146999835968018, 0.7110000252723694, 0.7139000296592712, 0.7170000076293945, 0.7171000242233276, 0.7203999757766724, 0.7156000137329102, 0.7128000259399414, 0.7190999984741211, 0.717199981212616, 0.7143999934196472, 0.7174999713897705, 0.7050999999046326, 0.7156000137329102, 0.7129999995231628, 0.720300018787384, 0.717199981212616, 0.7204999923706055, 0.7177000045776367, 0.718999981880188, 0.7139999866485596, 0.7206000089645386, 0.7197999954223633, 0.718999981880188, 0.7199000120162964, 0.7203999757766724, 0.7174000144004822, 0.7103999853134155, 0.7121999859809875, 0.7132999897003174, 0.7149999737739563, 0.722100019454956, 0.7020000219345093, 0.7233999967575073, 0.7203999757766724, 0.7166000008583069, 0.7146999835968018, 0.7128999829292297, 0.7153000235557556, 0.7163000106811523, 0.7148000001907349, 0.7196000218391418, 0.7221999764442444, 0.7214000225067139, 0.7134000062942505, 0.7182999849319458, 0.7193999886512756, 0.7145000100135803, 0.7129999995231628, 0.7170000076293945, 0.7174999713897705, 0.7159000039100647, 0.7157999873161316, 0.7189000248908997, 0.718500018119812, 0.7192000150680542, 0.7167999744415283, 0.7063000202178955, 0.72079998254776, 0.7178999781608582, 0.7181000113487244, 0.7188000082969666, 0.720300018787384, 0.7181000113487244, 0.7192000150680542, 0.7228999733924866, 0.711899995803833, 0.7235999703407288, 0.7250999808311462, 0.7233999967575073, 0.7211999893188477, 0.7250999808311462, 0.7246000170707703, 0.7240999937057495, 0.7251999974250793, 0.7213000059127808, 0.7251999974250793, 0.722599983215332, 0.7250999808311462, 0.7214000225067139, 0.7222999930381775, 0.717199981212616, 0.7246000170707703, 0.7242000102996826, 0.7236999869346619, 0.7231000065803528, 0.7188000082969666, 0.7204999923706055, 0.7200999855995178, 0.723800003528595, 0.7193999886512756, 0.720300018787384, 0.7214000225067139, 0.7267000079154968, 0.7250000238418579, 0.7265999913215637, 0.7243000268936157, 0.7247999906539917, 0.7221999764442444, 0.7222999930381775, 0.7246000170707703, 0.7250000238418579, 0.7235000133514404, 0.7239000201225281, 0.7208999991416931, 0.7247999906539917, 0.722100019454956, 0.7235999703407288, 0.7250000238418579, 0.7196999788284302, 0.7197999954223633, 0.723800003528595, 0.720300018787384, 0.7218999862670898, 0.723800003528595, 0.7258999943733215, 0.7250000238418579, 0.7224000096321106, 0.724399983882904, 0.7214999794960022, 0.7258999943733215, 0.7210999727249146, 0.7224000096321106, 0.723800003528595, 0.7246000170707703, 0.7214999794960022, 0.7211999893188477, 0.72079998254776, 0.7231000065803528, 0.7254999876022339, 0.722000002861023, 0.7239999771118164, 0.7204999923706055, 0.724399983882904, 0.7211999893188477, 0.7211999893188477, 0.7232999801635742, 0.7228000164031982, 0.7204999923706055, 0.7261000275611877, 0.7233999967575073, 0.7236999869346619, 0.7218000292778015, 0.7247999906539917, 0.7233999967575073, 0.7208999991416931, 0.7228000164031982, 0.7200999855995178, 0.7228000164031982, 0.7246000170707703, 0.7225000262260437, 0.722000002861023, 0.7236999869346619, 0.7229999899864197, 0.7232999801635742, 0.7236999869346619, 0.7239999771118164, 0.7228000164031982, 0.7204999923706055, 0.7231000065803528, 0.7188000082969666, 0.7196999788284302, 0.7208999991416931, 0.7246000170707703, 0.7235000133514404, 0.7233999967575073, 0.7253999710083008, 0.7228999733924866, 0.7214000225067139, 0.7261000275611877, 0.7211999893188477, 0.7258999943733215, 0.7200000286102295, 0.7243000268936157, 0.7203999757766724, 0.7160999774932861, 0.722599983215332, 0.7233999967575073, 0.7218999862670898, 0.7178000211715698, 0.720300018787384, 0.7232999801635742, 0.7199000120162964, 0.7204999923706055, 0.7202000021934509, 0.722100019454956, 0.7232999801635742, 0.7213000059127808, 0.722599983215332, 0.72079998254776, 0.7257000207901001, 0.7218999862670898, 0.7239000201225281, 0.7239999771118164, 0.7233999967575073, 0.7214000225067139, 0.7202000021934509, 0.722000002861023, 0.7239999771118164, 0.722599983215332, 0.7202000021934509, 0.7202000021934509, 0.722100019454956, 0.7246000170707703, 0.7170000076293945, 0.7245000004768372, 0.7221999764442444, 0.7246999740600586, 0.7228000164031982, 0.7249000072479248, 0.7225000262260437, 0.7226999998092651, 0.7189000248908997, 0.7229999899864197, 0.7192999720573425, 0.7235000133514404, 0.718999981880188, 0.722000002861023, 0.7229999899864197, 0.7196000218391418, 0.7203999757766724, 0.7228999733924866, 0.7232999801635742, 0.7153000235557556, 0.7231000065803528, 0.7197999954223633, 0.7232000231742859, 0.7182999849319458, 0.7192000150680542, 0.7203999757766724, 0.7211999893188477, 0.7190999984741211, 0.7224000096321106, 0.7196999788284302, 0.7253999710083008, 0.7233999967575073, 0.7181000113487244, 0.7246000170707703, 0.7221999764442444, 0.7195000052452087, 0.7235999703407288, 0.7214000225067139, 0.7224000096321106, 0.7208999991416931, 0.7185999751091003, 0.7233999967575073, 0.720300018787384, 0.7192000150680542, 0.7231000065803528, 0.7202000021934509, 0.7225000262260437, 0.7200999855995178, 0.7207000255584717, 0.720300018787384, 0.7235000133514404, 0.7210000157356262, 0.7211999893188477, 0.7188000082969666, 0.7224000096321106, 0.7214999794960022, 0.7210000157356262, 0.7196000218391418, 0.7203999757766724, 0.718999981880188, 0.7225000262260437, 0.7228000164031982, 0.7233999967575073, 0.7229999899864197, 0.7235999703407288, 0.722100019454956, 0.7218999862670898, 0.7222999930381775, 0.7225000262260437, 0.7232000231742859, 0.7214999794960022, 0.7229999899864197, 0.7224000096321106, 0.7211999893188477, 0.7222999930381775, 0.7229999899864197, 0.7206000089645386, 0.7242000102996826, 0.7213000059127808, 0.7225000262260437, 0.7221999764442444, 0.7214999794960022, 0.7236999869346619, 0.7228999733924866, 0.722100019454956, 0.7203999757766724, 0.7240999937057495, 0.7236999869346619, 0.7217000126838684, 0.7207000255584717, 0.72079998254776, 0.7229999899864197, 0.7228000164031982, 0.7232999801635742, 0.7207000255584717, 0.7228000164031982, 0.7214999794960022, 0.7232999801635742, 0.7222999930381775, 0.723800003528595, 0.7224000096321106, 0.7250000238418579, 0.7215999960899353, 0.7192000150680542, 0.7222999930381775, 0.7245000004768372, 0.7226999998092651, 0.7208999991416931, 0.7226999998092651, 0.7239000201225281, 0.7245000004768372, 0.7192000150680542, 0.7246000170707703, 0.7250999808311462, 0.7221999764442444, 0.7239999771118164, 0.7228999733924866, 0.7228000164031982, 0.7210999727249146, 0.7272999882698059, 0.7224000096321106, 0.7246000170707703, 0.7245000004768372, 0.72079998254776, 0.723800003528595, 0.722000002861023, 0.7236999869346619, 0.72079998254776, 0.7213000059127808, 0.7254999876022339, 0.7232000231742859, 0.7218999862670898, 0.7179999947547913, 0.7199000120162964, 0.7245000004768372, 0.723800003528595, 0.7217000126838684, 0.7213000059127808, 0.72079998254776, 0.7218000292778015, 0.7228000164031982, 0.7215999960899353, 0.7211999893188477, 0.7195000052452087, 0.7222999930381775, 0.7222999930381775, 0.7228999733924866, 0.7240999937057495, 0.7251999974250793, 0.7253000140190125, 0.7250999808311462, 0.7229999899864197, 0.722100019454956, 0.7218000292778015, 0.7210999727249146, 0.7228999733924866, 0.720300018787384, 0.7215999960899353, 0.7203999757766724, 0.7203999757766724, 0.7215999960899353, 0.7196999788284302, 0.7185999751091003, 0.7208999991416931, 0.7232000231742859, 0.7224000096321106, 0.7204999923706055, 0.7213000059127808, 0.7218000292778015, 0.7206000089645386, 0.7206000089645386, 0.722000002861023, 0.7217000126838684, 0.7199000120162964, 0.7235000133514404, 0.722599983215332, 0.7218000292778015, 0.7233999967575073, 0.7174999713897705, 0.7228000164031982, 0.7200999855995178, 0.7218000292778015, 0.7232999801635742, 0.7182999849319458, 0.722100019454956, 0.7200000286102295, 0.7218999862670898, 0.7240999937057495, 0.7211999893188477, 0.7246999740600586, 0.7214000225067139, 0.7208999991416931, 0.7239000201225281, 0.7228999733924866, 0.7225000262260437, 0.7245000004768372, 0.722000002861023, 0.7228999733924866, 0.7214999794960022, 0.7239000201225281, 0.7214999794960022, 0.7251999974250793, 0.7229999899864197, 0.7232000231742859, 0.7213000059127808, 0.7207000255584717, 0.7239999771118164, 0.7231000065803528, 0.7239000201225281, 0.7222999930381775, 0.7210999727249146, 0.7214999794960022, 0.7210000157356262, 0.7226999998092651, 0.722100019454956, 0.7202000021934509, 0.7231000065803528, 0.7214000225067139, 0.720300018787384, 0.7214999794960022, 0.722599983215332, 0.7196999788284302, 0.7224000096321106, 0.7239999771118164, 0.7228999733924866, 0.7225000262260437, 0.7210999727249146, 0.7214999794960022, 0.7204999923706055, 0.7218000292778015, 0.7226999998092651, 0.7232000231742859, 0.722100019454956, 0.7218000292778015, 0.7197999954223633, 0.7218999862670898, 0.7231000065803528, 0.7197999954223633, 0.722100019454956, 0.7210000157356262, 0.722100019454956, 0.7232999801635742, 0.7214999794960022, 0.7229999899864197, 0.7196999788284302, 0.722000002861023, 0.7242000102996826, 0.7226999998092651, 0.7221999764442444, 0.7222999930381775, 0.7214000225067139, 0.7257000207901001, 0.7233999967575073, 0.7242000102996826, 0.7221999764442444, 0.7251999974250793, 0.7203999757766724, 0.7214999794960022, 0.7232000231742859, 0.7185999751091003, 0.7210000157356262, 0.7228999733924866, 0.7210000157356262, 0.7217000126838684, 0.7210000157356262, 0.7233999967575073, 0.7206000089645386, 0.7199000120162964, 0.722599983215332, 0.7228999733924866, 0.7214999794960022, 0.7215999960899353, 0.7218000292778015, 0.7245000004768372, 0.7233999967575073, 0.7215999960899353, 0.72079998254776, 0.7218999862670898, 0.7247999906539917, 0.7222999930381775, 0.7202000021934509, 0.7225000262260437, 0.7225000262260437, 0.7222999930381775, 0.7218999862670898, 0.7247999906539917, 0.7229999899864197, 0.7239999771118164, 0.7203999757766724, 0.7217000126838684, 0.7204999923706055, 0.7233999967575073, 0.7232000231742859, 0.7242000102996826, 0.7228000164031982, 0.7226999998092651, 0.7222999930381775, 0.722100019454956, 0.722599983215332, 0.7235999703407288, 0.7229999899864197, 0.7214000225067139, 0.7235000133514404, 0.7228999733924866, 0.7228999733924866, 0.7235999703407288, 0.7221999764442444, 0.7228999733924866, 0.722599983215332, 0.7218000292778015, 0.7236999869346619, 0.7240999937057495, 0.7239999771118164, 0.722599983215332, 0.7228000164031982, 0.7229999899864197, 0.7276999950408936, 0.7239999771118164, 0.7228000164031982, 0.7232000231742859, 0.7245000004768372, 0.7233999967575073, 0.7232999801635742, 0.7225000262260437, 0.7249000072479248, 0.7228999733924866, 0.7261000275611877, 0.7228999733924866, 0.7228000164031982, 0.7232000231742859, 0.7224000096321106, 0.7204999923706055, 0.7236999869346619, 0.7224000096321106, 0.7235000133514404, 0.7224000096321106, 0.7215999960899353, 0.7246000170707703, 0.7228999733924866, 0.7228999733924866, 0.7251999974250793, 0.7242000102996826, 0.7195000052452087, 0.7225000262260437, 0.7224000096321106, 0.7239999771118164, 0.7229999899864197, 0.7203999757766724, 0.7232000231742859, 0.7245000004768372, 0.7242000102996826, 0.7239999771118164, 0.7235999703407288, 0.7232000231742859, 0.7232000231742859, 0.7260000109672546, 0.7232999801635742, 0.722100019454956, 0.7240999937057495, 0.7232999801635742, 0.723800003528595, 0.7229999899864197, 0.7245000004768372, 0.723800003528595, 0.7246000170707703, 0.7242000102996826, 0.7249000072479248, 0.7246999740600586, 0.7261999845504761, 0.7243000268936157, 0.7243000268936157, 0.724399983882904, 0.7243000268936157, 0.7246999740600586, 0.7218999862670898, 0.7245000004768372, 0.7245000004768372, 0.7236999869346619, 0.7243000268936157, 0.7240999937057495, 0.7253999710083008, 0.7253999710083008, 0.7257999777793884, 0.7232000231742859, 0.7264000177383423, 0.7233999967575073, 0.7242000102996826, 0.7246999740600586, 0.7250999808311462, 0.7251999974250793, 0.7254999876022339, 0.7261999845504761, 0.7253000140190125, 0.7246000170707703, 0.7245000004768372, 0.7243000268936157, 0.7254999876022339, 0.7239000201225281, 0.7250000238418579, 0.7250999808311462, 0.7246000170707703, 0.7232000231742859, 0.7246999740600586, 0.7257000207901001, 0.723800003528595, 0.7257000207901001, 0.7250999808311462, 0.7258999943733215, 0.7242000102996826, 0.7268000245094299, 0.7239000201225281, 0.7235999703407288, 0.7239999771118164, 0.7242000102996826, 0.7242000102996826, 0.7258999943733215, 0.7253999710083008, 0.724399983882904, 0.7245000004768372, 0.7239000201225281, 0.7264000177383423, 0.7251999974250793, 0.7247999906539917, 0.7249000072479248, 0.7260000109672546, 0.7240999937057495, 0.7249000072479248, 0.7250000238418579, 0.7232000231742859, 0.7249000072479248, 0.7254999876022339, 0.7246999740600586, 0.7236999869346619, 0.7247999906539917, 0.7247999906539917, 0.725600004196167, 0.725600004196167, 0.7267000079154968, 0.725600004196167, 0.7253999710083008, 0.7253999710083008, 0.7239999771118164, 0.7236999869346619, 0.7250999808311462, 0.7246999740600586, 0.7242000102996826, 0.7264000177383423, 0.7239999771118164, 0.7243000268936157, 0.7239000201225281, 0.7251999974250793, 0.725600004196167, 0.7245000004768372, 0.7236999869346619, 0.7232999801635742, 0.7232999801635742, 0.7257999777793884, 0.7254999876022339, 0.7254999876022339, 0.7260000109672546, 0.7251999974250793, 0.7247999906539917, 0.7236999869346619, 0.724399983882904, 0.7249000072479248, 0.7236999869346619, 0.725600004196167, 0.7250999808311462, 0.7226999998092651, 0.723800003528595, 0.7249000072479248, 0.7257000207901001, 0.7242000102996826, 0.7260000109672546, 0.7239999771118164, 0.7246999740600586, 0.7239999771118164, 0.7251999974250793, 0.7260000109672546, 0.7253000140190125, 0.7233999967575073, 0.725600004196167, 0.7246999740600586, 0.724399983882904, 0.7253999710083008, 0.724399983882904, 0.7263000011444092, 0.7247999906539917, 0.7251999974250793, 0.7263000011444092, 0.7243000268936157, 0.724399983882904, 0.723800003528595, 0.722599983215332, 0.7225000262260437, 0.7251999974250793, 0.7250000238418579, 0.723800003528595, 0.7226999998092651, 0.7240999937057495, 0.7246999740600586, 0.7247999906539917, 0.7247999906539917, 0.7239000201225281, 0.7235999703407288, 0.7253999710083008, 0.7260000109672546, 0.7232999801635742, 0.722599983215332, 0.7239999771118164, 0.7226999998092651, 0.7239999771118164, 0.7251999974250793, 0.7246999740600586, 0.724399983882904, 0.7242000102996826, 0.7246000170707703, 0.725600004196167, 0.7239999771118164, 0.723800003528595, 0.7257999777793884, 0.7246000170707703, 0.7250999808311462, 0.7232999801635742, 0.7236999869346619, 0.7240999937057495, 0.7224000096321106, 0.7232000231742859, 0.7232000231742859, 0.7249000072479248, 0.7268000245094299, 0.7250999808311462, 0.7245000004768372, 0.7257999777793884, 0.7232999801635742, 0.7247999906539917, 0.7250000238418579, 0.7250000238418579, 0.7257999777793884, 0.7251999974250793, 0.7253999710083008, 0.7261000275611877, 0.7257000207901001, 0.7261000275611877, 0.724399983882904, 0.723800003528595, 0.7250000238418579, 0.7228999733924866, 0.7261999845504761, 0.7239999771118164, 0.7245000004768372, 0.7251999974250793, 0.7253000140190125, 0.7250000238418579, 0.7243000268936157, 0.7239000201225281, 0.7242000102996826, 0.7250999808311462, 0.7257999777793884, 0.725600004196167, 0.7242000102996826, 0.7240999937057495, 0.7249000072479248, 0.7239000201225281, 0.7257999777793884, 0.7245000004768372, 0.7246999740600586, 0.7257999777793884, 0.7264999747276306, 0.7251999974250793, 0.724399983882904, 0.7258999943733215, 0.7265999913215637, 0.7261999845504761, 0.7247999906539917, 0.7228999733924866, 0.7265999913215637, 0.723800003528595, 0.7229999899864197, 0.7261000275611877, 0.7253000140190125, 0.723800003528595, 0.7246000170707703, 0.7247999906539917, 0.7232999801635742, 0.7246000170707703, 0.725600004196167, 0.7249000072479248, 0.7254999876022339, 0.7246000170707703, 0.7246000170707703, 0.7247999906539917, 0.7250999808311462, 0.7246000170707703, 0.7235999703407288, 0.7242000102996826, 0.7261000275611877, 0.7254999876022339, 0.7239000201225281, 0.7247999906539917, 0.7246000170707703, 0.7254999876022339, 0.7257000207901001, 0.7231000065803528, 0.7222999930381775, 0.7245000004768372, 0.7242000102996826, 0.7245000004768372, 0.7254999876022339, 0.7269999980926514, 0.7240999937057495, 0.7261000275611877, 0.7264000177383423, 0.7239999771118164, 0.7245000004768372, 0.7253999710083008, 0.7233999967575073, 0.7246000170707703, 0.7239999771118164, 0.7249000072479248, 0.7240999937057495, 0.7247999906539917, 0.7251999974250793, 0.7257999777793884, 0.7245000004768372, 0.724399983882904, 0.7250999808311462, 0.7239999771118164, 0.7253000140190125, 0.7246000170707703, 0.724399983882904, 0.7257999777793884, 0.7232000231742859, 0.7264999747276306, 0.7240999937057495, 0.7245000004768372, 0.7265999913215637, 0.7251999974250793, 0.7235000133514404, 0.7225000262260437, 0.7254999876022339, 0.7246000170707703, 0.7239000201225281, 0.7250999808311462, 0.7239999771118164, 0.722599983215332, 0.7228000164031982, 0.7251999974250793, 0.7235999703407288, 0.7249000072479248, 0.7253999710083008, 0.7240999937057495, 0.7253000140190125, 0.725600004196167, 0.7240999937057495, 0.7246000170707703, 0.7239000201225281, 0.7242000102996826, 0.7246000170707703, 0.7242000102996826, 0.7250000238418579, 0.7249000072479248, 0.7247999906539917], 'lr': [0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]}\n"
          ]
        }
      ]
    }
  ]
}