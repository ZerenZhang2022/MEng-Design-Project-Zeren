{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1sLDxOgbykC",
        "outputId": "b45ec7b7-946d-4c9c-9c07-818719f028a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_gZ8miyVENF",
        "outputId": "ec251258-c8d6-4a72-b445-51dc95e33bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "391/391 [==============================] - 4s 8ms/step - loss: 4.6043 - accuracy: 0.0106 - val_loss: 4.6013 - val_accuracy: 0.0121 - lr: 0.0200\n",
            "Epoch 2/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 4.5960 - accuracy: 0.0130 - val_loss: 4.5842 - val_accuracy: 0.0173 - lr: 0.0200\n",
            "Epoch 3/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 4.5496 - accuracy: 0.0185 - val_loss: 4.4950 - val_accuracy: 0.0248 - lr: 0.0200\n",
            "Epoch 4/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 4.4449 - accuracy: 0.0273 - val_loss: 4.3524 - val_accuracy: 0.0346 - lr: 0.0200\n",
            "Epoch 5/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 4.2791 - accuracy: 0.0421 - val_loss: 4.1837 - val_accuracy: 0.0558 - lr: 0.0200\n",
            "Epoch 6/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 4.1635 - accuracy: 0.0590 - val_loss: 4.1417 - val_accuracy: 0.0654 - lr: 0.0200\n",
            "Epoch 7/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 4.0876 - accuracy: 0.0722 - val_loss: 4.0419 - val_accuracy: 0.0817 - lr: 0.0200\n",
            "Epoch 8/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 4.0200 - accuracy: 0.0833 - val_loss: 3.9487 - val_accuracy: 0.0964 - lr: 0.0200\n",
            "Epoch 9/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.9525 - accuracy: 0.0924 - val_loss: 3.9037 - val_accuracy: 0.0971 - lr: 0.0200\n",
            "Epoch 10/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.8912 - accuracy: 0.1012 - val_loss: 3.8394 - val_accuracy: 0.1118 - lr: 0.0200\n",
            "Epoch 11/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 3.8455 - accuracy: 0.1111 - val_loss: 3.7892 - val_accuracy: 0.1264 - lr: 0.0200\n",
            "Epoch 12/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.8015 - accuracy: 0.1186 - val_loss: 3.7699 - val_accuracy: 0.1294 - lr: 0.0200\n",
            "Epoch 13/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 3.7646 - accuracy: 0.1254 - val_loss: 3.7097 - val_accuracy: 0.1387 - lr: 0.0200\n",
            "Epoch 14/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.7262 - accuracy: 0.1341 - val_loss: 3.6703 - val_accuracy: 0.1446 - lr: 0.0200\n",
            "Epoch 15/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.6866 - accuracy: 0.1380 - val_loss: 3.6746 - val_accuracy: 0.1479 - lr: 0.0200\n",
            "Epoch 16/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.6432 - accuracy: 0.1471 - val_loss: 3.6005 - val_accuracy: 0.1603 - lr: 0.0200\n",
            "Epoch 17/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.5920 - accuracy: 0.1552 - val_loss: 3.5165 - val_accuracy: 0.1771 - lr: 0.0200\n",
            "Epoch 18/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.5420 - accuracy: 0.1630 - val_loss: 3.4946 - val_accuracy: 0.1816 - lr: 0.0200\n",
            "Epoch 19/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.5054 - accuracy: 0.1720 - val_loss: 3.4263 - val_accuracy: 0.1925 - lr: 0.0200\n",
            "Epoch 20/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.4582 - accuracy: 0.1780 - val_loss: 3.4122 - val_accuracy: 0.1961 - lr: 0.0200\n",
            "Epoch 21/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 3.4214 - accuracy: 0.1849 - val_loss: 3.3758 - val_accuracy: 0.1992 - lr: 0.0200\n",
            "Epoch 22/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 3.3830 - accuracy: 0.1927 - val_loss: 3.3356 - val_accuracy: 0.2067 - lr: 0.0200\n",
            "Epoch 23/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.3505 - accuracy: 0.1953 - val_loss: 3.3154 - val_accuracy: 0.2100 - lr: 0.0200\n",
            "Epoch 24/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.3189 - accuracy: 0.2030 - val_loss: 3.2415 - val_accuracy: 0.2244 - lr: 0.0200\n",
            "Epoch 25/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.2873 - accuracy: 0.2084 - val_loss: 3.2163 - val_accuracy: 0.2257 - lr: 0.0200\n",
            "Epoch 26/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 3.2581 - accuracy: 0.2131 - val_loss: 3.1944 - val_accuracy: 0.2313 - lr: 0.0200\n",
            "Epoch 27/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.2252 - accuracy: 0.2185 - val_loss: 3.1748 - val_accuracy: 0.2393 - lr: 0.0200\n",
            "Epoch 28/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 3.1993 - accuracy: 0.2225 - val_loss: 3.1336 - val_accuracy: 0.2445 - lr: 0.0200\n",
            "Epoch 29/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.1740 - accuracy: 0.2266 - val_loss: 3.1161 - val_accuracy: 0.2471 - lr: 0.0200\n",
            "Epoch 30/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.1492 - accuracy: 0.2325 - val_loss: 3.0903 - val_accuracy: 0.2515 - lr: 0.0200\n",
            "Epoch 31/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.1273 - accuracy: 0.2368 - val_loss: 3.0695 - val_accuracy: 0.2551 - lr: 0.0200\n",
            "Epoch 32/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.0962 - accuracy: 0.2429 - val_loss: 3.0746 - val_accuracy: 0.2551 - lr: 0.0200\n",
            "Epoch 33/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.0801 - accuracy: 0.2458 - val_loss: 3.0337 - val_accuracy: 0.2617 - lr: 0.0200\n",
            "Epoch 34/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.0560 - accuracy: 0.2496 - val_loss: 3.0258 - val_accuracy: 0.2669 - lr: 0.0200\n",
            "Epoch 35/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 3.0336 - accuracy: 0.2545 - val_loss: 3.0166 - val_accuracy: 0.2682 - lr: 0.0200\n",
            "Epoch 36/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.0180 - accuracy: 0.2560 - val_loss: 3.0178 - val_accuracy: 0.2666 - lr: 0.0200\n",
            "Epoch 37/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 3.0011 - accuracy: 0.2618 - val_loss: 2.9552 - val_accuracy: 0.2785 - lr: 0.0200\n",
            "Epoch 38/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.9744 - accuracy: 0.2649 - val_loss: 2.9320 - val_accuracy: 0.2804 - lr: 0.0200\n",
            "Epoch 39/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.9649 - accuracy: 0.2695 - val_loss: 2.9177 - val_accuracy: 0.2854 - lr: 0.0200\n",
            "Epoch 40/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.9421 - accuracy: 0.2729 - val_loss: 2.9078 - val_accuracy: 0.2884 - lr: 0.0200\n",
            "Epoch 41/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.9236 - accuracy: 0.2769 - val_loss: 2.8970 - val_accuracy: 0.2861 - lr: 0.0200\n",
            "Epoch 42/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.9129 - accuracy: 0.2797 - val_loss: 2.9246 - val_accuracy: 0.2898 - lr: 0.0200\n",
            "Epoch 43/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.8979 - accuracy: 0.2823 - val_loss: 2.8610 - val_accuracy: 0.2957 - lr: 0.0200\n",
            "Epoch 44/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.8828 - accuracy: 0.2865 - val_loss: 2.8638 - val_accuracy: 0.2953 - lr: 0.0200\n",
            "Epoch 45/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.8690 - accuracy: 0.2867 - val_loss: 2.8795 - val_accuracy: 0.2927 - lr: 0.0200\n",
            "Epoch 46/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.8552 - accuracy: 0.2896 - val_loss: 2.8304 - val_accuracy: 0.2993 - lr: 0.0200\n",
            "Epoch 47/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.8413 - accuracy: 0.2933 - val_loss: 2.8261 - val_accuracy: 0.3015 - lr: 0.0200\n",
            "Epoch 48/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.8231 - accuracy: 0.2958 - val_loss: 2.8383 - val_accuracy: 0.3061 - lr: 0.0200\n",
            "Epoch 49/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.8102 - accuracy: 0.2998 - val_loss: 2.8276 - val_accuracy: 0.2998 - lr: 0.0200\n",
            "Epoch 50/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.7973 - accuracy: 0.3032 - val_loss: 2.7924 - val_accuracy: 0.3100 - lr: 0.0200\n",
            "Epoch 51/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.7906 - accuracy: 0.3065 - val_loss: 2.7957 - val_accuracy: 0.3088 - lr: 0.0200\n",
            "Epoch 52/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.7745 - accuracy: 0.3082 - val_loss: 2.7655 - val_accuracy: 0.3165 - lr: 0.0200\n",
            "Epoch 53/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.7621 - accuracy: 0.3098 - val_loss: 2.8148 - val_accuracy: 0.3124 - lr: 0.0200\n",
            "Epoch 54/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.7466 - accuracy: 0.3110 - val_loss: 2.7974 - val_accuracy: 0.3091 - lr: 0.0200\n",
            "Epoch 55/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.7382 - accuracy: 0.3121 - val_loss: 2.7907 - val_accuracy: 0.3131 - lr: 0.0200\n",
            "Epoch 56/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.7265 - accuracy: 0.3160 - val_loss: 2.7372 - val_accuracy: 0.3201 - lr: 0.0200\n",
            "Epoch 57/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.7198 - accuracy: 0.3193 - val_loss: 2.7308 - val_accuracy: 0.3176 - lr: 0.0200\n",
            "Epoch 58/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.7081 - accuracy: 0.3207 - val_loss: 2.7371 - val_accuracy: 0.3259 - lr: 0.0200\n",
            "Epoch 59/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.6978 - accuracy: 0.3217 - val_loss: 2.7344 - val_accuracy: 0.3200 - lr: 0.0200\n",
            "Epoch 60/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.6887 - accuracy: 0.3217 - val_loss: 2.7285 - val_accuracy: 0.3248 - lr: 0.0200\n",
            "Epoch 61/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.6798 - accuracy: 0.3255 - val_loss: 2.6952 - val_accuracy: 0.3339 - lr: 0.0200\n",
            "Epoch 62/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.6717 - accuracy: 0.3303 - val_loss: 2.7107 - val_accuracy: 0.3259 - lr: 0.0200\n",
            "Epoch 63/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.6608 - accuracy: 0.3280 - val_loss: 2.6966 - val_accuracy: 0.3310 - lr: 0.0200\n",
            "Epoch 64/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.6525 - accuracy: 0.3313 - val_loss: 2.6834 - val_accuracy: 0.3322 - lr: 0.0200\n",
            "Epoch 65/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.6388 - accuracy: 0.3344 - val_loss: 2.6801 - val_accuracy: 0.3338 - lr: 0.0200\n",
            "Epoch 66/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.6364 - accuracy: 0.3337 - val_loss: 2.6781 - val_accuracy: 0.3327 - lr: 0.0200\n",
            "Epoch 67/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.6243 - accuracy: 0.3405 - val_loss: 2.6714 - val_accuracy: 0.3380 - lr: 0.0200\n",
            "Epoch 68/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.6156 - accuracy: 0.3379 - val_loss: 2.6704 - val_accuracy: 0.3339 - lr: 0.0200\n",
            "Epoch 69/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.6073 - accuracy: 0.3417 - val_loss: 2.6917 - val_accuracy: 0.3326 - lr: 0.0200\n",
            "Epoch 70/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.5989 - accuracy: 0.3442 - val_loss: 2.6694 - val_accuracy: 0.3355 - lr: 0.0200\n",
            "Epoch 71/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.5953 - accuracy: 0.3435 - val_loss: 2.6523 - val_accuracy: 0.3401 - lr: 0.0200\n",
            "Epoch 72/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.5827 - accuracy: 0.3463 - val_loss: 2.6785 - val_accuracy: 0.3318 - lr: 0.0200\n",
            "Epoch 73/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.5741 - accuracy: 0.3461 - val_loss: 2.6657 - val_accuracy: 0.3401 - lr: 0.0200\n",
            "Epoch 74/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.5673 - accuracy: 0.3465 - val_loss: 2.7065 - val_accuracy: 0.3241 - lr: 0.0200\n",
            "Epoch 75/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.5581 - accuracy: 0.3508 - val_loss: 2.6335 - val_accuracy: 0.3430 - lr: 0.0200\n",
            "Epoch 76/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.5591 - accuracy: 0.3484 - val_loss: 2.6225 - val_accuracy: 0.3432 - lr: 0.0200\n",
            "Epoch 77/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.5486 - accuracy: 0.3524 - val_loss: 2.6137 - val_accuracy: 0.3491 - lr: 0.0200\n",
            "Epoch 78/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.5399 - accuracy: 0.3523 - val_loss: 2.6158 - val_accuracy: 0.3479 - lr: 0.0200\n",
            "Epoch 79/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.5339 - accuracy: 0.3566 - val_loss: 2.6133 - val_accuracy: 0.3475 - lr: 0.0200\n",
            "Epoch 80/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.5274 - accuracy: 0.3565 - val_loss: 2.6556 - val_accuracy: 0.3382 - lr: 0.0200\n",
            "Epoch 81/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.5210 - accuracy: 0.3569 - val_loss: 2.6053 - val_accuracy: 0.3507 - lr: 0.0200\n",
            "Epoch 82/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.5115 - accuracy: 0.3587 - val_loss: 2.6366 - val_accuracy: 0.3433 - lr: 0.0200\n",
            "Epoch 83/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.5075 - accuracy: 0.3592 - val_loss: 2.6076 - val_accuracy: 0.3492 - lr: 0.0200\n",
            "Epoch 84/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4953 - accuracy: 0.3637 - val_loss: 2.6036 - val_accuracy: 0.3500 - lr: 0.0200\n",
            "Epoch 85/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.4961 - accuracy: 0.3638 - val_loss: 2.5883 - val_accuracy: 0.3485 - lr: 0.0200\n",
            "Epoch 86/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.4920 - accuracy: 0.3648 - val_loss: 2.5992 - val_accuracy: 0.3515 - lr: 0.0200\n",
            "Epoch 87/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4832 - accuracy: 0.3644 - val_loss: 2.6091 - val_accuracy: 0.3451 - lr: 0.0200\n",
            "Epoch 88/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4761 - accuracy: 0.3668 - val_loss: 2.5944 - val_accuracy: 0.3479 - lr: 0.0200\n",
            "Epoch 89/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4714 - accuracy: 0.3669 - val_loss: 2.5863 - val_accuracy: 0.3539 - lr: 0.0200\n",
            "Epoch 90/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4621 - accuracy: 0.3694 - val_loss: 2.6032 - val_accuracy: 0.3463 - lr: 0.0200\n",
            "Epoch 91/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4637 - accuracy: 0.3693 - val_loss: 2.5665 - val_accuracy: 0.3554 - lr: 0.0200\n",
            "Epoch 92/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4509 - accuracy: 0.3701 - val_loss: 2.5935 - val_accuracy: 0.3511 - lr: 0.0200\n",
            "Epoch 93/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.4480 - accuracy: 0.3711 - val_loss: 2.5694 - val_accuracy: 0.3529 - lr: 0.0200\n",
            "Epoch 94/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4393 - accuracy: 0.3751 - val_loss: 2.5508 - val_accuracy: 0.3567 - lr: 0.0200\n",
            "Epoch 95/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.4340 - accuracy: 0.3741 - val_loss: 2.5455 - val_accuracy: 0.3604 - lr: 0.0200\n",
            "Epoch 96/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4341 - accuracy: 0.3737 - val_loss: 2.6107 - val_accuracy: 0.3488 - lr: 0.0200\n",
            "Epoch 97/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4260 - accuracy: 0.3765 - val_loss: 2.5668 - val_accuracy: 0.3554 - lr: 0.0200\n",
            "Epoch 98/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4231 - accuracy: 0.3809 - val_loss: 2.5267 - val_accuracy: 0.3670 - lr: 0.0200\n",
            "Epoch 99/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.4146 - accuracy: 0.3777 - val_loss: 2.5553 - val_accuracy: 0.3578 - lr: 0.0200\n",
            "Epoch 100/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4102 - accuracy: 0.3806 - val_loss: 2.5424 - val_accuracy: 0.3640 - lr: 0.0200\n",
            "Epoch 101/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3662 - accuracy: 0.3895 - val_loss: 2.5340 - val_accuracy: 0.3654 - lr: 0.0100\n",
            "Epoch 102/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3566 - accuracy: 0.3925 - val_loss: 2.5082 - val_accuracy: 0.3704 - lr: 0.0100\n",
            "Epoch 103/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3562 - accuracy: 0.3943 - val_loss: 2.5267 - val_accuracy: 0.3677 - lr: 0.0100\n",
            "Epoch 104/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.3487 - accuracy: 0.3933 - val_loss: 2.5159 - val_accuracy: 0.3658 - lr: 0.0100\n",
            "Epoch 105/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.3449 - accuracy: 0.3955 - val_loss: 2.5001 - val_accuracy: 0.3693 - lr: 0.0100\n",
            "Epoch 106/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.3488 - accuracy: 0.3938 - val_loss: 2.4896 - val_accuracy: 0.3730 - lr: 0.0100\n",
            "Epoch 107/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.3430 - accuracy: 0.3943 - val_loss: 2.4970 - val_accuracy: 0.3711 - lr: 0.0100\n",
            "Epoch 108/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.3397 - accuracy: 0.3961 - val_loss: 2.5203 - val_accuracy: 0.3690 - lr: 0.0100\n",
            "Epoch 109/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.3316 - accuracy: 0.3968 - val_loss: 2.4847 - val_accuracy: 0.3730 - lr: 0.0100\n",
            "Epoch 110/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.3345 - accuracy: 0.3946 - val_loss: 2.4965 - val_accuracy: 0.3689 - lr: 0.0100\n",
            "Epoch 111/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3351 - accuracy: 0.3971 - val_loss: 2.4900 - val_accuracy: 0.3711 - lr: 0.0100\n",
            "Epoch 112/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.3317 - accuracy: 0.3979 - val_loss: 2.4910 - val_accuracy: 0.3751 - lr: 0.0100\n",
            "Epoch 113/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3284 - accuracy: 0.3973 - val_loss: 2.4964 - val_accuracy: 0.3693 - lr: 0.0100\n",
            "Epoch 114/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3232 - accuracy: 0.3994 - val_loss: 2.4970 - val_accuracy: 0.3719 - lr: 0.0100\n",
            "Epoch 115/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.3230 - accuracy: 0.3993 - val_loss: 2.5020 - val_accuracy: 0.3687 - lr: 0.0100\n",
            "Epoch 116/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3191 - accuracy: 0.3997 - val_loss: 2.5047 - val_accuracy: 0.3671 - lr: 0.0100\n",
            "Epoch 117/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.3186 - accuracy: 0.3990 - val_loss: 2.4802 - val_accuracy: 0.3731 - lr: 0.0100\n",
            "Epoch 118/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3124 - accuracy: 0.4041 - val_loss: 2.5005 - val_accuracy: 0.3669 - lr: 0.0100\n",
            "Epoch 119/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3089 - accuracy: 0.4034 - val_loss: 2.4808 - val_accuracy: 0.3740 - lr: 0.0100\n",
            "Epoch 120/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3079 - accuracy: 0.4026 - val_loss: 2.4722 - val_accuracy: 0.3757 - lr: 0.0100\n",
            "Epoch 121/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3083 - accuracy: 0.4018 - val_loss: 2.4897 - val_accuracy: 0.3702 - lr: 0.0100\n",
            "Epoch 122/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.3047 - accuracy: 0.4039 - val_loss: 2.5006 - val_accuracy: 0.3671 - lr: 0.0100\n",
            "Epoch 123/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3014 - accuracy: 0.4050 - val_loss: 2.5275 - val_accuracy: 0.3623 - lr: 0.0100\n",
            "Epoch 124/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.3060 - accuracy: 0.4048 - val_loss: 2.4765 - val_accuracy: 0.3728 - lr: 0.0100\n",
            "Epoch 125/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2985 - accuracy: 0.4026 - val_loss: 2.4757 - val_accuracy: 0.3758 - lr: 0.0100\n",
            "Epoch 126/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2995 - accuracy: 0.4053 - val_loss: 2.4779 - val_accuracy: 0.3738 - lr: 0.0100\n",
            "Epoch 127/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2916 - accuracy: 0.4043 - val_loss: 2.4789 - val_accuracy: 0.3747 - lr: 0.0100\n",
            "Epoch 128/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2904 - accuracy: 0.4055 - val_loss: 2.4872 - val_accuracy: 0.3726 - lr: 0.0100\n",
            "Epoch 129/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2898 - accuracy: 0.4053 - val_loss: 2.4871 - val_accuracy: 0.3737 - lr: 0.0100\n",
            "Epoch 130/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2857 - accuracy: 0.4060 - val_loss: 2.4652 - val_accuracy: 0.3774 - lr: 0.0100\n",
            "Epoch 131/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2868 - accuracy: 0.4052 - val_loss: 2.5126 - val_accuracy: 0.3649 - lr: 0.0100\n",
            "Epoch 132/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2802 - accuracy: 0.4069 - val_loss: 2.4747 - val_accuracy: 0.3737 - lr: 0.0100\n",
            "Epoch 133/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2831 - accuracy: 0.4090 - val_loss: 2.4641 - val_accuracy: 0.3787 - lr: 0.0100\n",
            "Epoch 134/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2753 - accuracy: 0.4079 - val_loss: 2.4947 - val_accuracy: 0.3691 - lr: 0.0100\n",
            "Epoch 135/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2756 - accuracy: 0.4110 - val_loss: 2.4663 - val_accuracy: 0.3770 - lr: 0.0100\n",
            "Epoch 136/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2687 - accuracy: 0.4120 - val_loss: 2.5058 - val_accuracy: 0.3677 - lr: 0.0100\n",
            "Epoch 137/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2645 - accuracy: 0.4108 - val_loss: 2.4900 - val_accuracy: 0.3732 - lr: 0.0100\n",
            "Epoch 138/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2583 - accuracy: 0.4134 - val_loss: 2.4770 - val_accuracy: 0.3773 - lr: 0.0100\n",
            "Epoch 139/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2661 - accuracy: 0.4137 - val_loss: 2.4841 - val_accuracy: 0.3722 - lr: 0.0100\n",
            "Epoch 140/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2604 - accuracy: 0.4101 - val_loss: 2.4616 - val_accuracy: 0.3738 - lr: 0.0100\n",
            "Epoch 141/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2626 - accuracy: 0.4114 - val_loss: 2.4702 - val_accuracy: 0.3791 - lr: 0.0100\n",
            "Epoch 142/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.2566 - accuracy: 0.4121 - val_loss: 2.4599 - val_accuracy: 0.3786 - lr: 0.0100\n",
            "Epoch 143/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2539 - accuracy: 0.4130 - val_loss: 2.4709 - val_accuracy: 0.3757 - lr: 0.0100\n",
            "Epoch 144/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2528 - accuracy: 0.4133 - val_loss: 2.4629 - val_accuracy: 0.3782 - lr: 0.0100\n",
            "Epoch 145/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2497 - accuracy: 0.4122 - val_loss: 2.4897 - val_accuracy: 0.3718 - lr: 0.0100\n",
            "Epoch 146/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2462 - accuracy: 0.4134 - val_loss: 2.4604 - val_accuracy: 0.3789 - lr: 0.0100\n",
            "Epoch 147/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2464 - accuracy: 0.4149 - val_loss: 2.4580 - val_accuracy: 0.3774 - lr: 0.0100\n",
            "Epoch 148/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2420 - accuracy: 0.4139 - val_loss: 2.4718 - val_accuracy: 0.3779 - lr: 0.0100\n",
            "Epoch 149/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2412 - accuracy: 0.4159 - val_loss: 2.4903 - val_accuracy: 0.3690 - lr: 0.0100\n",
            "Epoch 150/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2410 - accuracy: 0.4161 - val_loss: 2.4546 - val_accuracy: 0.3795 - lr: 0.0100\n",
            "Epoch 151/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2319 - accuracy: 0.4188 - val_loss: 2.4656 - val_accuracy: 0.3774 - lr: 0.0100\n",
            "Epoch 152/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2320 - accuracy: 0.4163 - val_loss: 2.4649 - val_accuracy: 0.3787 - lr: 0.0100\n",
            "Epoch 153/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2329 - accuracy: 0.4155 - val_loss: 2.4855 - val_accuracy: 0.3726 - lr: 0.0100\n",
            "Epoch 154/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2349 - accuracy: 0.4172 - val_loss: 2.4566 - val_accuracy: 0.3776 - lr: 0.0100\n",
            "Epoch 155/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2302 - accuracy: 0.4194 - val_loss: 2.4612 - val_accuracy: 0.3751 - lr: 0.0100\n",
            "Epoch 156/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2236 - accuracy: 0.4201 - val_loss: 2.4695 - val_accuracy: 0.3773 - lr: 0.0100\n",
            "Epoch 157/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2286 - accuracy: 0.4155 - val_loss: 2.4471 - val_accuracy: 0.3796 - lr: 0.0100\n",
            "Epoch 158/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2221 - accuracy: 0.4194 - val_loss: 2.4481 - val_accuracy: 0.3809 - lr: 0.0100\n",
            "Epoch 159/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2243 - accuracy: 0.4187 - val_loss: 2.4709 - val_accuracy: 0.3737 - lr: 0.0100\n",
            "Epoch 160/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2175 - accuracy: 0.4198 - val_loss: 2.4520 - val_accuracy: 0.3795 - lr: 0.0100\n",
            "Epoch 161/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2128 - accuracy: 0.4209 - val_loss: 2.4535 - val_accuracy: 0.3796 - lr: 0.0100\n",
            "Epoch 162/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2187 - accuracy: 0.4205 - val_loss: 2.4551 - val_accuracy: 0.3760 - lr: 0.0100\n",
            "Epoch 163/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2127 - accuracy: 0.4233 - val_loss: 2.4470 - val_accuracy: 0.3778 - lr: 0.0100\n",
            "Epoch 164/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2104 - accuracy: 0.4208 - val_loss: 2.4394 - val_accuracy: 0.3832 - lr: 0.0100\n",
            "Epoch 165/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2097 - accuracy: 0.4218 - val_loss: 2.4642 - val_accuracy: 0.3756 - lr: 0.0100\n",
            "Epoch 166/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.2052 - accuracy: 0.4224 - val_loss: 2.4361 - val_accuracy: 0.3845 - lr: 0.0100\n",
            "Epoch 167/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.2070 - accuracy: 0.4201 - val_loss: 2.4332 - val_accuracy: 0.3833 - lr: 0.0100\n",
            "Epoch 168/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.2019 - accuracy: 0.4234 - val_loss: 2.4582 - val_accuracy: 0.3769 - lr: 0.0100\n",
            "Epoch 169/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2028 - accuracy: 0.4221 - val_loss: 2.4468 - val_accuracy: 0.3800 - lr: 0.0100\n",
            "Epoch 170/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2029 - accuracy: 0.4240 - val_loss: 2.4686 - val_accuracy: 0.3776 - lr: 0.0100\n",
            "Epoch 171/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1976 - accuracy: 0.4255 - val_loss: 2.4344 - val_accuracy: 0.3827 - lr: 0.0100\n",
            "Epoch 172/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.1982 - accuracy: 0.4226 - val_loss: 2.4299 - val_accuracy: 0.3885 - lr: 0.0100\n",
            "Epoch 173/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.1904 - accuracy: 0.4251 - val_loss: 2.4788 - val_accuracy: 0.3738 - lr: 0.0100\n",
            "Epoch 174/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1955 - accuracy: 0.4251 - val_loss: 2.4493 - val_accuracy: 0.3805 - lr: 0.0100\n",
            "Epoch 175/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1884 - accuracy: 0.4261 - val_loss: 2.4677 - val_accuracy: 0.3765 - lr: 0.0100\n",
            "Epoch 176/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1859 - accuracy: 0.4272 - val_loss: 2.4552 - val_accuracy: 0.3786 - lr: 0.0100\n",
            "Epoch 177/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.1817 - accuracy: 0.4272 - val_loss: 2.4542 - val_accuracy: 0.3774 - lr: 0.0100\n",
            "Epoch 178/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.1827 - accuracy: 0.4289 - val_loss: 2.4421 - val_accuracy: 0.3824 - lr: 0.0100\n",
            "Epoch 179/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1849 - accuracy: 0.4257 - val_loss: 2.4390 - val_accuracy: 0.3865 - lr: 0.0100\n",
            "Epoch 180/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1760 - accuracy: 0.4283 - val_loss: 2.4371 - val_accuracy: 0.3855 - lr: 0.0100\n",
            "Epoch 181/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1754 - accuracy: 0.4300 - val_loss: 2.4471 - val_accuracy: 0.3831 - lr: 0.0100\n",
            "Epoch 182/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1732 - accuracy: 0.4289 - val_loss: 2.4652 - val_accuracy: 0.3777 - lr: 0.0100\n",
            "Epoch 183/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1791 - accuracy: 0.4276 - val_loss: 2.4456 - val_accuracy: 0.3817 - lr: 0.0100\n",
            "Epoch 184/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1720 - accuracy: 0.4322 - val_loss: 2.4309 - val_accuracy: 0.3843 - lr: 0.0100\n",
            "Epoch 185/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1666 - accuracy: 0.4305 - val_loss: 2.4252 - val_accuracy: 0.3898 - lr: 0.0100\n",
            "Epoch 186/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1709 - accuracy: 0.4295 - val_loss: 2.4723 - val_accuracy: 0.3802 - lr: 0.0100\n",
            "Epoch 187/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1622 - accuracy: 0.4322 - val_loss: 2.4538 - val_accuracy: 0.3867 - lr: 0.0100\n",
            "Epoch 188/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1651 - accuracy: 0.4311 - val_loss: 2.4640 - val_accuracy: 0.3772 - lr: 0.0100\n",
            "Epoch 189/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1603 - accuracy: 0.4317 - val_loss: 2.4332 - val_accuracy: 0.3860 - lr: 0.0100\n",
            "Epoch 190/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1610 - accuracy: 0.4311 - val_loss: 2.4406 - val_accuracy: 0.3829 - lr: 0.0100\n",
            "Epoch 191/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1593 - accuracy: 0.4334 - val_loss: 2.4304 - val_accuracy: 0.3828 - lr: 0.0100\n",
            "Epoch 192/1000\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 2.1614 - accuracy: 0.4318 - val_loss: 2.4369 - val_accuracy: 0.3828 - lr: 0.0100\n",
            "Epoch 193/1000\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 2.1515 - accuracy: 0.4329 - val_loss: 2.4444 - val_accuracy: 0.3813 - lr: 0.0100\n",
            "Epoch 194/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1519 - accuracy: 0.4336 - val_loss: 2.4349 - val_accuracy: 0.3837 - lr: 0.0100\n",
            "Epoch 195/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1501 - accuracy: 0.4351 - val_loss: 2.4264 - val_accuracy: 0.3872 - lr: 0.0100\n",
            "Epoch 196/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1448 - accuracy: 0.4350 - val_loss: 2.4194 - val_accuracy: 0.3858 - lr: 0.0100\n",
            "Epoch 197/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1527 - accuracy: 0.4340 - val_loss: 2.4274 - val_accuracy: 0.3882 - lr: 0.0100\n",
            "Epoch 198/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1432 - accuracy: 0.4363 - val_loss: 2.4280 - val_accuracy: 0.3884 - lr: 0.0100\n",
            "Epoch 199/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1499 - accuracy: 0.4339 - val_loss: 2.4354 - val_accuracy: 0.3835 - lr: 0.0100\n",
            "Epoch 200/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1398 - accuracy: 0.4351 - val_loss: 2.4427 - val_accuracy: 0.3853 - lr: 0.0100\n",
            "Epoch 201/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1210 - accuracy: 0.4430 - val_loss: 2.4136 - val_accuracy: 0.3902 - lr: 0.0050\n",
            "Epoch 202/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1131 - accuracy: 0.4422 - val_loss: 2.4170 - val_accuracy: 0.3895 - lr: 0.0050\n",
            "Epoch 203/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1100 - accuracy: 0.4427 - val_loss: 2.4047 - val_accuracy: 0.3934 - lr: 0.0050\n",
            "Epoch 204/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1150 - accuracy: 0.4446 - val_loss: 2.4167 - val_accuracy: 0.3866 - lr: 0.0050\n",
            "Epoch 205/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1137 - accuracy: 0.4425 - val_loss: 2.4017 - val_accuracy: 0.3903 - lr: 0.0050\n",
            "Epoch 206/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1135 - accuracy: 0.4431 - val_loss: 2.3983 - val_accuracy: 0.3957 - lr: 0.0050\n",
            "Epoch 207/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1118 - accuracy: 0.4428 - val_loss: 2.4041 - val_accuracy: 0.3928 - lr: 0.0050\n",
            "Epoch 208/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1095 - accuracy: 0.4433 - val_loss: 2.4040 - val_accuracy: 0.3920 - lr: 0.0050\n",
            "Epoch 209/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1096 - accuracy: 0.4451 - val_loss: 2.4125 - val_accuracy: 0.3882 - lr: 0.0050\n",
            "Epoch 210/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1095 - accuracy: 0.4413 - val_loss: 2.4028 - val_accuracy: 0.3936 - lr: 0.0050\n",
            "Epoch 211/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1049 - accuracy: 0.4440 - val_loss: 2.4011 - val_accuracy: 0.3933 - lr: 0.0050\n",
            "Epoch 212/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1042 - accuracy: 0.4434 - val_loss: 2.4216 - val_accuracy: 0.3887 - lr: 0.0050\n",
            "Epoch 213/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1067 - accuracy: 0.4436 - val_loss: 2.4002 - val_accuracy: 0.3934 - lr: 0.0050\n",
            "Epoch 214/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1030 - accuracy: 0.4472 - val_loss: 2.4199 - val_accuracy: 0.3882 - lr: 0.0050\n",
            "Epoch 215/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1017 - accuracy: 0.4452 - val_loss: 2.3992 - val_accuracy: 0.3908 - lr: 0.0050\n",
            "Epoch 216/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1041 - accuracy: 0.4449 - val_loss: 2.4111 - val_accuracy: 0.3882 - lr: 0.0050\n",
            "Epoch 217/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1026 - accuracy: 0.4442 - val_loss: 2.4047 - val_accuracy: 0.3924 - lr: 0.0050\n",
            "Epoch 218/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0944 - accuracy: 0.4479 - val_loss: 2.4222 - val_accuracy: 0.3907 - lr: 0.0050\n",
            "Epoch 219/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0968 - accuracy: 0.4457 - val_loss: 2.4309 - val_accuracy: 0.3875 - lr: 0.0050\n",
            "Epoch 220/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.1003 - accuracy: 0.4448 - val_loss: 2.4035 - val_accuracy: 0.3913 - lr: 0.0050\n",
            "Epoch 221/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0967 - accuracy: 0.4462 - val_loss: 2.4070 - val_accuracy: 0.3922 - lr: 0.0050\n",
            "Epoch 222/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0946 - accuracy: 0.4479 - val_loss: 2.4097 - val_accuracy: 0.3928 - lr: 0.0050\n",
            "Epoch 223/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0925 - accuracy: 0.4456 - val_loss: 2.4061 - val_accuracy: 0.3888 - lr: 0.0050\n",
            "Epoch 224/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0960 - accuracy: 0.4457 - val_loss: 2.4020 - val_accuracy: 0.3924 - lr: 0.0050\n",
            "Epoch 225/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0927 - accuracy: 0.4451 - val_loss: 2.3981 - val_accuracy: 0.3928 - lr: 0.0050\n",
            "Epoch 226/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0917 - accuracy: 0.4484 - val_loss: 2.4025 - val_accuracy: 0.3922 - lr: 0.0050\n",
            "Epoch 227/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0927 - accuracy: 0.4486 - val_loss: 2.4366 - val_accuracy: 0.3873 - lr: 0.0050\n",
            "Epoch 228/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0882 - accuracy: 0.4479 - val_loss: 2.4009 - val_accuracy: 0.3922 - lr: 0.0050\n",
            "Epoch 229/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0873 - accuracy: 0.4466 - val_loss: 2.4122 - val_accuracy: 0.3895 - lr: 0.0050\n",
            "Epoch 230/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0924 - accuracy: 0.4471 - val_loss: 2.4017 - val_accuracy: 0.3960 - lr: 0.0050\n",
            "Epoch 231/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0833 - accuracy: 0.4497 - val_loss: 2.4098 - val_accuracy: 0.3884 - lr: 0.0050\n",
            "Epoch 232/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0877 - accuracy: 0.4482 - val_loss: 2.4154 - val_accuracy: 0.3934 - lr: 0.0050\n",
            "Epoch 233/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0856 - accuracy: 0.4493 - val_loss: 2.4054 - val_accuracy: 0.3911 - lr: 0.0050\n",
            "Epoch 234/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0928 - accuracy: 0.4467 - val_loss: 2.3964 - val_accuracy: 0.3915 - lr: 0.0050\n",
            "Epoch 235/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0848 - accuracy: 0.4492 - val_loss: 2.3939 - val_accuracy: 0.3956 - lr: 0.0050\n",
            "Epoch 236/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0890 - accuracy: 0.4475 - val_loss: 2.3923 - val_accuracy: 0.3941 - lr: 0.0050\n",
            "Epoch 237/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0817 - accuracy: 0.4496 - val_loss: 2.4105 - val_accuracy: 0.3887 - lr: 0.0050\n",
            "Epoch 238/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0799 - accuracy: 0.4508 - val_loss: 2.4009 - val_accuracy: 0.3940 - lr: 0.0050\n",
            "Epoch 239/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0806 - accuracy: 0.4484 - val_loss: 2.4053 - val_accuracy: 0.3896 - lr: 0.0050\n",
            "Epoch 240/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0799 - accuracy: 0.4492 - val_loss: 2.4133 - val_accuracy: 0.3877 - lr: 0.0050\n",
            "Epoch 241/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0833 - accuracy: 0.4500 - val_loss: 2.4022 - val_accuracy: 0.3954 - lr: 0.0050\n",
            "Epoch 242/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0762 - accuracy: 0.4498 - val_loss: 2.4020 - val_accuracy: 0.3939 - lr: 0.0050\n",
            "Epoch 243/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0782 - accuracy: 0.4515 - val_loss: 2.4300 - val_accuracy: 0.3882 - lr: 0.0050\n",
            "Epoch 244/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0751 - accuracy: 0.4527 - val_loss: 2.4024 - val_accuracy: 0.3925 - lr: 0.0050\n",
            "Epoch 245/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0790 - accuracy: 0.4495 - val_loss: 2.3894 - val_accuracy: 0.3966 - lr: 0.0050\n",
            "Epoch 246/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0780 - accuracy: 0.4515 - val_loss: 2.4050 - val_accuracy: 0.3926 - lr: 0.0050\n",
            "Epoch 247/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0750 - accuracy: 0.4503 - val_loss: 2.3998 - val_accuracy: 0.3959 - lr: 0.0050\n",
            "Epoch 248/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0699 - accuracy: 0.4511 - val_loss: 2.4406 - val_accuracy: 0.3840 - lr: 0.0050\n",
            "Epoch 249/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0630 - accuracy: 0.4513 - val_loss: 2.4127 - val_accuracy: 0.3897 - lr: 0.0050\n",
            "Epoch 250/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0691 - accuracy: 0.4497 - val_loss: 2.3921 - val_accuracy: 0.4002 - lr: 0.0050\n",
            "Epoch 251/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0690 - accuracy: 0.4531 - val_loss: 2.3968 - val_accuracy: 0.3918 - lr: 0.0050\n",
            "Epoch 252/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0718 - accuracy: 0.4517 - val_loss: 2.3984 - val_accuracy: 0.3920 - lr: 0.0050\n",
            "Epoch 253/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0638 - accuracy: 0.4514 - val_loss: 2.3934 - val_accuracy: 0.3955 - lr: 0.0050\n",
            "Epoch 254/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0735 - accuracy: 0.4529 - val_loss: 2.3886 - val_accuracy: 0.3974 - lr: 0.0050\n",
            "Epoch 255/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0654 - accuracy: 0.4534 - val_loss: 2.4256 - val_accuracy: 0.3876 - lr: 0.0050\n",
            "Epoch 256/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0658 - accuracy: 0.4490 - val_loss: 2.4046 - val_accuracy: 0.3935 - lr: 0.0050\n",
            "Epoch 257/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0669 - accuracy: 0.4525 - val_loss: 2.3898 - val_accuracy: 0.3972 - lr: 0.0050\n",
            "Epoch 258/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0649 - accuracy: 0.4522 - val_loss: 2.3938 - val_accuracy: 0.3952 - lr: 0.0050\n",
            "Epoch 259/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0613 - accuracy: 0.4533 - val_loss: 2.4023 - val_accuracy: 0.3941 - lr: 0.0050\n",
            "Epoch 260/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0625 - accuracy: 0.4541 - val_loss: 2.3959 - val_accuracy: 0.3937 - lr: 0.0050\n",
            "Epoch 261/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0660 - accuracy: 0.4506 - val_loss: 2.3972 - val_accuracy: 0.3914 - lr: 0.0050\n",
            "Epoch 262/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0617 - accuracy: 0.4532 - val_loss: 2.3915 - val_accuracy: 0.3971 - lr: 0.0050\n",
            "Epoch 263/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0590 - accuracy: 0.4540 - val_loss: 2.3987 - val_accuracy: 0.3955 - lr: 0.0050\n",
            "Epoch 264/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0604 - accuracy: 0.4534 - val_loss: 2.3847 - val_accuracy: 0.3982 - lr: 0.0050\n",
            "Epoch 265/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0525 - accuracy: 0.4548 - val_loss: 2.4160 - val_accuracy: 0.3880 - lr: 0.0050\n",
            "Epoch 266/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0590 - accuracy: 0.4539 - val_loss: 2.3991 - val_accuracy: 0.3938 - lr: 0.0050\n",
            "Epoch 267/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0581 - accuracy: 0.4532 - val_loss: 2.3972 - val_accuracy: 0.3922 - lr: 0.0050\n",
            "Epoch 268/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0517 - accuracy: 0.4553 - val_loss: 2.3887 - val_accuracy: 0.3964 - lr: 0.0050\n",
            "Epoch 269/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0550 - accuracy: 0.4546 - val_loss: 2.3946 - val_accuracy: 0.3946 - lr: 0.0050\n",
            "Epoch 270/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0530 - accuracy: 0.4556 - val_loss: 2.4075 - val_accuracy: 0.3932 - lr: 0.0050\n",
            "Epoch 271/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0512 - accuracy: 0.4564 - val_loss: 2.4015 - val_accuracy: 0.3958 - lr: 0.0050\n",
            "Epoch 272/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0533 - accuracy: 0.4549 - val_loss: 2.4023 - val_accuracy: 0.3963 - lr: 0.0050\n",
            "Epoch 273/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0498 - accuracy: 0.4576 - val_loss: 2.3848 - val_accuracy: 0.3982 - lr: 0.0050\n",
            "Epoch 274/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0464 - accuracy: 0.4556 - val_loss: 2.3900 - val_accuracy: 0.3940 - lr: 0.0050\n",
            "Epoch 275/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0433 - accuracy: 0.4565 - val_loss: 2.4021 - val_accuracy: 0.3975 - lr: 0.0050\n",
            "Epoch 276/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0528 - accuracy: 0.4544 - val_loss: 2.3861 - val_accuracy: 0.3965 - lr: 0.0050\n",
            "Epoch 277/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0444 - accuracy: 0.4570 - val_loss: 2.3957 - val_accuracy: 0.3973 - lr: 0.0050\n",
            "Epoch 278/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0501 - accuracy: 0.4544 - val_loss: 2.3889 - val_accuracy: 0.3971 - lr: 0.0050\n",
            "Epoch 279/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0467 - accuracy: 0.4575 - val_loss: 2.3935 - val_accuracy: 0.3998 - lr: 0.0050\n",
            "Epoch 280/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0405 - accuracy: 0.4568 - val_loss: 2.4085 - val_accuracy: 0.3956 - lr: 0.0050\n",
            "Epoch 281/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0446 - accuracy: 0.4561 - val_loss: 2.3845 - val_accuracy: 0.3999 - lr: 0.0050\n",
            "Epoch 282/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0455 - accuracy: 0.4553 - val_loss: 2.3911 - val_accuracy: 0.3970 - lr: 0.0050\n",
            "Epoch 283/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0441 - accuracy: 0.4597 - val_loss: 2.3783 - val_accuracy: 0.4003 - lr: 0.0050\n",
            "Epoch 284/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0393 - accuracy: 0.4578 - val_loss: 2.3909 - val_accuracy: 0.3963 - lr: 0.0050\n",
            "Epoch 285/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0425 - accuracy: 0.4581 - val_loss: 2.3954 - val_accuracy: 0.3952 - lr: 0.0050\n",
            "Epoch 286/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0448 - accuracy: 0.4576 - val_loss: 2.4116 - val_accuracy: 0.3934 - lr: 0.0050\n",
            "Epoch 287/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0397 - accuracy: 0.4577 - val_loss: 2.3892 - val_accuracy: 0.3986 - lr: 0.0050\n",
            "Epoch 288/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0432 - accuracy: 0.4582 - val_loss: 2.4232 - val_accuracy: 0.3887 - lr: 0.0050\n",
            "Epoch 289/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0391 - accuracy: 0.4569 - val_loss: 2.3977 - val_accuracy: 0.3975 - lr: 0.0050\n",
            "Epoch 290/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0420 - accuracy: 0.4566 - val_loss: 2.3843 - val_accuracy: 0.3965 - lr: 0.0050\n",
            "Epoch 291/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0417 - accuracy: 0.4589 - val_loss: 2.4063 - val_accuracy: 0.3962 - lr: 0.0050\n",
            "Epoch 292/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0388 - accuracy: 0.4583 - val_loss: 2.3964 - val_accuracy: 0.3953 - lr: 0.0050\n",
            "Epoch 293/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0289 - accuracy: 0.4603 - val_loss: 2.3837 - val_accuracy: 0.4013 - lr: 0.0050\n",
            "Epoch 294/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0403 - accuracy: 0.4600 - val_loss: 2.3860 - val_accuracy: 0.3950 - lr: 0.0050\n",
            "Epoch 295/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0373 - accuracy: 0.4557 - val_loss: 2.4083 - val_accuracy: 0.3946 - lr: 0.0050\n",
            "Epoch 296/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0367 - accuracy: 0.4580 - val_loss: 2.3916 - val_accuracy: 0.3973 - lr: 0.0050\n",
            "Epoch 297/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0407 - accuracy: 0.4571 - val_loss: 2.3916 - val_accuracy: 0.3969 - lr: 0.0050\n",
            "Epoch 298/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0335 - accuracy: 0.4601 - val_loss: 2.4005 - val_accuracy: 0.3949 - lr: 0.0050\n",
            "Epoch 299/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0352 - accuracy: 0.4585 - val_loss: 2.3797 - val_accuracy: 0.3979 - lr: 0.0050\n",
            "Epoch 300/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0333 - accuracy: 0.4583 - val_loss: 2.3941 - val_accuracy: 0.3946 - lr: 0.0050\n",
            "Epoch 301/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0248 - accuracy: 0.4615 - val_loss: 2.4038 - val_accuracy: 0.3935 - lr: 0.0050\n",
            "Epoch 302/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0342 - accuracy: 0.4572 - val_loss: 2.3889 - val_accuracy: 0.3971 - lr: 0.0050\n",
            "Epoch 303/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0280 - accuracy: 0.4589 - val_loss: 2.4109 - val_accuracy: 0.3952 - lr: 0.0050\n",
            "Epoch 304/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0320 - accuracy: 0.4583 - val_loss: 2.3867 - val_accuracy: 0.3966 - lr: 0.0050\n",
            "Epoch 305/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0240 - accuracy: 0.4611 - val_loss: 2.3776 - val_accuracy: 0.4002 - lr: 0.0050\n",
            "Epoch 306/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0305 - accuracy: 0.4583 - val_loss: 2.3907 - val_accuracy: 0.3981 - lr: 0.0050\n",
            "Epoch 307/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0244 - accuracy: 0.4615 - val_loss: 2.3977 - val_accuracy: 0.3969 - lr: 0.0050\n",
            "Epoch 308/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0208 - accuracy: 0.4621 - val_loss: 2.3934 - val_accuracy: 0.3975 - lr: 0.0050\n",
            "Epoch 309/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0205 - accuracy: 0.4615 - val_loss: 2.3806 - val_accuracy: 0.3998 - lr: 0.0050\n",
            "Epoch 310/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0300 - accuracy: 0.4574 - val_loss: 2.3847 - val_accuracy: 0.3971 - lr: 0.0050\n",
            "Epoch 311/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0256 - accuracy: 0.4596 - val_loss: 2.3942 - val_accuracy: 0.3935 - lr: 0.0050\n",
            "Epoch 312/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0220 - accuracy: 0.4608 - val_loss: 2.3988 - val_accuracy: 0.3941 - lr: 0.0050\n",
            "Epoch 313/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0248 - accuracy: 0.4627 - val_loss: 2.3898 - val_accuracy: 0.3981 - lr: 0.0050\n",
            "Epoch 314/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0205 - accuracy: 0.4620 - val_loss: 2.3762 - val_accuracy: 0.3996 - lr: 0.0050\n",
            "Epoch 315/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0215 - accuracy: 0.4623 - val_loss: 2.3732 - val_accuracy: 0.4015 - lr: 0.0050\n",
            "Epoch 316/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0166 - accuracy: 0.4620 - val_loss: 2.3838 - val_accuracy: 0.3996 - lr: 0.0050\n",
            "Epoch 317/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0193 - accuracy: 0.4620 - val_loss: 2.4102 - val_accuracy: 0.3933 - lr: 0.0050\n",
            "Epoch 318/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0146 - accuracy: 0.4604 - val_loss: 2.3779 - val_accuracy: 0.4022 - lr: 0.0050\n",
            "Epoch 319/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0196 - accuracy: 0.4611 - val_loss: 2.3892 - val_accuracy: 0.3955 - lr: 0.0050\n",
            "Epoch 320/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0191 - accuracy: 0.4625 - val_loss: 2.3785 - val_accuracy: 0.3994 - lr: 0.0050\n",
            "Epoch 321/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0159 - accuracy: 0.4634 - val_loss: 2.3767 - val_accuracy: 0.3983 - lr: 0.0050\n",
            "Epoch 322/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0157 - accuracy: 0.4612 - val_loss: 2.3664 - val_accuracy: 0.4011 - lr: 0.0050\n",
            "Epoch 323/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0170 - accuracy: 0.4627 - val_loss: 2.3754 - val_accuracy: 0.4042 - lr: 0.0050\n",
            "Epoch 324/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0180 - accuracy: 0.4627 - val_loss: 2.3937 - val_accuracy: 0.3951 - lr: 0.0050\n",
            "Epoch 325/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0093 - accuracy: 0.4658 - val_loss: 2.3985 - val_accuracy: 0.3934 - lr: 0.0050\n",
            "Epoch 326/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0103 - accuracy: 0.4637 - val_loss: 2.3957 - val_accuracy: 0.3937 - lr: 0.0050\n",
            "Epoch 327/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0133 - accuracy: 0.4634 - val_loss: 2.3842 - val_accuracy: 0.4015 - lr: 0.0050\n",
            "Epoch 328/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0129 - accuracy: 0.4628 - val_loss: 2.4101 - val_accuracy: 0.3946 - lr: 0.0050\n",
            "Epoch 329/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0138 - accuracy: 0.4646 - val_loss: 2.4061 - val_accuracy: 0.3940 - lr: 0.0050\n",
            "Epoch 330/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0131 - accuracy: 0.4628 - val_loss: 2.4130 - val_accuracy: 0.3900 - lr: 0.0050\n",
            "Epoch 331/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0094 - accuracy: 0.4644 - val_loss: 2.3832 - val_accuracy: 0.4007 - lr: 0.0050\n",
            "Epoch 332/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0088 - accuracy: 0.4651 - val_loss: 2.4150 - val_accuracy: 0.3921 - lr: 0.0050\n",
            "Epoch 333/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0076 - accuracy: 0.4649 - val_loss: 2.3945 - val_accuracy: 0.3965 - lr: 0.0050\n",
            "Epoch 334/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0127 - accuracy: 0.4628 - val_loss: 2.4068 - val_accuracy: 0.3933 - lr: 0.0050\n",
            "Epoch 335/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0077 - accuracy: 0.4649 - val_loss: 2.3877 - val_accuracy: 0.3981 - lr: 0.0050\n",
            "Epoch 336/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0065 - accuracy: 0.4632 - val_loss: 2.3912 - val_accuracy: 0.4010 - lr: 0.0050\n",
            "Epoch 337/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0010 - accuracy: 0.4650 - val_loss: 2.3725 - val_accuracy: 0.4034 - lr: 0.0050\n",
            "Epoch 338/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9986 - accuracy: 0.4661 - val_loss: 2.3926 - val_accuracy: 0.3976 - lr: 0.0050\n",
            "Epoch 339/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0103 - accuracy: 0.4621 - val_loss: 2.3857 - val_accuracy: 0.3997 - lr: 0.0050\n",
            "Epoch 340/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0035 - accuracy: 0.4679 - val_loss: 2.4034 - val_accuracy: 0.3936 - lr: 0.0050\n",
            "Epoch 341/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0051 - accuracy: 0.4627 - val_loss: 2.3770 - val_accuracy: 0.3990 - lr: 0.0050\n",
            "Epoch 342/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0049 - accuracy: 0.4631 - val_loss: 2.4125 - val_accuracy: 0.3918 - lr: 0.0050\n",
            "Epoch 343/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9997 - accuracy: 0.4650 - val_loss: 2.3865 - val_accuracy: 0.4007 - lr: 0.0050\n",
            "Epoch 344/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9998 - accuracy: 0.4652 - val_loss: 2.3800 - val_accuracy: 0.4014 - lr: 0.0050\n",
            "Epoch 345/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9988 - accuracy: 0.4661 - val_loss: 2.3862 - val_accuracy: 0.3958 - lr: 0.0050\n",
            "Epoch 346/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9966 - accuracy: 0.4668 - val_loss: 2.3804 - val_accuracy: 0.3961 - lr: 0.0050\n",
            "Epoch 347/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9963 - accuracy: 0.4667 - val_loss: 2.3875 - val_accuracy: 0.3959 - lr: 0.0050\n",
            "Epoch 348/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9975 - accuracy: 0.4662 - val_loss: 2.3750 - val_accuracy: 0.4004 - lr: 0.0050\n",
            "Epoch 349/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9969 - accuracy: 0.4677 - val_loss: 2.4006 - val_accuracy: 0.3944 - lr: 0.0050\n",
            "Epoch 350/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9929 - accuracy: 0.4673 - val_loss: 2.3688 - val_accuracy: 0.4026 - lr: 0.0050\n",
            "Epoch 351/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9979 - accuracy: 0.4661 - val_loss: 2.3787 - val_accuracy: 0.3995 - lr: 0.0050\n",
            "Epoch 352/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9948 - accuracy: 0.4665 - val_loss: 2.3789 - val_accuracy: 0.4002 - lr: 0.0050\n",
            "Epoch 353/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.0011 - accuracy: 0.4654 - val_loss: 2.3824 - val_accuracy: 0.4017 - lr: 0.0050\n",
            "Epoch 354/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9898 - accuracy: 0.4660 - val_loss: 2.3821 - val_accuracy: 0.3971 - lr: 0.0050\n",
            "Epoch 355/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9888 - accuracy: 0.4696 - val_loss: 2.3734 - val_accuracy: 0.4005 - lr: 0.0050\n",
            "Epoch 356/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9898 - accuracy: 0.4687 - val_loss: 2.3716 - val_accuracy: 0.4020 - lr: 0.0050\n",
            "Epoch 357/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9935 - accuracy: 0.4671 - val_loss: 2.3729 - val_accuracy: 0.4007 - lr: 0.0050\n",
            "Epoch 358/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9891 - accuracy: 0.4688 - val_loss: 2.3809 - val_accuracy: 0.3997 - lr: 0.0050\n",
            "Epoch 359/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9900 - accuracy: 0.4663 - val_loss: 2.3665 - val_accuracy: 0.4017 - lr: 0.0050\n",
            "Epoch 360/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9900 - accuracy: 0.4672 - val_loss: 2.4055 - val_accuracy: 0.3944 - lr: 0.0050\n",
            "Epoch 361/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9870 - accuracy: 0.4687 - val_loss: 2.3774 - val_accuracy: 0.4012 - lr: 0.0050\n",
            "Epoch 362/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9783 - accuracy: 0.4706 - val_loss: 2.3987 - val_accuracy: 0.3935 - lr: 0.0050\n",
            "Epoch 363/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9863 - accuracy: 0.4673 - val_loss: 2.3718 - val_accuracy: 0.4006 - lr: 0.0050\n",
            "Epoch 364/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9874 - accuracy: 0.4674 - val_loss: 2.3807 - val_accuracy: 0.3983 - lr: 0.0050\n",
            "Epoch 365/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9865 - accuracy: 0.4701 - val_loss: 2.3749 - val_accuracy: 0.3986 - lr: 0.0050\n",
            "Epoch 366/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9928 - accuracy: 0.4689 - val_loss: 2.3897 - val_accuracy: 0.3946 - lr: 0.0050\n",
            "Epoch 367/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9875 - accuracy: 0.4698 - val_loss: 2.3631 - val_accuracy: 0.4010 - lr: 0.0050\n",
            "Epoch 368/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9859 - accuracy: 0.4705 - val_loss: 2.3833 - val_accuracy: 0.3970 - lr: 0.0050\n",
            "Epoch 369/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9814 - accuracy: 0.4679 - val_loss: 2.3872 - val_accuracy: 0.3959 - lr: 0.0050\n",
            "Epoch 370/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9889 - accuracy: 0.4692 - val_loss: 2.3737 - val_accuracy: 0.3997 - lr: 0.0050\n",
            "Epoch 371/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9791 - accuracy: 0.4715 - val_loss: 2.3761 - val_accuracy: 0.4029 - lr: 0.0050\n",
            "Epoch 372/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9808 - accuracy: 0.4706 - val_loss: 2.3927 - val_accuracy: 0.3972 - lr: 0.0050\n",
            "Epoch 373/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9750 - accuracy: 0.4712 - val_loss: 2.3891 - val_accuracy: 0.3938 - lr: 0.0050\n",
            "Epoch 374/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9760 - accuracy: 0.4713 - val_loss: 2.3881 - val_accuracy: 0.3986 - lr: 0.0050\n",
            "Epoch 375/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9776 - accuracy: 0.4689 - val_loss: 2.4310 - val_accuracy: 0.3880 - lr: 0.0050\n",
            "Epoch 376/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9749 - accuracy: 0.4729 - val_loss: 2.4020 - val_accuracy: 0.3948 - lr: 0.0050\n",
            "Epoch 377/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9851 - accuracy: 0.4701 - val_loss: 2.3794 - val_accuracy: 0.3972 - lr: 0.0050\n",
            "Epoch 378/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9755 - accuracy: 0.4685 - val_loss: 2.3792 - val_accuracy: 0.4004 - lr: 0.0050\n",
            "Epoch 379/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9719 - accuracy: 0.4722 - val_loss: 2.3672 - val_accuracy: 0.4057 - lr: 0.0050\n",
            "Epoch 380/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9765 - accuracy: 0.4708 - val_loss: 2.3810 - val_accuracy: 0.4017 - lr: 0.0050\n",
            "Epoch 381/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9754 - accuracy: 0.4713 - val_loss: 2.3660 - val_accuracy: 0.4003 - lr: 0.0050\n",
            "Epoch 382/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9763 - accuracy: 0.4722 - val_loss: 2.4018 - val_accuracy: 0.3924 - lr: 0.0050\n",
            "Epoch 383/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9738 - accuracy: 0.4713 - val_loss: 2.3718 - val_accuracy: 0.4011 - lr: 0.0050\n",
            "Epoch 384/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9711 - accuracy: 0.4705 - val_loss: 2.3745 - val_accuracy: 0.4013 - lr: 0.0050\n",
            "Epoch 385/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9776 - accuracy: 0.4687 - val_loss: 2.3791 - val_accuracy: 0.3998 - lr: 0.0050\n",
            "Epoch 386/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9766 - accuracy: 0.4696 - val_loss: 2.3641 - val_accuracy: 0.4038 - lr: 0.0050\n",
            "Epoch 387/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9670 - accuracy: 0.4710 - val_loss: 2.3792 - val_accuracy: 0.4017 - lr: 0.0050\n",
            "Epoch 388/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9776 - accuracy: 0.4698 - val_loss: 2.3775 - val_accuracy: 0.3975 - lr: 0.0050\n",
            "Epoch 389/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9739 - accuracy: 0.4714 - val_loss: 2.3842 - val_accuracy: 0.3985 - lr: 0.0050\n",
            "Epoch 390/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9767 - accuracy: 0.4666 - val_loss: 2.3738 - val_accuracy: 0.3977 - lr: 0.0050\n",
            "Epoch 391/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9721 - accuracy: 0.4737 - val_loss: 2.3764 - val_accuracy: 0.3989 - lr: 0.0050\n",
            "Epoch 392/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9636 - accuracy: 0.4736 - val_loss: 2.3790 - val_accuracy: 0.4007 - lr: 0.0050\n",
            "Epoch 393/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9661 - accuracy: 0.4719 - val_loss: 2.3737 - val_accuracy: 0.4018 - lr: 0.0050\n",
            "Epoch 394/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9644 - accuracy: 0.4750 - val_loss: 2.3633 - val_accuracy: 0.4038 - lr: 0.0050\n",
            "Epoch 395/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9727 - accuracy: 0.4725 - val_loss: 2.3635 - val_accuracy: 0.4032 - lr: 0.0050\n",
            "Epoch 396/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9658 - accuracy: 0.4749 - val_loss: 2.3685 - val_accuracy: 0.3983 - lr: 0.0050\n",
            "Epoch 397/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9681 - accuracy: 0.4717 - val_loss: 2.3706 - val_accuracy: 0.4004 - lr: 0.0050\n",
            "Epoch 398/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9620 - accuracy: 0.4715 - val_loss: 2.3735 - val_accuracy: 0.3981 - lr: 0.0050\n",
            "Epoch 399/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9686 - accuracy: 0.4740 - val_loss: 2.3966 - val_accuracy: 0.3990 - lr: 0.0050\n",
            "Epoch 400/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9716 - accuracy: 0.4718 - val_loss: 2.3723 - val_accuracy: 0.3994 - lr: 0.0050\n",
            "Epoch 401/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9461 - accuracy: 0.4768 - val_loss: 2.3595 - val_accuracy: 0.4007 - lr: 0.0030\n",
            "Epoch 402/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9491 - accuracy: 0.4788 - val_loss: 2.3694 - val_accuracy: 0.4021 - lr: 0.0030\n",
            "Epoch 403/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9478 - accuracy: 0.4780 - val_loss: 2.3759 - val_accuracy: 0.3984 - lr: 0.0030\n",
            "Epoch 404/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9540 - accuracy: 0.4770 - val_loss: 2.3662 - val_accuracy: 0.4024 - lr: 0.0030\n",
            "Epoch 405/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9564 - accuracy: 0.4763 - val_loss: 2.3640 - val_accuracy: 0.4033 - lr: 0.0030\n",
            "Epoch 406/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9513 - accuracy: 0.4791 - val_loss: 2.3743 - val_accuracy: 0.3976 - lr: 0.0030\n",
            "Epoch 407/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9457 - accuracy: 0.4755 - val_loss: 2.3716 - val_accuracy: 0.3998 - lr: 0.0030\n",
            "Epoch 408/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9474 - accuracy: 0.4772 - val_loss: 2.3724 - val_accuracy: 0.4014 - lr: 0.0030\n",
            "Epoch 409/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9508 - accuracy: 0.4761 - val_loss: 2.3599 - val_accuracy: 0.4037 - lr: 0.0030\n",
            "Epoch 410/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9522 - accuracy: 0.4774 - val_loss: 2.3646 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 411/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9431 - accuracy: 0.4778 - val_loss: 2.3637 - val_accuracy: 0.4002 - lr: 0.0030\n",
            "Epoch 412/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9432 - accuracy: 0.4770 - val_loss: 2.3517 - val_accuracy: 0.4044 - lr: 0.0030\n",
            "Epoch 413/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9431 - accuracy: 0.4768 - val_loss: 2.3670 - val_accuracy: 0.4008 - lr: 0.0030\n",
            "Epoch 414/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9460 - accuracy: 0.4790 - val_loss: 2.3750 - val_accuracy: 0.3993 - lr: 0.0030\n",
            "Epoch 415/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9463 - accuracy: 0.4769 - val_loss: 2.3660 - val_accuracy: 0.4021 - lr: 0.0030\n",
            "Epoch 416/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9500 - accuracy: 0.4779 - val_loss: 2.3664 - val_accuracy: 0.4018 - lr: 0.0030\n",
            "Epoch 417/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9408 - accuracy: 0.4806 - val_loss: 2.3851 - val_accuracy: 0.4006 - lr: 0.0030\n",
            "Epoch 418/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9462 - accuracy: 0.4766 - val_loss: 2.3649 - val_accuracy: 0.4022 - lr: 0.0030\n",
            "Epoch 419/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9431 - accuracy: 0.4797 - val_loss: 2.3633 - val_accuracy: 0.4013 - lr: 0.0030\n",
            "Epoch 420/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9402 - accuracy: 0.4808 - val_loss: 2.3696 - val_accuracy: 0.4048 - lr: 0.0030\n",
            "Epoch 421/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9409 - accuracy: 0.4776 - val_loss: 2.3611 - val_accuracy: 0.4050 - lr: 0.0030\n",
            "Epoch 422/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9467 - accuracy: 0.4784 - val_loss: 2.3709 - val_accuracy: 0.4013 - lr: 0.0030\n",
            "Epoch 423/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9484 - accuracy: 0.4770 - val_loss: 2.3660 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 424/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9427 - accuracy: 0.4790 - val_loss: 2.3651 - val_accuracy: 0.3994 - lr: 0.0030\n",
            "Epoch 425/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9426 - accuracy: 0.4779 - val_loss: 2.3725 - val_accuracy: 0.3994 - lr: 0.0030\n",
            "Epoch 426/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9421 - accuracy: 0.4795 - val_loss: 2.3639 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 427/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9414 - accuracy: 0.4789 - val_loss: 2.3608 - val_accuracy: 0.4021 - lr: 0.0030\n",
            "Epoch 428/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9416 - accuracy: 0.4779 - val_loss: 2.3668 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 429/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9400 - accuracy: 0.4795 - val_loss: 2.3614 - val_accuracy: 0.4065 - lr: 0.0030\n",
            "Epoch 430/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9365 - accuracy: 0.4785 - val_loss: 2.3682 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 431/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9374 - accuracy: 0.4792 - val_loss: 2.3729 - val_accuracy: 0.4005 - lr: 0.0030\n",
            "Epoch 432/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9389 - accuracy: 0.4799 - val_loss: 2.3688 - val_accuracy: 0.4012 - lr: 0.0030\n",
            "Epoch 433/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9399 - accuracy: 0.4797 - val_loss: 2.3744 - val_accuracy: 0.4005 - lr: 0.0030\n",
            "Epoch 434/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9376 - accuracy: 0.4781 - val_loss: 2.3704 - val_accuracy: 0.4022 - lr: 0.0030\n",
            "Epoch 435/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9383 - accuracy: 0.4802 - val_loss: 2.3747 - val_accuracy: 0.4008 - lr: 0.0030\n",
            "Epoch 436/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9384 - accuracy: 0.4786 - val_loss: 2.3668 - val_accuracy: 0.4023 - lr: 0.0030\n",
            "Epoch 437/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9351 - accuracy: 0.4814 - val_loss: 2.3592 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 438/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9355 - accuracy: 0.4783 - val_loss: 2.3639 - val_accuracy: 0.3999 - lr: 0.0030\n",
            "Epoch 439/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9328 - accuracy: 0.4822 - val_loss: 2.3662 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 440/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9367 - accuracy: 0.4798 - val_loss: 2.3659 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 441/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9385 - accuracy: 0.4804 - val_loss: 2.3589 - val_accuracy: 0.4052 - lr: 0.0030\n",
            "Epoch 442/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9385 - accuracy: 0.4769 - val_loss: 2.3660 - val_accuracy: 0.4013 - lr: 0.0030\n",
            "Epoch 443/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9309 - accuracy: 0.4820 - val_loss: 2.3597 - val_accuracy: 0.4016 - lr: 0.0030\n",
            "Epoch 444/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9325 - accuracy: 0.4804 - val_loss: 2.3658 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 445/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9400 - accuracy: 0.4790 - val_loss: 2.3606 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 446/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9320 - accuracy: 0.4815 - val_loss: 2.3802 - val_accuracy: 0.3966 - lr: 0.0030\n",
            "Epoch 447/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9318 - accuracy: 0.4810 - val_loss: 2.3529 - val_accuracy: 0.4008 - lr: 0.0030\n",
            "Epoch 448/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9284 - accuracy: 0.4800 - val_loss: 2.3647 - val_accuracy: 0.4024 - lr: 0.0030\n",
            "Epoch 449/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9332 - accuracy: 0.4805 - val_loss: 2.3663 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 450/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9317 - accuracy: 0.4792 - val_loss: 2.3629 - val_accuracy: 0.4001 - lr: 0.0030\n",
            "Epoch 451/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9381 - accuracy: 0.4800 - val_loss: 2.3660 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 452/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9307 - accuracy: 0.4793 - val_loss: 2.3568 - val_accuracy: 0.4021 - lr: 0.0030\n",
            "Epoch 453/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9334 - accuracy: 0.4782 - val_loss: 2.3622 - val_accuracy: 0.4049 - lr: 0.0030\n",
            "Epoch 454/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9334 - accuracy: 0.4783 - val_loss: 2.3674 - val_accuracy: 0.4018 - lr: 0.0030\n",
            "Epoch 455/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9310 - accuracy: 0.4806 - val_loss: 2.3678 - val_accuracy: 0.4016 - lr: 0.0030\n",
            "Epoch 456/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9319 - accuracy: 0.4794 - val_loss: 2.3646 - val_accuracy: 0.4018 - lr: 0.0030\n",
            "Epoch 457/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9375 - accuracy: 0.4804 - val_loss: 2.3758 - val_accuracy: 0.3992 - lr: 0.0030\n",
            "Epoch 458/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9286 - accuracy: 0.4810 - val_loss: 2.3591 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 459/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9296 - accuracy: 0.4799 - val_loss: 2.3725 - val_accuracy: 0.4003 - lr: 0.0030\n",
            "Epoch 460/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9338 - accuracy: 0.4790 - val_loss: 2.3677 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 461/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9292 - accuracy: 0.4811 - val_loss: 2.3547 - val_accuracy: 0.4039 - lr: 0.0030\n",
            "Epoch 462/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9337 - accuracy: 0.4817 - val_loss: 2.3653 - val_accuracy: 0.4019 - lr: 0.0030\n",
            "Epoch 463/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9284 - accuracy: 0.4820 - val_loss: 2.3646 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 464/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9231 - accuracy: 0.4804 - val_loss: 2.3607 - val_accuracy: 0.4046 - lr: 0.0030\n",
            "Epoch 465/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9276 - accuracy: 0.4799 - val_loss: 2.3669 - val_accuracy: 0.3993 - lr: 0.0030\n",
            "Epoch 466/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9281 - accuracy: 0.4813 - val_loss: 2.3595 - val_accuracy: 0.4033 - lr: 0.0030\n",
            "Epoch 467/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9238 - accuracy: 0.4811 - val_loss: 2.3687 - val_accuracy: 0.4002 - lr: 0.0030\n",
            "Epoch 468/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9283 - accuracy: 0.4805 - val_loss: 2.3646 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 469/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9248 - accuracy: 0.4841 - val_loss: 2.3704 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 470/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9295 - accuracy: 0.4822 - val_loss: 2.3614 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 471/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9246 - accuracy: 0.4817 - val_loss: 2.3612 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 472/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9288 - accuracy: 0.4794 - val_loss: 2.3545 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 473/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9272 - accuracy: 0.4805 - val_loss: 2.3673 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 474/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9270 - accuracy: 0.4830 - val_loss: 2.3548 - val_accuracy: 0.4010 - lr: 0.0030\n",
            "Epoch 475/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9292 - accuracy: 0.4830 - val_loss: 2.3685 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 476/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9220 - accuracy: 0.4821 - val_loss: 2.3538 - val_accuracy: 0.4037 - lr: 0.0030\n",
            "Epoch 477/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9200 - accuracy: 0.4819 - val_loss: 2.3564 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 478/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9264 - accuracy: 0.4791 - val_loss: 2.3615 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 479/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9283 - accuracy: 0.4791 - val_loss: 2.3610 - val_accuracy: 0.4039 - lr: 0.0030\n",
            "Epoch 480/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9194 - accuracy: 0.4814 - val_loss: 2.3723 - val_accuracy: 0.4001 - lr: 0.0030\n",
            "Epoch 481/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9266 - accuracy: 0.4820 - val_loss: 2.3604 - val_accuracy: 0.4051 - lr: 0.0030\n",
            "Epoch 482/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9207 - accuracy: 0.4837 - val_loss: 2.3601 - val_accuracy: 0.4053 - lr: 0.0030\n",
            "Epoch 483/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9262 - accuracy: 0.4798 - val_loss: 2.3819 - val_accuracy: 0.3983 - lr: 0.0030\n",
            "Epoch 484/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9252 - accuracy: 0.4826 - val_loss: 2.3547 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 485/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9205 - accuracy: 0.4823 - val_loss: 2.3597 - val_accuracy: 0.4030 - lr: 0.0030\n",
            "Epoch 486/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9200 - accuracy: 0.4835 - val_loss: 2.3696 - val_accuracy: 0.4024 - lr: 0.0030\n",
            "Epoch 487/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9224 - accuracy: 0.4816 - val_loss: 2.3564 - val_accuracy: 0.4030 - lr: 0.0030\n",
            "Epoch 488/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9237 - accuracy: 0.4829 - val_loss: 2.3590 - val_accuracy: 0.4050 - lr: 0.0030\n",
            "Epoch 489/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9226 - accuracy: 0.4818 - val_loss: 2.3582 - val_accuracy: 0.4046 - lr: 0.0030\n",
            "Epoch 490/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9188 - accuracy: 0.4830 - val_loss: 2.3586 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 491/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9141 - accuracy: 0.4849 - val_loss: 2.3576 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 492/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9249 - accuracy: 0.4817 - val_loss: 2.3698 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 493/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9183 - accuracy: 0.4832 - val_loss: 2.3584 - val_accuracy: 0.4064 - lr: 0.0030\n",
            "Epoch 494/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9226 - accuracy: 0.4829 - val_loss: 2.3614 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 495/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9188 - accuracy: 0.4838 - val_loss: 2.3548 - val_accuracy: 0.4042 - lr: 0.0030\n",
            "Epoch 496/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9156 - accuracy: 0.4831 - val_loss: 2.3825 - val_accuracy: 0.3992 - lr: 0.0030\n",
            "Epoch 497/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9208 - accuracy: 0.4834 - val_loss: 2.3551 - val_accuracy: 0.4040 - lr: 0.0030\n",
            "Epoch 498/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9201 - accuracy: 0.4827 - val_loss: 2.3655 - val_accuracy: 0.4018 - lr: 0.0030\n",
            "Epoch 499/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9171 - accuracy: 0.4849 - val_loss: 2.3534 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 500/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9173 - accuracy: 0.4835 - val_loss: 2.3597 - val_accuracy: 0.4039 - lr: 0.0030\n",
            "Epoch 501/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9140 - accuracy: 0.4843 - val_loss: 2.3813 - val_accuracy: 0.4003 - lr: 0.0030\n",
            "Epoch 502/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9167 - accuracy: 0.4826 - val_loss: 2.3643 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 503/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9115 - accuracy: 0.4855 - val_loss: 2.3935 - val_accuracy: 0.3940 - lr: 0.0030\n",
            "Epoch 504/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9161 - accuracy: 0.4833 - val_loss: 2.3612 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 505/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9143 - accuracy: 0.4854 - val_loss: 2.3693 - val_accuracy: 0.4004 - lr: 0.0030\n",
            "Epoch 506/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9175 - accuracy: 0.4814 - val_loss: 2.3685 - val_accuracy: 0.4000 - lr: 0.0030\n",
            "Epoch 507/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.9109 - accuracy: 0.4852 - val_loss: 2.3686 - val_accuracy: 0.4007 - lr: 0.0030\n",
            "Epoch 508/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9163 - accuracy: 0.4842 - val_loss: 2.3680 - val_accuracy: 0.4035 - lr: 0.0030\n",
            "Epoch 509/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9145 - accuracy: 0.4838 - val_loss: 2.3637 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 510/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9135 - accuracy: 0.4836 - val_loss: 2.3615 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 511/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9162 - accuracy: 0.4826 - val_loss: 2.3636 - val_accuracy: 0.4016 - lr: 0.0030\n",
            "Epoch 512/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9137 - accuracy: 0.4846 - val_loss: 2.3633 - val_accuracy: 0.4022 - lr: 0.0030\n",
            "Epoch 513/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9142 - accuracy: 0.4841 - val_loss: 2.3660 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 514/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9119 - accuracy: 0.4830 - val_loss: 2.3789 - val_accuracy: 0.4010 - lr: 0.0030\n",
            "Epoch 515/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9107 - accuracy: 0.4861 - val_loss: 2.3683 - val_accuracy: 0.4032 - lr: 0.0030\n",
            "Epoch 516/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9121 - accuracy: 0.4822 - val_loss: 2.3578 - val_accuracy: 0.4044 - lr: 0.0030\n",
            "Epoch 517/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9092 - accuracy: 0.4861 - val_loss: 2.3619 - val_accuracy: 0.4023 - lr: 0.0030\n",
            "Epoch 518/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9106 - accuracy: 0.4855 - val_loss: 2.3628 - val_accuracy: 0.4026 - lr: 0.0030\n",
            "Epoch 519/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9130 - accuracy: 0.4859 - val_loss: 2.3681 - val_accuracy: 0.4019 - lr: 0.0030\n",
            "Epoch 520/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9118 - accuracy: 0.4859 - val_loss: 2.3637 - val_accuracy: 0.4023 - lr: 0.0030\n",
            "Epoch 521/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9130 - accuracy: 0.4842 - val_loss: 2.3631 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 522/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9112 - accuracy: 0.4847 - val_loss: 2.3649 - val_accuracy: 0.4047 - lr: 0.0030\n",
            "Epoch 523/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9105 - accuracy: 0.4835 - val_loss: 2.3659 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 524/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9079 - accuracy: 0.4861 - val_loss: 2.3537 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 525/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9137 - accuracy: 0.4827 - val_loss: 2.3615 - val_accuracy: 0.4041 - lr: 0.0030\n",
            "Epoch 526/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9117 - accuracy: 0.4857 - val_loss: 2.3676 - val_accuracy: 0.4016 - lr: 0.0030\n",
            "Epoch 527/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9091 - accuracy: 0.4833 - val_loss: 2.3559 - val_accuracy: 0.4043 - lr: 0.0030\n",
            "Epoch 528/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9089 - accuracy: 0.4880 - val_loss: 2.3583 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 529/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9083 - accuracy: 0.4864 - val_loss: 2.3622 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 530/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9075 - accuracy: 0.4850 - val_loss: 2.3749 - val_accuracy: 0.4014 - lr: 0.0030\n",
            "Epoch 531/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9100 - accuracy: 0.4837 - val_loss: 2.3545 - val_accuracy: 0.4052 - lr: 0.0030\n",
            "Epoch 532/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9042 - accuracy: 0.4850 - val_loss: 2.3592 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 533/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9045 - accuracy: 0.4854 - val_loss: 2.3706 - val_accuracy: 0.3976 - lr: 0.0030\n",
            "Epoch 534/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9056 - accuracy: 0.4860 - val_loss: 2.3570 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 535/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9011 - accuracy: 0.4835 - val_loss: 2.3692 - val_accuracy: 0.4022 - lr: 0.0030\n",
            "Epoch 536/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9035 - accuracy: 0.4845 - val_loss: 2.3530 - val_accuracy: 0.4037 - lr: 0.0030\n",
            "Epoch 537/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9055 - accuracy: 0.4863 - val_loss: 2.3633 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 538/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9088 - accuracy: 0.4834 - val_loss: 2.3635 - val_accuracy: 0.4032 - lr: 0.0030\n",
            "Epoch 539/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9022 - accuracy: 0.4873 - val_loss: 2.3711 - val_accuracy: 0.3988 - lr: 0.0030\n",
            "Epoch 540/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9042 - accuracy: 0.4872 - val_loss: 2.3513 - val_accuracy: 0.4006 - lr: 0.0030\n",
            "Epoch 541/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9062 - accuracy: 0.4832 - val_loss: 2.3562 - val_accuracy: 0.4051 - lr: 0.0030\n",
            "Epoch 542/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9061 - accuracy: 0.4856 - val_loss: 2.3682 - val_accuracy: 0.3998 - lr: 0.0030\n",
            "Epoch 543/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9068 - accuracy: 0.4839 - val_loss: 2.3627 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 544/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8979 - accuracy: 0.4876 - val_loss: 2.3651 - val_accuracy: 0.4045 - lr: 0.0030\n",
            "Epoch 545/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9053 - accuracy: 0.4867 - val_loss: 2.3611 - val_accuracy: 0.4052 - lr: 0.0030\n",
            "Epoch 546/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9032 - accuracy: 0.4866 - val_loss: 2.3820 - val_accuracy: 0.3993 - lr: 0.0030\n",
            "Epoch 547/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8993 - accuracy: 0.4870 - val_loss: 2.3545 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 548/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9018 - accuracy: 0.4857 - val_loss: 2.3614 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 549/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9071 - accuracy: 0.4870 - val_loss: 2.3683 - val_accuracy: 0.3998 - lr: 0.0030\n",
            "Epoch 550/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9063 - accuracy: 0.4851 - val_loss: 2.3590 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 551/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9041 - accuracy: 0.4872 - val_loss: 2.3754 - val_accuracy: 0.4012 - lr: 0.0030\n",
            "Epoch 552/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9048 - accuracy: 0.4869 - val_loss: 2.3585 - val_accuracy: 0.4039 - lr: 0.0030\n",
            "Epoch 553/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9008 - accuracy: 0.4872 - val_loss: 2.3685 - val_accuracy: 0.3997 - lr: 0.0030\n",
            "Epoch 554/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8977 - accuracy: 0.4855 - val_loss: 2.3516 - val_accuracy: 0.4050 - lr: 0.0030\n",
            "Epoch 555/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9049 - accuracy: 0.4865 - val_loss: 2.3575 - val_accuracy: 0.4062 - lr: 0.0030\n",
            "Epoch 556/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8990 - accuracy: 0.4886 - val_loss: 2.3713 - val_accuracy: 0.3975 - lr: 0.0030\n",
            "Epoch 557/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9011 - accuracy: 0.4841 - val_loss: 2.3686 - val_accuracy: 0.4016 - lr: 0.0030\n",
            "Epoch 558/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9051 - accuracy: 0.4841 - val_loss: 2.3632 - val_accuracy: 0.4013 - lr: 0.0030\n",
            "Epoch 559/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9026 - accuracy: 0.4865 - val_loss: 2.3614 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 560/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9019 - accuracy: 0.4884 - val_loss: 2.3542 - val_accuracy: 0.4063 - lr: 0.0030\n",
            "Epoch 561/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9005 - accuracy: 0.4852 - val_loss: 2.3573 - val_accuracy: 0.4033 - lr: 0.0030\n",
            "Epoch 562/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8991 - accuracy: 0.4872 - val_loss: 2.3580 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 563/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8968 - accuracy: 0.4867 - val_loss: 2.3684 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 564/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8972 - accuracy: 0.4877 - val_loss: 2.3614 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 565/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8991 - accuracy: 0.4892 - val_loss: 2.3562 - val_accuracy: 0.4059 - lr: 0.0030\n",
            "Epoch 566/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9003 - accuracy: 0.4861 - val_loss: 2.3602 - val_accuracy: 0.4045 - lr: 0.0030\n",
            "Epoch 567/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8989 - accuracy: 0.4873 - val_loss: 2.3633 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 568/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8927 - accuracy: 0.4877 - val_loss: 2.3671 - val_accuracy: 0.4026 - lr: 0.0030\n",
            "Epoch 569/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9031 - accuracy: 0.4854 - val_loss: 2.3719 - val_accuracy: 0.3991 - lr: 0.0030\n",
            "Epoch 570/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8998 - accuracy: 0.4872 - val_loss: 2.3641 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 571/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8949 - accuracy: 0.4873 - val_loss: 2.3631 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 572/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9028 - accuracy: 0.4848 - val_loss: 2.3715 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 573/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8928 - accuracy: 0.4899 - val_loss: 2.3658 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 574/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8954 - accuracy: 0.4881 - val_loss: 2.3566 - val_accuracy: 0.4060 - lr: 0.0030\n",
            "Epoch 575/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8954 - accuracy: 0.4877 - val_loss: 2.3474 - val_accuracy: 0.4083 - lr: 0.0030\n",
            "Epoch 576/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8960 - accuracy: 0.4880 - val_loss: 2.3541 - val_accuracy: 0.4033 - lr: 0.0030\n",
            "Epoch 577/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8995 - accuracy: 0.4881 - val_loss: 2.3548 - val_accuracy: 0.4050 - lr: 0.0030\n",
            "Epoch 578/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8921 - accuracy: 0.4881 - val_loss: 2.3718 - val_accuracy: 0.4005 - lr: 0.0030\n",
            "Epoch 579/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8916 - accuracy: 0.4897 - val_loss: 2.3616 - val_accuracy: 0.4030 - lr: 0.0030\n",
            "Epoch 580/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8948 - accuracy: 0.4876 - val_loss: 2.3558 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 581/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8919 - accuracy: 0.4883 - val_loss: 2.3601 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 582/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8930 - accuracy: 0.4881 - val_loss: 2.3592 - val_accuracy: 0.4040 - lr: 0.0030\n",
            "Epoch 583/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8845 - accuracy: 0.4916 - val_loss: 2.3613 - val_accuracy: 0.4037 - lr: 0.0030\n",
            "Epoch 584/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8977 - accuracy: 0.4863 - val_loss: 2.3602 - val_accuracy: 0.4024 - lr: 0.0030\n",
            "Epoch 585/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8917 - accuracy: 0.4879 - val_loss: 2.3615 - val_accuracy: 0.4005 - lr: 0.0030\n",
            "Epoch 586/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8923 - accuracy: 0.4863 - val_loss: 2.3592 - val_accuracy: 0.4051 - lr: 0.0030\n",
            "Epoch 587/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8950 - accuracy: 0.4887 - val_loss: 2.3689 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 588/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8921 - accuracy: 0.4897 - val_loss: 2.3683 - val_accuracy: 0.4006 - lr: 0.0030\n",
            "Epoch 589/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8949 - accuracy: 0.4874 - val_loss: 2.3580 - val_accuracy: 0.4035 - lr: 0.0030\n",
            "Epoch 590/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8952 - accuracy: 0.4880 - val_loss: 2.3613 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 591/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8881 - accuracy: 0.4895 - val_loss: 2.3681 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 592/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8880 - accuracy: 0.4872 - val_loss: 2.3713 - val_accuracy: 0.4021 - lr: 0.0030\n",
            "Epoch 593/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8874 - accuracy: 0.4890 - val_loss: 2.3517 - val_accuracy: 0.4051 - lr: 0.0030\n",
            "Epoch 594/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8866 - accuracy: 0.4902 - val_loss: 2.3758 - val_accuracy: 0.4009 - lr: 0.0030\n",
            "Epoch 595/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8890 - accuracy: 0.4894 - val_loss: 2.3629 - val_accuracy: 0.4044 - lr: 0.0030\n",
            "Epoch 596/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8910 - accuracy: 0.4885 - val_loss: 2.3508 - val_accuracy: 0.4053 - lr: 0.0030\n",
            "Epoch 597/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8883 - accuracy: 0.4898 - val_loss: 2.3573 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 598/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8844 - accuracy: 0.4889 - val_loss: 2.3622 - val_accuracy: 0.4053 - lr: 0.0030\n",
            "Epoch 599/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8817 - accuracy: 0.4907 - val_loss: 2.3521 - val_accuracy: 0.4075 - lr: 0.0030\n",
            "Epoch 600/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8869 - accuracy: 0.4906 - val_loss: 2.3698 - val_accuracy: 0.4016 - lr: 0.0030\n",
            "Epoch 601/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8904 - accuracy: 0.4883 - val_loss: 2.3589 - val_accuracy: 0.4048 - lr: 0.0030\n",
            "Epoch 602/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8899 - accuracy: 0.4893 - val_loss: 2.3667 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 603/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8870 - accuracy: 0.4898 - val_loss: 2.3677 - val_accuracy: 0.4017 - lr: 0.0030\n",
            "Epoch 604/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8908 - accuracy: 0.4891 - val_loss: 2.3556 - val_accuracy: 0.4051 - lr: 0.0030\n",
            "Epoch 605/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8835 - accuracy: 0.4898 - val_loss: 2.3568 - val_accuracy: 0.4040 - lr: 0.0030\n",
            "Epoch 606/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8872 - accuracy: 0.4892 - val_loss: 2.3520 - val_accuracy: 0.4049 - lr: 0.0030\n",
            "Epoch 607/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8876 - accuracy: 0.4900 - val_loss: 2.3653 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 608/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8858 - accuracy: 0.4921 - val_loss: 2.3515 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 609/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8825 - accuracy: 0.4913 - val_loss: 2.3792 - val_accuracy: 0.3993 - lr: 0.0030\n",
            "Epoch 610/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8796 - accuracy: 0.4895 - val_loss: 2.3587 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 611/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8825 - accuracy: 0.4910 - val_loss: 2.3696 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 612/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8833 - accuracy: 0.4908 - val_loss: 2.3550 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 613/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8909 - accuracy: 0.4895 - val_loss: 2.3634 - val_accuracy: 0.4037 - lr: 0.0030\n",
            "Epoch 614/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8825 - accuracy: 0.4904 - val_loss: 2.3598 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 615/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8900 - accuracy: 0.4905 - val_loss: 2.3579 - val_accuracy: 0.4044 - lr: 0.0030\n",
            "Epoch 616/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8798 - accuracy: 0.4903 - val_loss: 2.3655 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 617/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8869 - accuracy: 0.4918 - val_loss: 2.3552 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 618/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8825 - accuracy: 0.4908 - val_loss: 2.3502 - val_accuracy: 0.4069 - lr: 0.0030\n",
            "Epoch 619/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8742 - accuracy: 0.4916 - val_loss: 2.3596 - val_accuracy: 0.4031 - lr: 0.0030\n",
            "Epoch 620/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8795 - accuracy: 0.4925 - val_loss: 2.3612 - val_accuracy: 0.4051 - lr: 0.0030\n",
            "Epoch 621/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8862 - accuracy: 0.4882 - val_loss: 2.3586 - val_accuracy: 0.4044 - lr: 0.0030\n",
            "Epoch 622/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8858 - accuracy: 0.4907 - val_loss: 2.3564 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 623/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8793 - accuracy: 0.4896 - val_loss: 2.3478 - val_accuracy: 0.4065 - lr: 0.0030\n",
            "Epoch 624/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8841 - accuracy: 0.4904 - val_loss: 2.3715 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 625/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8817 - accuracy: 0.4893 - val_loss: 2.3620 - val_accuracy: 0.4043 - lr: 0.0030\n",
            "Epoch 626/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8822 - accuracy: 0.4907 - val_loss: 2.3642 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 627/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8853 - accuracy: 0.4889 - val_loss: 2.3638 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 628/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8873 - accuracy: 0.4894 - val_loss: 2.3663 - val_accuracy: 0.4014 - lr: 0.0030\n",
            "Epoch 629/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8855 - accuracy: 0.4888 - val_loss: 2.3902 - val_accuracy: 0.3974 - lr: 0.0030\n",
            "Epoch 630/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8816 - accuracy: 0.4885 - val_loss: 2.3683 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 631/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8755 - accuracy: 0.4927 - val_loss: 2.3641 - val_accuracy: 0.4042 - lr: 0.0030\n",
            "Epoch 632/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8834 - accuracy: 0.4884 - val_loss: 2.3602 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 633/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8833 - accuracy: 0.4881 - val_loss: 2.3537 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 634/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8770 - accuracy: 0.4910 - val_loss: 2.3522 - val_accuracy: 0.4052 - lr: 0.0030\n",
            "Epoch 635/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8812 - accuracy: 0.4910 - val_loss: 2.3552 - val_accuracy: 0.4042 - lr: 0.0030\n",
            "Epoch 636/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8787 - accuracy: 0.4900 - val_loss: 2.3578 - val_accuracy: 0.4039 - lr: 0.0030\n",
            "Epoch 637/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8809 - accuracy: 0.4885 - val_loss: 2.3640 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 638/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8790 - accuracy: 0.4907 - val_loss: 2.3607 - val_accuracy: 0.4033 - lr: 0.0030\n",
            "Epoch 639/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8829 - accuracy: 0.4910 - val_loss: 2.3569 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 640/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8769 - accuracy: 0.4925 - val_loss: 2.3723 - val_accuracy: 0.4034 - lr: 0.0030\n",
            "Epoch 641/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8754 - accuracy: 0.4955 - val_loss: 2.3454 - val_accuracy: 0.4090 - lr: 0.0030\n",
            "Epoch 642/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8814 - accuracy: 0.4906 - val_loss: 2.3569 - val_accuracy: 0.4022 - lr: 0.0030\n",
            "Epoch 643/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8659 - accuracy: 0.4944 - val_loss: 2.3537 - val_accuracy: 0.4059 - lr: 0.0030\n",
            "Epoch 644/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8837 - accuracy: 0.4894 - val_loss: 2.3567 - val_accuracy: 0.4049 - lr: 0.0030\n",
            "Epoch 645/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8708 - accuracy: 0.4920 - val_loss: 2.3555 - val_accuracy: 0.4040 - lr: 0.0030\n",
            "Epoch 646/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8801 - accuracy: 0.4920 - val_loss: 2.3572 - val_accuracy: 0.4050 - lr: 0.0030\n",
            "Epoch 647/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8729 - accuracy: 0.4913 - val_loss: 2.3651 - val_accuracy: 0.4026 - lr: 0.0030\n",
            "Epoch 648/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8794 - accuracy: 0.4907 - val_loss: 2.3638 - val_accuracy: 0.4004 - lr: 0.0030\n",
            "Epoch 649/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8694 - accuracy: 0.4929 - val_loss: 2.3724 - val_accuracy: 0.4013 - lr: 0.0030\n",
            "Epoch 650/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8758 - accuracy: 0.4911 - val_loss: 2.3548 - val_accuracy: 0.4028 - lr: 0.0030\n",
            "Epoch 651/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8762 - accuracy: 0.4922 - val_loss: 2.3602 - val_accuracy: 0.4043 - lr: 0.0030\n",
            "Epoch 652/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8764 - accuracy: 0.4927 - val_loss: 2.3535 - val_accuracy: 0.4061 - lr: 0.0030\n",
            "Epoch 653/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8749 - accuracy: 0.4928 - val_loss: 2.3673 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 654/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8682 - accuracy: 0.4925 - val_loss: 2.3529 - val_accuracy: 0.4083 - lr: 0.0030\n",
            "Epoch 655/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8672 - accuracy: 0.4941 - val_loss: 2.3816 - val_accuracy: 0.3984 - lr: 0.0030\n",
            "Epoch 656/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8663 - accuracy: 0.4921 - val_loss: 2.3575 - val_accuracy: 0.4036 - lr: 0.0030\n",
            "Epoch 657/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8791 - accuracy: 0.4927 - val_loss: 2.3579 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 658/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8762 - accuracy: 0.4928 - val_loss: 2.3541 - val_accuracy: 0.4069 - lr: 0.0030\n",
            "Epoch 659/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8653 - accuracy: 0.4935 - val_loss: 2.3866 - val_accuracy: 0.3952 - lr: 0.0030\n",
            "Epoch 660/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8749 - accuracy: 0.4908 - val_loss: 2.3600 - val_accuracy: 0.4043 - lr: 0.0030\n",
            "Epoch 661/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8673 - accuracy: 0.4944 - val_loss: 2.3575 - val_accuracy: 0.4023 - lr: 0.0030\n",
            "Epoch 662/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8686 - accuracy: 0.4937 - val_loss: 2.3522 - val_accuracy: 0.4055 - lr: 0.0030\n",
            "Epoch 663/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8746 - accuracy: 0.4899 - val_loss: 2.3505 - val_accuracy: 0.4012 - lr: 0.0030\n",
            "Epoch 664/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8672 - accuracy: 0.4937 - val_loss: 2.3527 - val_accuracy: 0.4061 - lr: 0.0030\n",
            "Epoch 665/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8688 - accuracy: 0.4937 - val_loss: 2.3587 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 666/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8714 - accuracy: 0.4930 - val_loss: 2.3682 - val_accuracy: 0.3996 - lr: 0.0030\n",
            "Epoch 667/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8677 - accuracy: 0.4944 - val_loss: 2.3511 - val_accuracy: 0.4049 - lr: 0.0030\n",
            "Epoch 668/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8717 - accuracy: 0.4928 - val_loss: 2.3591 - val_accuracy: 0.4023 - lr: 0.0030\n",
            "Epoch 669/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8678 - accuracy: 0.4924 - val_loss: 2.3575 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 670/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8676 - accuracy: 0.4953 - val_loss: 2.3609 - val_accuracy: 0.4042 - lr: 0.0030\n",
            "Epoch 671/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8657 - accuracy: 0.4930 - val_loss: 2.3678 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 672/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8670 - accuracy: 0.4954 - val_loss: 2.3761 - val_accuracy: 0.4018 - lr: 0.0030\n",
            "Epoch 673/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8724 - accuracy: 0.4915 - val_loss: 2.3612 - val_accuracy: 0.4010 - lr: 0.0030\n",
            "Epoch 674/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8675 - accuracy: 0.4945 - val_loss: 2.3508 - val_accuracy: 0.4077 - lr: 0.0030\n",
            "Epoch 675/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8716 - accuracy: 0.4947 - val_loss: 2.3593 - val_accuracy: 0.4026 - lr: 0.0030\n",
            "Epoch 676/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8621 - accuracy: 0.4956 - val_loss: 2.3544 - val_accuracy: 0.4040 - lr: 0.0030\n",
            "Epoch 677/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8668 - accuracy: 0.4942 - val_loss: 2.3611 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 678/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8731 - accuracy: 0.4939 - val_loss: 2.3524 - val_accuracy: 0.4078 - lr: 0.0030\n",
            "Epoch 679/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8654 - accuracy: 0.4928 - val_loss: 2.3521 - val_accuracy: 0.4035 - lr: 0.0030\n",
            "Epoch 680/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8726 - accuracy: 0.4933 - val_loss: 2.3669 - val_accuracy: 0.4011 - lr: 0.0030\n",
            "Epoch 681/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8655 - accuracy: 0.4949 - val_loss: 2.3590 - val_accuracy: 0.4025 - lr: 0.0030\n",
            "Epoch 682/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8714 - accuracy: 0.4920 - val_loss: 2.3774 - val_accuracy: 0.3991 - lr: 0.0030\n",
            "Epoch 683/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8662 - accuracy: 0.4946 - val_loss: 2.3562 - val_accuracy: 0.4056 - lr: 0.0030\n",
            "Epoch 684/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8634 - accuracy: 0.4939 - val_loss: 2.3612 - val_accuracy: 0.4029 - lr: 0.0030\n",
            "Epoch 685/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8652 - accuracy: 0.4926 - val_loss: 2.3600 - val_accuracy: 0.4058 - lr: 0.0030\n",
            "Epoch 686/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8694 - accuracy: 0.4952 - val_loss: 2.3633 - val_accuracy: 0.4039 - lr: 0.0030\n",
            "Epoch 687/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8714 - accuracy: 0.4930 - val_loss: 2.3597 - val_accuracy: 0.4026 - lr: 0.0030\n",
            "Epoch 688/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8690 - accuracy: 0.4907 - val_loss: 2.3681 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 689/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8653 - accuracy: 0.4947 - val_loss: 2.3597 - val_accuracy: 0.4027 - lr: 0.0030\n",
            "Epoch 690/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8599 - accuracy: 0.4949 - val_loss: 2.3557 - val_accuracy: 0.4062 - lr: 0.0030\n",
            "Epoch 691/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8608 - accuracy: 0.4913 - val_loss: 2.3564 - val_accuracy: 0.4049 - lr: 0.0030\n",
            "Epoch 692/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8621 - accuracy: 0.4964 - val_loss: 2.3532 - val_accuracy: 0.4046 - lr: 0.0030\n",
            "Epoch 693/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8618 - accuracy: 0.4940 - val_loss: 2.3703 - val_accuracy: 0.4001 - lr: 0.0030\n",
            "Epoch 694/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8615 - accuracy: 0.4974 - val_loss: 2.3523 - val_accuracy: 0.4061 - lr: 0.0030\n",
            "Epoch 695/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8611 - accuracy: 0.4957 - val_loss: 2.3663 - val_accuracy: 0.4042 - lr: 0.0030\n",
            "Epoch 696/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8590 - accuracy: 0.4969 - val_loss: 2.3525 - val_accuracy: 0.4059 - lr: 0.0030\n",
            "Epoch 697/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8654 - accuracy: 0.4963 - val_loss: 2.3637 - val_accuracy: 0.4022 - lr: 0.0030\n",
            "Epoch 698/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8616 - accuracy: 0.4944 - val_loss: 2.3635 - val_accuracy: 0.4038 - lr: 0.0030\n",
            "Epoch 699/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8581 - accuracy: 0.4947 - val_loss: 2.3638 - val_accuracy: 0.4042 - lr: 0.0030\n",
            "Epoch 700/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8612 - accuracy: 0.4956 - val_loss: 2.3647 - val_accuracy: 0.4020 - lr: 0.0030\n",
            "Epoch 701/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8459 - accuracy: 0.4993 - val_loss: 2.3486 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 702/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8545 - accuracy: 0.4965 - val_loss: 2.3529 - val_accuracy: 0.4068 - lr: 0.0010\n",
            "Epoch 703/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8482 - accuracy: 0.4966 - val_loss: 2.3583 - val_accuracy: 0.4052 - lr: 0.0010\n",
            "Epoch 704/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8472 - accuracy: 0.4980 - val_loss: 2.3495 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 705/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8571 - accuracy: 0.4970 - val_loss: 2.3494 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 706/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8468 - accuracy: 0.4990 - val_loss: 2.3526 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 707/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8492 - accuracy: 0.4986 - val_loss: 2.3510 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 708/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8484 - accuracy: 0.4978 - val_loss: 2.3582 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 709/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8505 - accuracy: 0.5004 - val_loss: 2.3519 - val_accuracy: 0.4065 - lr: 0.0010\n",
            "Epoch 710/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8518 - accuracy: 0.4989 - val_loss: 2.3537 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 711/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8466 - accuracy: 0.4957 - val_loss: 2.3532 - val_accuracy: 0.4043 - lr: 0.0010\n",
            "Epoch 712/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8498 - accuracy: 0.5000 - val_loss: 2.3486 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 713/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8476 - accuracy: 0.4987 - val_loss: 2.3484 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 714/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8446 - accuracy: 0.4982 - val_loss: 2.3479 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 715/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8496 - accuracy: 0.4990 - val_loss: 2.3530 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 716/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8462 - accuracy: 0.5010 - val_loss: 2.3532 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 717/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8534 - accuracy: 0.4974 - val_loss: 2.3525 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 718/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8529 - accuracy: 0.4970 - val_loss: 2.3494 - val_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 719/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8470 - accuracy: 0.4992 - val_loss: 2.3496 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 720/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8482 - accuracy: 0.4988 - val_loss: 2.3538 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 721/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8457 - accuracy: 0.4984 - val_loss: 2.3539 - val_accuracy: 0.4043 - lr: 0.0010\n",
            "Epoch 722/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8447 - accuracy: 0.5009 - val_loss: 2.3467 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 723/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8478 - accuracy: 0.5004 - val_loss: 2.3585 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 724/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8455 - accuracy: 0.4973 - val_loss: 2.3544 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 725/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8494 - accuracy: 0.4984 - val_loss: 2.3515 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 726/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8436 - accuracy: 0.4997 - val_loss: 2.3535 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 727/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8406 - accuracy: 0.5003 - val_loss: 2.3562 - val_accuracy: 0.4052 - lr: 0.0010\n",
            "Epoch 728/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8512 - accuracy: 0.4976 - val_loss: 2.3535 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 729/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8449 - accuracy: 0.4993 - val_loss: 2.3510 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 730/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8447 - accuracy: 0.5002 - val_loss: 2.3518 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 731/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8433 - accuracy: 0.4993 - val_loss: 2.3589 - val_accuracy: 0.4055 - lr: 0.0010\n",
            "Epoch 732/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8471 - accuracy: 0.4994 - val_loss: 2.3506 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 733/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8466 - accuracy: 0.4985 - val_loss: 2.3470 - val_accuracy: 0.4063 - lr: 0.0010\n",
            "Epoch 734/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8446 - accuracy: 0.5001 - val_loss: 2.3504 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 735/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8488 - accuracy: 0.4983 - val_loss: 2.3665 - val_accuracy: 0.4032 - lr: 0.0010\n",
            "Epoch 736/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8425 - accuracy: 0.5020 - val_loss: 2.3536 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 737/1000\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.8455 - accuracy: 0.5005 - val_loss: 2.3549 - val_accuracy: 0.4056 - lr: 0.0010\n",
            "Epoch 738/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8418 - accuracy: 0.4996 - val_loss: 2.3537 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 739/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8472 - accuracy: 0.4984 - val_loss: 2.3523 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 740/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8436 - accuracy: 0.5010 - val_loss: 2.3538 - val_accuracy: 0.4045 - lr: 0.0010\n",
            "Epoch 741/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8475 - accuracy: 0.4979 - val_loss: 2.3479 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 742/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8459 - accuracy: 0.5003 - val_loss: 2.3526 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 743/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8425 - accuracy: 0.4994 - val_loss: 2.3524 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 744/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8459 - accuracy: 0.5007 - val_loss: 2.3453 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 745/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8453 - accuracy: 0.4998 - val_loss: 2.3544 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 746/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8414 - accuracy: 0.5006 - val_loss: 2.3601 - val_accuracy: 0.4039 - lr: 0.0010\n",
            "Epoch 747/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8465 - accuracy: 0.4984 - val_loss: 2.3557 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 748/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8406 - accuracy: 0.4985 - val_loss: 2.3541 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 749/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8456 - accuracy: 0.5001 - val_loss: 2.3552 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 750/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8503 - accuracy: 0.4987 - val_loss: 2.3492 - val_accuracy: 0.4092 - lr: 0.0010\n",
            "Epoch 751/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8391 - accuracy: 0.4986 - val_loss: 2.3514 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 752/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8420 - accuracy: 0.4995 - val_loss: 2.3550 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 753/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8391 - accuracy: 0.5007 - val_loss: 2.3542 - val_accuracy: 0.4043 - lr: 0.0010\n",
            "Epoch 754/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8322 - accuracy: 0.5018 - val_loss: 2.3567 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 755/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8459 - accuracy: 0.5000 - val_loss: 2.3556 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 756/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8393 - accuracy: 0.5005 - val_loss: 2.3509 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 757/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8449 - accuracy: 0.4998 - val_loss: 2.3520 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 758/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8440 - accuracy: 0.5007 - val_loss: 2.3576 - val_accuracy: 0.4034 - lr: 0.0010\n",
            "Epoch 759/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8461 - accuracy: 0.4968 - val_loss: 2.3540 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 760/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8363 - accuracy: 0.5029 - val_loss: 2.3524 - val_accuracy: 0.4047 - lr: 0.0010\n",
            "Epoch 761/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8380 - accuracy: 0.5010 - val_loss: 2.3568 - val_accuracy: 0.4041 - lr: 0.0010\n",
            "Epoch 762/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8395 - accuracy: 0.5045 - val_loss: 2.3460 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 763/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8418 - accuracy: 0.4997 - val_loss: 2.3539 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 764/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8399 - accuracy: 0.5003 - val_loss: 2.3502 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 765/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8481 - accuracy: 0.4978 - val_loss: 2.3554 - val_accuracy: 0.4042 - lr: 0.0010\n",
            "Epoch 766/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8476 - accuracy: 0.4972 - val_loss: 2.3502 - val_accuracy: 0.4047 - lr: 0.0010\n",
            "Epoch 767/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8444 - accuracy: 0.4964 - val_loss: 2.3518 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 768/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8453 - accuracy: 0.4986 - val_loss: 2.3543 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 769/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8395 - accuracy: 0.5016 - val_loss: 2.3491 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 770/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8357 - accuracy: 0.5023 - val_loss: 2.3475 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 771/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8464 - accuracy: 0.5016 - val_loss: 2.3536 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 772/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8447 - accuracy: 0.4985 - val_loss: 2.3494 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 773/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8459 - accuracy: 0.4976 - val_loss: 2.3557 - val_accuracy: 0.4032 - lr: 0.0010\n",
            "Epoch 774/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8406 - accuracy: 0.4978 - val_loss: 2.3490 - val_accuracy: 0.4086 - lr: 0.0010\n",
            "Epoch 775/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8444 - accuracy: 0.4989 - val_loss: 2.3482 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 776/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8418 - accuracy: 0.5001 - val_loss: 2.3521 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 777/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8470 - accuracy: 0.4973 - val_loss: 2.3518 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 778/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8386 - accuracy: 0.5007 - val_loss: 2.3560 - val_accuracy: 0.4056 - lr: 0.0010\n",
            "Epoch 779/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8453 - accuracy: 0.4967 - val_loss: 2.3626 - val_accuracy: 0.4018 - lr: 0.0010\n",
            "Epoch 780/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8454 - accuracy: 0.5001 - val_loss: 2.3604 - val_accuracy: 0.4041 - lr: 0.0010\n",
            "Epoch 781/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8425 - accuracy: 0.4974 - val_loss: 2.3612 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 782/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8383 - accuracy: 0.5005 - val_loss: 2.3510 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 783/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8446 - accuracy: 0.4985 - val_loss: 2.3529 - val_accuracy: 0.4052 - lr: 0.0010\n",
            "Epoch 784/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8385 - accuracy: 0.4993 - val_loss: 2.3487 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 785/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8400 - accuracy: 0.5008 - val_loss: 2.3546 - val_accuracy: 0.4045 - lr: 0.0010\n",
            "Epoch 786/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8390 - accuracy: 0.4991 - val_loss: 2.3539 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 787/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8428 - accuracy: 0.5004 - val_loss: 2.3522 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 788/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8414 - accuracy: 0.4976 - val_loss: 2.3539 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 789/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8448 - accuracy: 0.4989 - val_loss: 2.3571 - val_accuracy: 0.4038 - lr: 0.0010\n",
            "Epoch 790/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8416 - accuracy: 0.5011 - val_loss: 2.3520 - val_accuracy: 0.4046 - lr: 0.0010\n",
            "Epoch 791/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8396 - accuracy: 0.4998 - val_loss: 2.3530 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 792/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8327 - accuracy: 0.5024 - val_loss: 2.3556 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 793/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8424 - accuracy: 0.4978 - val_loss: 2.3508 - val_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 794/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8395 - accuracy: 0.5001 - val_loss: 2.3528 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 795/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8414 - accuracy: 0.5009 - val_loss: 2.3486 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 796/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8468 - accuracy: 0.4974 - val_loss: 2.3631 - val_accuracy: 0.4013 - lr: 0.0010\n",
            "Epoch 797/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8399 - accuracy: 0.4987 - val_loss: 2.3546 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 798/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8333 - accuracy: 0.5003 - val_loss: 2.3521 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 799/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8399 - accuracy: 0.5008 - val_loss: 2.3503 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 800/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8461 - accuracy: 0.4977 - val_loss: 2.3523 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 801/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8399 - accuracy: 0.5009 - val_loss: 2.3559 - val_accuracy: 0.4045 - lr: 0.0010\n",
            "Epoch 802/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8386 - accuracy: 0.5017 - val_loss: 2.3482 - val_accuracy: 0.4087 - lr: 0.0010\n",
            "Epoch 803/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8374 - accuracy: 0.5008 - val_loss: 2.3532 - val_accuracy: 0.4079 - lr: 0.0010\n",
            "Epoch 804/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8418 - accuracy: 0.4980 - val_loss: 2.3571 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 805/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8391 - accuracy: 0.5015 - val_loss: 2.3505 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 806/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8394 - accuracy: 0.5009 - val_loss: 2.3490 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 807/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8432 - accuracy: 0.5022 - val_loss: 2.3493 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 808/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8361 - accuracy: 0.5037 - val_loss: 2.3510 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 809/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8411 - accuracy: 0.5006 - val_loss: 2.3509 - val_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 810/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8331 - accuracy: 0.5020 - val_loss: 2.3466 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 811/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8319 - accuracy: 0.5037 - val_loss: 2.3521 - val_accuracy: 0.4065 - lr: 0.0010\n",
            "Epoch 812/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8336 - accuracy: 0.5017 - val_loss: 2.3552 - val_accuracy: 0.4052 - lr: 0.0010\n",
            "Epoch 813/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8405 - accuracy: 0.4996 - val_loss: 2.3495 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 814/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8334 - accuracy: 0.5015 - val_loss: 2.3517 - val_accuracy: 0.4035 - lr: 0.0010\n",
            "Epoch 815/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8284 - accuracy: 0.5017 - val_loss: 2.3538 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 816/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8386 - accuracy: 0.4976 - val_loss: 2.3513 - val_accuracy: 0.4055 - lr: 0.0010\n",
            "Epoch 817/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8460 - accuracy: 0.4975 - val_loss: 2.3535 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 818/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8475 - accuracy: 0.4980 - val_loss: 2.3465 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 819/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8335 - accuracy: 0.4987 - val_loss: 2.3531 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 820/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8356 - accuracy: 0.5026 - val_loss: 2.3561 - val_accuracy: 0.4056 - lr: 0.0010\n",
            "Epoch 821/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8459 - accuracy: 0.4993 - val_loss: 2.3611 - val_accuracy: 0.4022 - lr: 0.0010\n",
            "Epoch 822/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8323 - accuracy: 0.5009 - val_loss: 2.3592 - val_accuracy: 0.4030 - lr: 0.0010\n",
            "Epoch 823/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8420 - accuracy: 0.4989 - val_loss: 2.3502 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 824/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8338 - accuracy: 0.5015 - val_loss: 2.3561 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 825/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8397 - accuracy: 0.5002 - val_loss: 2.3555 - val_accuracy: 0.4063 - lr: 0.0010\n",
            "Epoch 826/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8320 - accuracy: 0.5025 - val_loss: 2.3543 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 827/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8371 - accuracy: 0.5006 - val_loss: 2.3484 - val_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 828/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8346 - accuracy: 0.5000 - val_loss: 2.3601 - val_accuracy: 0.4029 - lr: 0.0010\n",
            "Epoch 829/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8349 - accuracy: 0.5020 - val_loss: 2.3486 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 830/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8337 - accuracy: 0.4996 - val_loss: 2.3557 - val_accuracy: 0.4045 - lr: 0.0010\n",
            "Epoch 831/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8404 - accuracy: 0.4987 - val_loss: 2.3516 - val_accuracy: 0.4068 - lr: 0.0010\n",
            "Epoch 832/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8325 - accuracy: 0.5008 - val_loss: 2.3577 - val_accuracy: 0.4046 - lr: 0.0010\n",
            "Epoch 833/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8419 - accuracy: 0.4996 - val_loss: 2.3513 - val_accuracy: 0.4042 - lr: 0.0010\n",
            "Epoch 834/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8319 - accuracy: 0.5018 - val_loss: 2.3514 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 835/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8382 - accuracy: 0.5003 - val_loss: 2.3481 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 836/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8403 - accuracy: 0.5022 - val_loss: 2.3570 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 837/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8397 - accuracy: 0.5013 - val_loss: 2.3586 - val_accuracy: 0.4055 - lr: 0.0010\n",
            "Epoch 838/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8342 - accuracy: 0.5005 - val_loss: 2.3567 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 839/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8366 - accuracy: 0.5012 - val_loss: 2.3518 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 840/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8314 - accuracy: 0.5034 - val_loss: 2.3530 - val_accuracy: 0.4056 - lr: 0.0010\n",
            "Epoch 841/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8344 - accuracy: 0.5041 - val_loss: 2.3522 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 842/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8397 - accuracy: 0.4999 - val_loss: 2.3482 - val_accuracy: 0.4068 - lr: 0.0010\n",
            "Epoch 843/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8364 - accuracy: 0.5002 - val_loss: 2.3504 - val_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 844/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8328 - accuracy: 0.5015 - val_loss: 2.3586 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 845/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8405 - accuracy: 0.5008 - val_loss: 2.3542 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 846/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8362 - accuracy: 0.5009 - val_loss: 2.3501 - val_accuracy: 0.4069 - lr: 0.0010\n",
            "Epoch 847/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8383 - accuracy: 0.4988 - val_loss: 2.3464 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 848/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8382 - accuracy: 0.4994 - val_loss: 2.3571 - val_accuracy: 0.4037 - lr: 0.0010\n",
            "Epoch 849/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8290 - accuracy: 0.5024 - val_loss: 2.3519 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 850/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8327 - accuracy: 0.5022 - val_loss: 2.3502 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 851/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8366 - accuracy: 0.5031 - val_loss: 2.3534 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 852/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8316 - accuracy: 0.5056 - val_loss: 2.3495 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 853/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8419 - accuracy: 0.5016 - val_loss: 2.3517 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 854/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8403 - accuracy: 0.5017 - val_loss: 2.3624 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 855/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8356 - accuracy: 0.5010 - val_loss: 2.3551 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 856/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8381 - accuracy: 0.4983 - val_loss: 2.3542 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 857/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8327 - accuracy: 0.5006 - val_loss: 2.3511 - val_accuracy: 0.4075 - lr: 0.0010\n",
            "Epoch 858/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8340 - accuracy: 0.5031 - val_loss: 2.3565 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 859/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8293 - accuracy: 0.5020 - val_loss: 2.3543 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 860/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8363 - accuracy: 0.5035 - val_loss: 2.3545 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 861/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8334 - accuracy: 0.5033 - val_loss: 2.3504 - val_accuracy: 0.4102 - lr: 0.0010\n",
            "Epoch 862/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8352 - accuracy: 0.5010 - val_loss: 2.3532 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 863/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8337 - accuracy: 0.5023 - val_loss: 2.3512 - val_accuracy: 0.4080 - lr: 0.0010\n",
            "Epoch 864/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8309 - accuracy: 0.5026 - val_loss: 2.3516 - val_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 865/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8361 - accuracy: 0.5024 - val_loss: 2.3476 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 866/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8399 - accuracy: 0.5009 - val_loss: 2.3473 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 867/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8303 - accuracy: 0.5015 - val_loss: 2.3502 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 868/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8335 - accuracy: 0.5023 - val_loss: 2.3567 - val_accuracy: 0.4035 - lr: 0.0010\n",
            "Epoch 869/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8356 - accuracy: 0.5000 - val_loss: 2.3521 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 870/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8295 - accuracy: 0.5051 - val_loss: 2.3559 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 871/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8347 - accuracy: 0.4991 - val_loss: 2.3566 - val_accuracy: 0.4033 - lr: 0.0010\n",
            "Epoch 872/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8367 - accuracy: 0.5004 - val_loss: 2.3505 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 873/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8390 - accuracy: 0.5011 - val_loss: 2.3539 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 874/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8308 - accuracy: 0.5020 - val_loss: 2.3535 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 875/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8352 - accuracy: 0.5014 - val_loss: 2.3561 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 876/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8387 - accuracy: 0.4994 - val_loss: 2.3549 - val_accuracy: 0.4056 - lr: 0.0010\n",
            "Epoch 877/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8313 - accuracy: 0.5051 - val_loss: 2.3523 - val_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 878/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8327 - accuracy: 0.5003 - val_loss: 2.3550 - val_accuracy: 0.4063 - lr: 0.0010\n",
            "Epoch 879/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8364 - accuracy: 0.5002 - val_loss: 2.3557 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 880/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8272 - accuracy: 0.5029 - val_loss: 2.3456 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 881/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8349 - accuracy: 0.4994 - val_loss: 2.3553 - val_accuracy: 0.4032 - lr: 0.0010\n",
            "Epoch 882/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8370 - accuracy: 0.5020 - val_loss: 2.3488 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 883/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8353 - accuracy: 0.5026 - val_loss: 2.3542 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 884/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8323 - accuracy: 0.5027 - val_loss: 2.3498 - val_accuracy: 0.4052 - lr: 0.0010\n",
            "Epoch 885/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8367 - accuracy: 0.4990 - val_loss: 2.3543 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 886/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8329 - accuracy: 0.4978 - val_loss: 2.3558 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 887/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8327 - accuracy: 0.5003 - val_loss: 2.3555 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 888/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8376 - accuracy: 0.5001 - val_loss: 2.3506 - val_accuracy: 0.4046 - lr: 0.0010\n",
            "Epoch 889/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8264 - accuracy: 0.5039 - val_loss: 2.3464 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 890/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8330 - accuracy: 0.4996 - val_loss: 2.3496 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 891/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8387 - accuracy: 0.5010 - val_loss: 2.3480 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 892/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8344 - accuracy: 0.5018 - val_loss: 2.3473 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 893/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8323 - accuracy: 0.5029 - val_loss: 2.3548 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 894/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8383 - accuracy: 0.5000 - val_loss: 2.3510 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 895/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8314 - accuracy: 0.5019 - val_loss: 2.3519 - val_accuracy: 0.4055 - lr: 0.0010\n",
            "Epoch 896/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8353 - accuracy: 0.5009 - val_loss: 2.3539 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 897/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8245 - accuracy: 0.5012 - val_loss: 2.3564 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 898/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8274 - accuracy: 0.5028 - val_loss: 2.3498 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 899/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8324 - accuracy: 0.5013 - val_loss: 2.3538 - val_accuracy: 0.4075 - lr: 0.0010\n",
            "Epoch 900/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8252 - accuracy: 0.5021 - val_loss: 2.3500 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 901/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8304 - accuracy: 0.5043 - val_loss: 2.3557 - val_accuracy: 0.4045 - lr: 0.0010\n",
            "Epoch 902/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8368 - accuracy: 0.5015 - val_loss: 2.3546 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 903/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8313 - accuracy: 0.5020 - val_loss: 2.3507 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 904/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8337 - accuracy: 0.5018 - val_loss: 2.3480 - val_accuracy: 0.4075 - lr: 0.0010\n",
            "Epoch 905/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8300 - accuracy: 0.5035 - val_loss: 2.3535 - val_accuracy: 0.4044 - lr: 0.0010\n",
            "Epoch 906/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8335 - accuracy: 0.5010 - val_loss: 2.3496 - val_accuracy: 0.4068 - lr: 0.0010\n",
            "Epoch 907/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8332 - accuracy: 0.5002 - val_loss: 2.3513 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 908/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8310 - accuracy: 0.5009 - val_loss: 2.3488 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 909/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8253 - accuracy: 0.5048 - val_loss: 2.3498 - val_accuracy: 0.4085 - lr: 0.0010\n",
            "Epoch 910/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8285 - accuracy: 0.5018 - val_loss: 2.3489 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 911/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8221 - accuracy: 0.5044 - val_loss: 2.3508 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 912/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8349 - accuracy: 0.5013 - val_loss: 2.3530 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 913/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8276 - accuracy: 0.5019 - val_loss: 2.3596 - val_accuracy: 0.4047 - lr: 0.0010\n",
            "Epoch 914/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8323 - accuracy: 0.5021 - val_loss: 2.3532 - val_accuracy: 0.4065 - lr: 0.0010\n",
            "Epoch 915/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8336 - accuracy: 0.5024 - val_loss: 2.3543 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 916/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8274 - accuracy: 0.5020 - val_loss: 2.3557 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 917/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8310 - accuracy: 0.5010 - val_loss: 2.3485 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 918/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8308 - accuracy: 0.5030 - val_loss: 2.3490 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 919/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8317 - accuracy: 0.5017 - val_loss: 2.3506 - val_accuracy: 0.4052 - lr: 0.0010\n",
            "Epoch 920/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8244 - accuracy: 0.5027 - val_loss: 2.3526 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 921/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8300 - accuracy: 0.5001 - val_loss: 2.3488 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 922/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8244 - accuracy: 0.5051 - val_loss: 2.3501 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 923/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8353 - accuracy: 0.5028 - val_loss: 2.3504 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 924/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8278 - accuracy: 0.5027 - val_loss: 2.3546 - val_accuracy: 0.4076 - lr: 0.0010\n",
            "Epoch 925/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8300 - accuracy: 0.5028 - val_loss: 2.3583 - val_accuracy: 0.4048 - lr: 0.0010\n",
            "Epoch 926/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8290 - accuracy: 0.5041 - val_loss: 2.3562 - val_accuracy: 0.4043 - lr: 0.0010\n",
            "Epoch 927/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8250 - accuracy: 0.5035 - val_loss: 2.3491 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 928/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8247 - accuracy: 0.5021 - val_loss: 2.3509 - val_accuracy: 0.4055 - lr: 0.0010\n",
            "Epoch 929/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8343 - accuracy: 0.5032 - val_loss: 2.3553 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 930/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8337 - accuracy: 0.5007 - val_loss: 2.3468 - val_accuracy: 0.4105 - lr: 0.0010\n",
            "Epoch 931/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8336 - accuracy: 0.5008 - val_loss: 2.3469 - val_accuracy: 0.4079 - lr: 0.0010\n",
            "Epoch 932/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8226 - accuracy: 0.5023 - val_loss: 2.3552 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 933/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8256 - accuracy: 0.5022 - val_loss: 2.3547 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 934/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8299 - accuracy: 0.5031 - val_loss: 2.3535 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 935/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8321 - accuracy: 0.5032 - val_loss: 2.3526 - val_accuracy: 0.4081 - lr: 0.0010\n",
            "Epoch 936/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8286 - accuracy: 0.5020 - val_loss: 2.3539 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 937/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8308 - accuracy: 0.5036 - val_loss: 2.3569 - val_accuracy: 0.4062 - lr: 0.0010\n",
            "Epoch 938/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8294 - accuracy: 0.5017 - val_loss: 2.3516 - val_accuracy: 0.4069 - lr: 0.0010\n",
            "Epoch 939/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8290 - accuracy: 0.5041 - val_loss: 2.3546 - val_accuracy: 0.4069 - lr: 0.0010\n",
            "Epoch 940/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8325 - accuracy: 0.5027 - val_loss: 2.3554 - val_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 941/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8280 - accuracy: 0.5041 - val_loss: 2.3513 - val_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 942/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8312 - accuracy: 0.5027 - val_loss: 2.3538 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 943/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8267 - accuracy: 0.5029 - val_loss: 2.3548 - val_accuracy: 0.4069 - lr: 0.0010\n",
            "Epoch 944/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8225 - accuracy: 0.5049 - val_loss: 2.3544 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 945/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8336 - accuracy: 0.5017 - val_loss: 2.3504 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 946/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8284 - accuracy: 0.5044 - val_loss: 2.3499 - val_accuracy: 0.4083 - lr: 0.0010\n",
            "Epoch 947/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8314 - accuracy: 0.5054 - val_loss: 2.3526 - val_accuracy: 0.4076 - lr: 0.0010\n",
            "Epoch 948/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8271 - accuracy: 0.5027 - val_loss: 2.3567 - val_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 949/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8233 - accuracy: 0.5041 - val_loss: 2.3527 - val_accuracy: 0.4092 - lr: 0.0010\n",
            "Epoch 950/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8287 - accuracy: 0.5031 - val_loss: 2.3519 - val_accuracy: 0.4049 - lr: 0.0010\n",
            "Epoch 951/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8240 - accuracy: 0.5040 - val_loss: 2.3541 - val_accuracy: 0.4054 - lr: 0.0010\n",
            "Epoch 952/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8315 - accuracy: 0.5007 - val_loss: 2.3491 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 953/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8245 - accuracy: 0.5057 - val_loss: 2.3437 - val_accuracy: 0.4100 - lr: 0.0010\n",
            "Epoch 954/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8206 - accuracy: 0.5017 - val_loss: 2.3518 - val_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 955/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8353 - accuracy: 0.5017 - val_loss: 2.3522 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 956/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8258 - accuracy: 0.5035 - val_loss: 2.3564 - val_accuracy: 0.4041 - lr: 0.0010\n",
            "Epoch 957/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8315 - accuracy: 0.5013 - val_loss: 2.3514 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 958/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8312 - accuracy: 0.5052 - val_loss: 2.3508 - val_accuracy: 0.4102 - lr: 0.0010\n",
            "Epoch 959/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8253 - accuracy: 0.5019 - val_loss: 2.3515 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 960/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8285 - accuracy: 0.5039 - val_loss: 2.3531 - val_accuracy: 0.4043 - lr: 0.0010\n",
            "Epoch 961/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8307 - accuracy: 0.5011 - val_loss: 2.3505 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 962/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8214 - accuracy: 0.5048 - val_loss: 2.3486 - val_accuracy: 0.4082 - lr: 0.0010\n",
            "Epoch 963/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8264 - accuracy: 0.5027 - val_loss: 2.3497 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 964/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8286 - accuracy: 0.5020 - val_loss: 2.3530 - val_accuracy: 0.4081 - lr: 0.0010\n",
            "Epoch 965/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8262 - accuracy: 0.5012 - val_loss: 2.3494 - val_accuracy: 0.4081 - lr: 0.0010\n",
            "Epoch 966/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8236 - accuracy: 0.5042 - val_loss: 2.3544 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 967/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8213 - accuracy: 0.5037 - val_loss: 2.3494 - val_accuracy: 0.4081 - lr: 0.0010\n",
            "Epoch 968/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8240 - accuracy: 0.5035 - val_loss: 2.3496 - val_accuracy: 0.4086 - lr: 0.0010\n",
            "Epoch 969/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8299 - accuracy: 0.5029 - val_loss: 2.3513 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 970/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8270 - accuracy: 0.5022 - val_loss: 2.3535 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 971/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8272 - accuracy: 0.5027 - val_loss: 2.3477 - val_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 972/1000\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8253 - accuracy: 0.5037 - val_loss: 2.3500 - val_accuracy: 0.4090 - lr: 0.0010\n",
            "Epoch 973/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8241 - accuracy: 0.5050 - val_loss: 2.3523 - val_accuracy: 0.4070 - lr: 0.0010\n",
            "Epoch 974/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8296 - accuracy: 0.5019 - val_loss: 2.3474 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 975/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8199 - accuracy: 0.5053 - val_loss: 2.3512 - val_accuracy: 0.4077 - lr: 0.0010\n",
            "Epoch 976/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8338 - accuracy: 0.5025 - val_loss: 2.3477 - val_accuracy: 0.4075 - lr: 0.0010\n",
            "Epoch 977/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8272 - accuracy: 0.5046 - val_loss: 2.3530 - val_accuracy: 0.4059 - lr: 0.0010\n",
            "Epoch 978/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8287 - accuracy: 0.5006 - val_loss: 2.3592 - val_accuracy: 0.4039 - lr: 0.0010\n",
            "Epoch 979/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8276 - accuracy: 0.5024 - val_loss: 2.3493 - val_accuracy: 0.4088 - lr: 0.0010\n",
            "Epoch 980/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8310 - accuracy: 0.5022 - val_loss: 2.3516 - val_accuracy: 0.4085 - lr: 0.0010\n",
            "Epoch 981/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8233 - accuracy: 0.5046 - val_loss: 2.3511 - val_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 982/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8325 - accuracy: 0.5029 - val_loss: 2.3510 - val_accuracy: 0.4091 - lr: 0.0010\n",
            "Epoch 983/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8263 - accuracy: 0.5048 - val_loss: 2.3523 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 984/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8279 - accuracy: 0.5011 - val_loss: 2.3541 - val_accuracy: 0.4065 - lr: 0.0010\n",
            "Epoch 985/1000\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8273 - accuracy: 0.5044 - val_loss: 2.3505 - val_accuracy: 0.4078 - lr: 0.0010\n",
            "Epoch 986/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8238 - accuracy: 0.5053 - val_loss: 2.3563 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 987/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8176 - accuracy: 0.5032 - val_loss: 2.3480 - val_accuracy: 0.4066 - lr: 0.0010\n",
            "Epoch 988/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8224 - accuracy: 0.5050 - val_loss: 2.3554 - val_accuracy: 0.4064 - lr: 0.0010\n",
            "Epoch 989/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8262 - accuracy: 0.5019 - val_loss: 2.3505 - val_accuracy: 0.4092 - lr: 0.0010\n",
            "Epoch 990/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8249 - accuracy: 0.5033 - val_loss: 2.3528 - val_accuracy: 0.4068 - lr: 0.0010\n",
            "Epoch 991/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8257 - accuracy: 0.5034 - val_loss: 2.3546 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 992/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8199 - accuracy: 0.5055 - val_loss: 2.3580 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 993/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8277 - accuracy: 0.5023 - val_loss: 2.3530 - val_accuracy: 0.4065 - lr: 0.0010\n",
            "Epoch 994/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8218 - accuracy: 0.5029 - val_loss: 2.3500 - val_accuracy: 0.4088 - lr: 0.0010\n",
            "Epoch 995/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8240 - accuracy: 0.5026 - val_loss: 2.3495 - val_accuracy: 0.4079 - lr: 0.0010\n",
            "Epoch 996/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8238 - accuracy: 0.5032 - val_loss: 2.3546 - val_accuracy: 0.4073 - lr: 0.0010\n",
            "Epoch 997/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8300 - accuracy: 0.5012 - val_loss: 2.3520 - val_accuracy: 0.4080 - lr: 0.0010\n",
            "Epoch 998/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8169 - accuracy: 0.5074 - val_loss: 2.3549 - val_accuracy: 0.4072 - lr: 0.0010\n",
            "Epoch 999/1000\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8281 - accuracy: 0.5030 - val_loss: 2.3587 - val_accuracy: 0.4038 - lr: 0.0010\n",
            "Epoch 1000/1000\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8213 - accuracy: 0.5062 - val_loss: 2.3588 - val_accuracy: 0.4051 - lr: 0.0010\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.3588 - accuracy: 0.4051\n",
            "Testset Loss: 2.358841\n",
            "Testset Accuracy: 0.405100\n"
          ]
        }
      ],
      "source": [
        "# Keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Python Std Lib\n",
        "import os\n",
        "\n",
        "# User Lib\n",
        "dropout = 0.2\n",
        "\n",
        "# get the training and test data\n",
        "(input_train, output_train), (input_test, output_test) = cifar100.load_data()\n",
        "\n",
        "# creating the basic model\n",
        "model = Sequential()\n",
        "\n",
        "# 30 Conv Layer\n",
        "model.add(Conv2D(30, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(32, 32, 3)))\n",
        "# 15 Max Pool Layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(Dropout(dropout))\n",
        "# 13 Conv Layer\n",
        "model.add(Conv2D(13, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "# 6 Max Pool Layer\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(Dropout(dropout))\n",
        "# Flatten the Layer for transitioning to the Fully Connected Layers\n",
        "model.add(Flatten())\n",
        "# 120 Fully Connected Layer\n",
        "model.add(Dense(120, activation='relu'))\n",
        "# 84 Fully Connected Layer\n",
        "model.add(Dense(86, activation='relu'))\n",
        "# 100 Output\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# compile the model\n",
        "initial_learning_rate = 0.001\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 100:\n",
        "    return 0.02\n",
        "  elif epoch < 200:\n",
        "    return 0.01\n",
        "  elif epoch < 400:\n",
        "    return 0.005\n",
        "  elif epoch < 700:\n",
        "    return 0.003\n",
        "  else: return 0.001    \n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "save_dir = '/content/drive/MyDrive/ECE6930/Lenet-0222-01/cifar100/1dropout/1'\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(os.path.join(save_dir, '{epoch:03d}.h5'), monitor='val_loss', verbose=0,\t\t\t\t\t\tsave_best_only=False, \n",
        " \t\t\t\t\t\t\t\tsave_weights_only=False, mode='auto', \n",
        " \t\t\t\t\t\t\t\tperiod=10)\n",
        "\n",
        "\n",
        "# train the model\n",
        "history = model.fit(input_train/255, to_categorical(output_train), epochs=1000, \n",
        "           validation_data=(input_test/255, to_categorical(output_test)),\n",
        "                    batch_size=128,callbacks=[callback,checkpointer])\n",
        "\n",
        "\n",
        "# test\n",
        "score = model.evaluate(input_test/255, to_categorical(output_test), batch_size=128)\n",
        "\n",
        "# print test set results\n",
        "print(\"Testset Loss: %f\" % score[0])\n",
        "print(\"Testset Accuracy: %f\" % score[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"test\"],loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hIWjK9z7YU-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "96d5db89-ab98-4952-f135-ae2805cbd72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history)"
      ],
      "metadata": {
        "id": "RHc1aneQaOGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c726d8e1-8be8-491a-fef9-c4e196acb946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [4.604349613189697, 4.596037864685059, 4.549551963806152, 4.444911479949951, 4.279093265533447, 4.163459777832031, 4.087595462799072, 4.020031452178955, 3.9525146484375, 3.891193389892578, 3.845459461212158, 3.801543951034546, 3.764559030532837, 3.7262015342712402, 3.6866140365600586, 3.643212080001831, 3.592010021209717, 3.541990041732788, 3.5053985118865967, 3.4581527709960938, 3.421414375305176, 3.3830039501190186, 3.3504793643951416, 3.3188862800598145, 3.287250518798828, 3.258096218109131, 3.225213050842285, 3.1992671489715576, 3.1740293502807617, 3.149219036102295, 3.1273341178894043, 3.0961575508117676, 3.080125570297241, 3.0559535026550293, 3.033604621887207, 3.0180277824401855, 3.0011212825775146, 2.974440574645996, 2.964852809906006, 2.9421169757843018, 2.9236371517181396, 2.912888526916504, 2.8979272842407227, 2.88283371925354, 2.8690452575683594, 2.8552286624908447, 2.84132719039917, 2.823136329650879, 2.8102283477783203, 2.7972755432128906, 2.7905874252319336, 2.7744522094726562, 2.762136459350586, 2.746640920639038, 2.7382028102874756, 2.7265355587005615, 2.7198123931884766, 2.708101511001587, 2.697758197784424, 2.6887288093566895, 2.679835557937622, 2.671729326248169, 2.660775899887085, 2.6525022983551025, 2.6388356685638428, 2.636414051055908, 2.6242775917053223, 2.6155810356140137, 2.607272148132324, 2.598903179168701, 2.5952672958374023, 2.5826706886291504, 2.574054002761841, 2.567274332046509, 2.558058738708496, 2.5590662956237793, 2.548591136932373, 2.539949655532837, 2.5339038372039795, 2.5274369716644287, 2.5209741592407227, 2.5115432739257812, 2.507512092590332, 2.4952683448791504, 2.4960880279541016, 2.4919605255126953, 2.4832398891448975, 2.476095199584961, 2.471414566040039, 2.462128162384033, 2.46370005607605, 2.4509332180023193, 2.4480350017547607, 2.4393155574798584, 2.4339654445648193, 2.4340758323669434, 2.4259703159332275, 2.423084259033203, 2.4146316051483154, 2.4101505279541016, 2.366157293319702, 2.35656476020813, 2.3561604022979736, 2.348724126815796, 2.344876289367676, 2.3488333225250244, 2.3430025577545166, 2.3396823406219482, 2.331601858139038, 2.3345096111297607, 2.3350894451141357, 2.331749677658081, 2.328429698944092, 2.323167562484741, 2.3229522705078125, 2.319058656692505, 2.318622589111328, 2.312412977218628, 2.3088603019714355, 2.307874917984009, 2.3082621097564697, 2.3047194480895996, 2.3014466762542725, 2.30597186088562, 2.298473358154297, 2.2994563579559326, 2.2916078567504883, 2.2903964519500732, 2.289811611175537, 2.2857134342193604, 2.2868030071258545, 2.2802188396453857, 2.283052444458008, 2.27528977394104, 2.2755961418151855, 2.268723964691162, 2.2645103931427, 2.2582898139953613, 2.2661187648773193, 2.260404109954834, 2.262629508972168, 2.25657057762146, 2.253889799118042, 2.2527663707733154, 2.249682903289795, 2.246227741241455, 2.2463572025299072, 2.241966485977173, 2.241159439086914, 2.2410290241241455, 2.2318661212921143, 2.231966495513916, 2.2329163551330566, 2.234872341156006, 2.2302470207214355, 2.223628520965576, 2.2286393642425537, 2.2221310138702393, 2.224292278289795, 2.2175490856170654, 2.212773323059082, 2.2186601161956787, 2.212655544281006, 2.2103755474090576, 2.2096822261810303, 2.2052412033081055, 2.2070250511169434, 2.2019333839416504, 2.2027671337127686, 2.202866792678833, 2.197559118270874, 2.1982028484344482, 2.1904184818267822, 2.19551682472229, 2.1884443759918213, 2.185929536819458, 2.1817479133605957, 2.1826608180999756, 2.1848537921905518, 2.1759796142578125, 2.175370216369629, 2.1732125282287598, 2.1790761947631836, 2.172004222869873, 2.1665780544281006, 2.1708569526672363, 2.1622314453125, 2.1651010513305664, 2.1603078842163086, 2.161012887954712, 2.1593098640441895, 2.1614365577697754, 2.1515238285064697, 2.151937961578369, 2.1500585079193115, 2.1447720527648926, 2.152667284011841, 2.143160104751587, 2.1499292850494385, 2.139786958694458, 2.121027708053589, 2.1130552291870117, 2.1099696159362793, 2.1150283813476562, 2.113748788833618, 2.113481283187866, 2.1117634773254395, 2.109510660171509, 2.1095528602600098, 2.1094741821289062, 2.1049129962921143, 2.104248523712158, 2.1066792011260986, 2.1029794216156006, 2.10166335105896, 2.104142427444458, 2.1026451587677, 2.094418525695801, 2.0967743396759033, 2.100339651107788, 2.0966930389404297, 2.094616413116455, 2.092487096786499, 2.095989942550659, 2.092651605606079, 2.091722249984741, 2.0926761627197266, 2.0881686210632324, 2.0873239040374756, 2.0924489498138428, 2.08329701423645, 2.0876781940460205, 2.0856478214263916, 2.0927932262420654, 2.0847530364990234, 2.088973045349121, 2.081712245941162, 2.079874038696289, 2.080610990524292, 2.079892158508301, 2.0832583904266357, 2.0762360095977783, 2.078160524368286, 2.07513689994812, 2.0789918899536133, 2.0779800415039062, 2.0749852657318115, 2.069911479949951, 2.0629935264587402, 2.0691018104553223, 2.0690078735351562, 2.0718071460723877, 2.0637660026550293, 2.07352352142334, 2.065368175506592, 2.0658364295959473, 2.0669007301330566, 2.0649189949035645, 2.0612730979919434, 2.062476634979248, 2.0660219192504883, 2.061671018600464, 2.058967113494873, 2.060396194458008, 2.0525476932525635, 2.0590405464172363, 2.0581159591674805, 2.0517187118530273, 2.0549604892730713, 2.052995204925537, 2.0511906147003174, 2.053305149078369, 2.049825668334961, 2.0463998317718506, 2.043264865875244, 2.052844285964966, 2.0443999767303467, 2.0500693321228027, 2.0466718673706055, 2.0404651165008545, 2.044635772705078, 2.0455055236816406, 2.0441133975982666, 2.0392796993255615, 2.0424985885620117, 2.0448479652404785, 2.0397417545318604, 2.043195962905884, 2.039116144180298, 2.0420010089874268, 2.041736364364624, 2.0388007164001465, 2.028877019882202, 2.0403354167938232, 2.03729248046875, 2.036728858947754, 2.040677070617676, 2.0334603786468506, 2.035238742828369, 2.033308267593384, 2.024770736694336, 2.0341899394989014, 2.02803635597229, 2.0319862365722656, 2.0239779949188232, 2.030508041381836, 2.024413585662842, 2.020792007446289, 2.020512104034424, 2.0299835205078125, 2.0256457328796387, 2.0220160484313965, 2.0248124599456787, 2.020484447479248, 2.02146577835083, 2.0165820121765137, 2.019348382949829, 2.0146360397338867, 2.019636869430542, 2.0191190242767334, 2.0159475803375244, 2.0156798362731934, 2.0170047283172607, 2.0180137157440186, 2.0092689990997314, 2.0102713108062744, 2.013312578201294, 2.0128891468048096, 2.0137858390808105, 2.0131242275238037, 2.0094494819641113, 2.0087785720825195, 2.0076091289520264, 2.0126631259918213, 2.0076963901519775, 2.006490707397461, 2.0010030269622803, 1.9985846281051636, 2.0103132724761963, 2.003467082977295, 2.0051465034484863, 2.004854202270508, 1.9996747970581055, 1.9998173713684082, 1.998844027519226, 1.9966182708740234, 1.9963412284851074, 1.9974933862686157, 1.9969240427017212, 1.9929431676864624, 1.9978991746902466, 1.9947984218597412, 2.001126766204834, 1.9897748231887817, 1.9888449907302856, 1.9897663593292236, 1.993474006652832, 1.9890917539596558, 1.9900267124176025, 1.990002989768982, 1.987037181854248, 1.9783421754837036, 1.9863014221191406, 1.9873871803283691, 1.9865193367004395, 1.992805004119873, 1.9875270128250122, 1.9858990907669067, 1.9813883304595947, 1.9888558387756348, 1.9791483879089355, 1.9808249473571777, 1.9749584197998047, 1.9759790897369385, 1.9776391983032227, 1.9749491214752197, 1.985137701034546, 1.9754748344421387, 1.9719226360321045, 1.9765347242355347, 1.9753541946411133, 1.9763288497924805, 1.9737603664398193, 1.9711326360702515, 1.9775869846343994, 1.9765855073928833, 1.9670222997665405, 1.9775511026382446, 1.9739102125167847, 1.976723313331604, 1.9720818996429443, 1.9635553359985352, 1.9660887718200684, 1.964428424835205, 1.9727144241333008, 1.9657559394836426, 1.9680635929107666, 1.9619801044464111, 1.9685698747634888, 1.9715760946273804, 1.946138858795166, 1.9491193294525146, 1.947834849357605, 1.9540220499038696, 1.9563945531845093, 1.951322317123413, 1.9457253217697144, 1.9474495649337769, 1.9508461952209473, 1.9522302150726318, 1.9430854320526123, 1.9432026147842407, 1.943127155303955, 1.9460488557815552, 1.9462934732437134, 1.9500489234924316, 1.9407612085342407, 1.9462007284164429, 1.9431135654449463, 1.9401862621307373, 1.9409286975860596, 1.9467014074325562, 1.9483919143676758, 1.9427415132522583, 1.9425981044769287, 1.9420839548110962, 1.9413865804672241, 1.9416054487228394, 1.9400460720062256, 1.936508297920227, 1.937435269355774, 1.9389281272888184, 1.9399057626724243, 1.937599539756775, 1.9383041858673096, 1.9384030103683472, 1.935102939605713, 1.9355080127716064, 1.932840347290039, 1.936684012413025, 1.9384732246398926, 1.9384905099868774, 1.930949091911316, 1.9325400590896606, 1.9400453567504883, 1.9320276975631714, 1.9317677021026611, 1.9284037351608276, 1.9331974983215332, 1.9317477941513062, 1.9380894899368286, 1.9307260513305664, 1.9333784580230713, 1.93342924118042, 1.93104088306427, 1.9318815469741821, 1.937530517578125, 1.928582787513733, 1.9295545816421509, 1.9337834119796753, 1.9292333126068115, 1.9336540699005127, 1.9284217357635498, 1.9230647087097168, 1.9276032447814941, 1.9281202554702759, 1.923840880393982, 1.9282556772232056, 1.9247679710388184, 1.9294829368591309, 1.92460036277771, 1.9287960529327393, 1.92718505859375, 1.9270269870758057, 1.9292292594909668, 1.921998143196106, 1.9199857711791992, 1.926357388496399, 1.9283349514007568, 1.9194090366363525, 1.9266183376312256, 1.9207226037979126, 1.9262206554412842, 1.9251967668533325, 1.9204773902893066, 1.920021414756775, 1.9223828315734863, 1.9236732721328735, 1.9226168394088745, 1.918817400932312, 1.9140515327453613, 1.9248915910720825, 1.9183313846588135, 1.9226173162460327, 1.9188095331192017, 1.915567398071289, 1.9208260774612427, 1.9200572967529297, 1.91710364818573, 1.9172592163085938, 1.9140336513519287, 1.9167059659957886, 1.9114657640457153, 1.9161376953125, 1.9142584800720215, 1.917524814605713, 1.9108983278274536, 1.9163165092468262, 1.9145421981811523, 1.9134503602981567, 1.9162237644195557, 1.9137134552001953, 1.9141762256622314, 1.9119127988815308, 1.9106976985931396, 1.9121254682540894, 1.9091739654541016, 1.9106061458587646, 1.9129729270935059, 1.9117895364761353, 1.9129949808120728, 1.9111860990524292, 1.910519003868103, 1.9078521728515625, 1.9137375354766846, 1.9116524457931519, 1.9091274738311768, 1.9088536500930786, 1.9083226919174194, 1.907547950744629, 1.9099668264389038, 1.9042268991470337, 1.9044835567474365, 1.905630111694336, 1.9011090993881226, 1.9035001993179321, 1.905504584312439, 1.9088079929351807, 1.9022125005722046, 1.9042407274246216, 1.9061694145202637, 1.9061269760131836, 1.90677809715271, 1.8978606462478638, 1.905285358428955, 1.903153896331787, 1.8993362188339233, 1.9018170833587646, 1.9070892333984375, 1.9063466787338257, 1.9040660858154297, 1.9048210382461548, 1.9007912874221802, 1.8977364301681519, 1.9049403667449951, 1.898970603942871, 1.9011229276657104, 1.9050713777542114, 1.9026479721069336, 1.9018703699111938, 1.900460958480835, 1.899140477180481, 1.896844744682312, 1.8972309827804565, 1.8991111516952515, 1.9002703428268433, 1.8988615274429321, 1.892707347869873, 1.9031367301940918, 1.8998297452926636, 1.894864559173584, 1.9027845859527588, 1.8927615880966187, 1.8953518867492676, 1.8953907489776611, 1.8959572315216064, 1.8995497226715088, 1.8920888900756836, 1.8916044235229492, 1.8948049545288086, 1.8919098377227783, 1.8929522037506104, 1.8845082521438599, 1.8976755142211914, 1.8917120695114136, 1.8922888040542603, 1.8950093984603882, 1.8920867443084717, 1.8948668241500854, 1.895211100578308, 1.8881075382232666, 1.8880218267440796, 1.8873741626739502, 1.8865855932235718, 1.8889751434326172, 1.8910332918167114, 1.8882709741592407, 1.8844102621078491, 1.8817278146743774, 1.8869233131408691, 1.8904165029525757, 1.889878749847412, 1.8869656324386597, 1.890846610069275, 1.8834816217422485, 1.8871592283248901, 1.887611746788025, 1.8858468532562256, 1.8824542760849, 1.879647970199585, 1.8824723958969116, 1.8833134174346924, 1.8909456729888916, 1.8825455904006958, 1.8900312185287476, 1.8798019886016846, 1.8869425058364868, 1.8825424909591675, 1.8741682767868042, 1.8795191049575806, 1.8862258195877075, 1.8858246803283691, 1.8792966604232788, 1.8840876817703247, 1.881683111190796, 1.8821731805801392, 1.8853278160095215, 1.8873050212860107, 1.8854866027832031, 1.8815903663635254, 1.8755359649658203, 1.8834431171417236, 1.883277177810669, 1.8769683837890625, 1.8811887502670288, 1.8786627054214478, 1.8809492588043213, 1.8789523839950562, 1.8828870058059692, 1.876894474029541, 1.875354528427124, 1.8813899755477905, 1.8658819198608398, 1.8836727142333984, 1.870819330215454, 1.8801370859146118, 1.872939109802246, 1.8793649673461914, 1.869421124458313, 1.8757588863372803, 1.876198172569275, 1.8763959407806396, 1.87490713596344, 1.8682187795639038, 1.8672114610671997, 1.866277813911438, 1.8790838718414307, 1.8761786222457886, 1.86528480052948, 1.8749274015426636, 1.8672749996185303, 1.8685755729675293, 1.8745568990707397, 1.8671609163284302, 1.8688347339630127, 1.8713613748550415, 1.8677048683166504, 1.8717337846755981, 1.86782968044281, 1.8676012754440308, 1.8656504154205322, 1.8670406341552734, 1.872354507446289, 1.8675103187561035, 1.8715741634368896, 1.862121820449829, 1.8667651414871216, 1.8731428384780884, 1.865416407585144, 1.872562289237976, 1.8655140399932861, 1.8714280128479004, 1.8662055730819702, 1.8633748292922974, 1.8651529550552368, 1.8694303035736084, 1.8714066743850708, 1.868960976600647, 1.8653134107589722, 1.8599096536636353, 1.8608318567276, 1.862067461013794, 1.86182701587677, 1.8614791631698608, 1.8610820770263672, 1.8589931726455688, 1.865403652191162, 1.8615559339523315, 1.8580886125564575, 1.8612463474273682, 1.8458563089370728, 1.8545137643814087, 1.848170518875122, 1.8472174406051636, 1.8570674657821655, 1.8467602729797363, 1.849161982536316, 1.848418951034546, 1.8505076169967651, 1.8518216609954834, 1.8466339111328125, 1.849795937538147, 1.847643256187439, 1.8446351289749146, 1.849649429321289, 1.846234679222107, 1.8533718585968018, 1.8528789281845093, 1.8470417261123657, 1.848225474357605, 1.845663070678711, 1.8447190523147583, 1.8477559089660645, 1.845489501953125, 1.8493565320968628, 1.843579888343811, 1.8406280279159546, 1.8512200117111206, 1.8449220657348633, 1.8447386026382446, 1.8433467149734497, 1.8470524549484253, 1.8465533256530762, 1.8446344137191772, 1.8487958908081055, 1.8425065279006958, 1.8455462455749512, 1.841819405555725, 1.8471579551696777, 1.8436357975006104, 1.8474717140197754, 1.8458915948867798, 1.8425335884094238, 1.8458704948425293, 1.845346212387085, 1.8413630723953247, 1.8464971780776978, 1.8406383991241455, 1.845637321472168, 1.8502793312072754, 1.839100956916809, 1.8420372009277344, 1.8390601873397827, 1.832192063331604, 1.8458811044692993, 1.8393384218215942, 1.8448792695999146, 1.8440239429473877, 1.8461105823516846, 1.83628511428833, 1.8379523754119873, 1.839523434638977, 1.8417859077453613, 1.8399276733398438, 1.8481391668319702, 1.8476320505142212, 1.8443596363067627, 1.8452978134155273, 1.8394768238067627, 1.8356791734695435, 1.8463855981826782, 1.8447351455688477, 1.8458884954452515, 1.8405568599700928, 1.8443790674209595, 1.8418083190917969, 1.8470044136047363, 1.8386385440826416, 1.8453460931777954, 1.845445156097412, 1.8424605131149292, 1.8382843732833862, 1.8445812463760376, 1.8385379314422607, 1.8400063514709473, 1.8390045166015625, 1.8428187370300293, 1.8414045572280884, 1.844765305519104, 1.84157395362854, 1.8395967483520508, 1.8326635360717773, 1.842355728149414, 1.8394620418548584, 1.8413926362991333, 1.8467873334884644, 1.8399406671524048, 1.8333054780960083, 1.8399399518966675, 1.846144676208496, 1.8399368524551392, 1.8385769128799438, 1.8373943567276, 1.8418205976486206, 1.8391261100769043, 1.8394417762756348, 1.84320068359375, 1.8360868692398071, 1.8411264419555664, 1.8331290483474731, 1.8319215774536133, 1.8335638046264648, 1.840499997138977, 1.8333697319030762, 1.82840895652771, 1.838619589805603, 1.8460056781768799, 1.8474525213241577, 1.8335082530975342, 1.8355509042739868, 1.8459446430206299, 1.8322993516921997, 1.8420029878616333, 1.833762764930725, 1.8396973609924316, 1.831964373588562, 1.8370972871780396, 1.834571123123169, 1.8349493741989136, 1.8337280750274658, 1.8403708934783936, 1.8325121402740479, 1.841866135597229, 1.8318641185760498, 1.8382261991500854, 1.8403213024139404, 1.8396888971328735, 1.834191083908081, 1.8366326093673706, 1.8314242362976074, 1.8343689441680908, 1.8396990299224854, 1.8364362716674805, 1.8327921628952026, 1.840471863746643, 1.836212158203125, 1.8383232355117798, 1.838184118270874, 1.8289724588394165, 1.8326541185379028, 1.8365721702575684, 1.8315974473953247, 1.8418647050857544, 1.8402730226516724, 1.8355880975723267, 1.83806312084198, 1.8327170610427856, 1.8340492248535156, 1.82932448387146, 1.8362516164779663, 1.8333662748336792, 1.8352450132369995, 1.833693265914917, 1.830857753753662, 1.8360751867294312, 1.8398563861846924, 1.8303189277648926, 1.8335191011428833, 1.8355669975280762, 1.8294858932495117, 1.8346920013427734, 1.836650013923645, 1.839005470275879, 1.8307675123214722, 1.8351534605026245, 1.838724970817566, 1.8313097953796387, 1.8326795101165771, 1.8363990783691406, 1.827223539352417, 1.8349226713180542, 1.8370413780212402, 1.8353190422058105, 1.8322802782058716, 1.8366998434066772, 1.8329354524612427, 1.832729697227478, 1.8375540971755981, 1.8264453411102295, 1.8329870700836182, 1.8387340307235718, 1.8344004154205322, 1.8322508335113525, 1.8383255004882812, 1.8314287662506104, 1.8352818489074707, 1.824484944343567, 1.8273626565933228, 1.8323540687561035, 1.8252406120300293, 1.8303719758987427, 1.8367862701416016, 1.8312803506851196, 1.8337363004684448, 1.8300206661224365, 1.8334511518478394, 1.8331778049468994, 1.8310374021530151, 1.8252609968185425, 1.8284598588943481, 1.8220696449279785, 1.8349316120147705, 1.8275914192199707, 1.8323220014572144, 1.8335936069488525, 1.8273732662200928, 1.8310034275054932, 1.8308334350585938, 1.8317039012908936, 1.8244484663009644, 1.829958438873291, 1.82435941696167, 1.8353397846221924, 1.8278021812438965, 1.8299809694290161, 1.8290232419967651, 1.82503080368042, 1.824656367301941, 1.8342608213424683, 1.8336702585220337, 1.8336113691329956, 1.822616457939148, 1.8256480693817139, 1.8298810720443726, 1.8320626020431519, 1.8286443948745728, 1.8307641744613647, 1.829447865486145, 1.8290334939956665, 1.8324681520462036, 1.8279575109481812, 1.8311558961868286, 1.826672911643982, 1.822489857673645, 1.8335626125335693, 1.8284231424331665, 1.8314120769500732, 1.8271363973617554, 1.8233311176300049, 1.8286895751953125, 1.8240119218826294, 1.8314777612686157, 1.824460744857788, 1.8205950260162354, 1.8352994918823242, 1.8257696628570557, 1.8314921855926514, 1.8312287330627441, 1.82534658908844, 1.8285126686096191, 1.8306714296340942, 1.821414589881897, 1.8263810873031616, 1.8286405801773071, 1.8262343406677246, 1.8236290216445923, 1.8212531805038452, 1.8239994049072266, 1.8298861980438232, 1.827048420906067, 1.8271576166152954, 1.8253467082977295, 1.8241307735443115, 1.8295778036117554, 1.8199328184127808, 1.8337571620941162, 1.8271880149841309, 1.8287028074264526, 1.8275752067565918, 1.8309601545333862, 1.8232543468475342, 1.8324636220932007, 1.8263473510742188, 1.8279445171356201, 1.8273200988769531, 1.8237693309783936, 1.8175609111785889, 1.8224059343338013, 1.8261581659317017, 1.8249040842056274, 1.8256679773330688, 1.8198950290679932, 1.8276528120040894, 1.821779727935791, 1.823971152305603, 1.8237614631652832, 1.8300113677978516, 1.8168549537658691, 1.8280813694000244, 1.821293592453003], 'accuracy': [0.01056000031530857, 0.012980000115931034, 0.01850000023841858, 0.027340000495314598, 0.042100001126527786, 0.059039998799562454, 0.0722000002861023, 0.0833199992775917, 0.09241999685764313, 0.10115999728441238, 0.1110600009560585, 0.11857999861240387, 0.12540000677108765, 0.13407999277114868, 0.13801999390125275, 0.14711999893188477, 0.15515999495983124, 0.16300000250339508, 0.17202000319957733, 0.17800000309944153, 0.18491999804973602, 0.19266000390052795, 0.19533999264240265, 0.20302000641822815, 0.20839999616146088, 0.21313999593257904, 0.2185399979352951, 0.2225400060415268, 0.22655999660491943, 0.2325199991464615, 0.23680000007152557, 0.24286000430583954, 0.2457599937915802, 0.24955999851226807, 0.25446000695228577, 0.25600001215934753, 0.26183998584747314, 0.2649199962615967, 0.269540011882782, 0.2729400098323822, 0.27691999077796936, 0.27974000573158264, 0.282260000705719, 0.28652000427246094, 0.2867000102996826, 0.2896200120449066, 0.29330000281333923, 0.29576000571250916, 0.29980000853538513, 0.3031800091266632, 0.3064799904823303, 0.3081600069999695, 0.3097600042819977, 0.3109999895095825, 0.3121199905872345, 0.3160400092601776, 0.3193199932575226, 0.32067999243736267, 0.3216800093650818, 0.3216800093650818, 0.3255000114440918, 0.3303000032901764, 0.32798001170158386, 0.331279993057251, 0.33438000082969666, 0.33371999859809875, 0.3405199944972992, 0.33792001008987427, 0.3416999876499176, 0.3441599905490875, 0.34345999360084534, 0.3462600111961365, 0.3460800051689148, 0.34648001194000244, 0.3508400022983551, 0.34841999411582947, 0.352400004863739, 0.3522999882698059, 0.3566400110721588, 0.3565399944782257, 0.3569200038909912, 0.35868000984191895, 0.35923999547958374, 0.3637399971485138, 0.3637999892234802, 0.36484000086784363, 0.364439994096756, 0.36682000756263733, 0.36687999963760376, 0.3694399893283844, 0.3693000078201294, 0.37007999420166016, 0.37112000584602356, 0.3751400113105774, 0.37411999702453613, 0.37373998761177063, 0.37648001313209534, 0.3808799982070923, 0.37770000100135803, 0.3805600106716156, 0.3894599974155426, 0.3924599885940552, 0.39434000849723816, 0.39329999685287476, 0.39546000957489014, 0.3937999904155731, 0.394320011138916, 0.3960599899291992, 0.3967599868774414, 0.3945600092411041, 0.3970800042152405, 0.3979400098323822, 0.3972800076007843, 0.3994399905204773, 0.3993000090122223, 0.3996799886226654, 0.3990199863910675, 0.4041000008583069, 0.403439998626709, 0.4025999903678894, 0.40178000926971436, 0.40389999747276306, 0.4050000011920929, 0.40478000044822693, 0.4025999903678894, 0.4053399860858917, 0.404339998960495, 0.40549999475479126, 0.40529999136924744, 0.4059799909591675, 0.405239999294281, 0.40689998865127563, 0.40904000401496887, 0.40786001086235046, 0.41100001335144043, 0.41200000047683716, 0.41082000732421875, 0.4134399890899658, 0.41370001435279846, 0.41005998849868774, 0.41141998767852783, 0.41214001178741455, 0.41304001212120056, 0.4133400022983551, 0.41223999857902527, 0.41339999437332153, 0.41492000222206116, 0.41387999057769775, 0.4159199893474579, 0.4160799980163574, 0.4187600016593933, 0.41631999611854553, 0.41547998785972595, 0.4171600043773651, 0.41940000653266907, 0.42006000876426697, 0.4154599905014038, 0.4194200038909912, 0.41868001222610474, 0.4197799861431122, 0.420879989862442, 0.4204599857330322, 0.4232800006866455, 0.42080000042915344, 0.42179998755455017, 0.4223800003528595, 0.42006000876426697, 0.42344000935554504, 0.4221400022506714, 0.4240399897098541, 0.42546001076698303, 0.4225600063800812, 0.4250999987125397, 0.4250999987125397, 0.4260999858379364, 0.42719998955726624, 0.42719998955726624, 0.42890000343322754, 0.42566001415252686, 0.42829999327659607, 0.42998000979423523, 0.42886000871658325, 0.42757999897003174, 0.4321799874305725, 0.43046000599861145, 0.42945998907089233, 0.43215999007225037, 0.43108001351356506, 0.4317399859428406, 0.43112000823020935, 0.43338000774383545, 0.43182000517845154, 0.4328800141811371, 0.43356001377105713, 0.43507999181747437, 0.4350399971008301, 0.4339999854564667, 0.4362800121307373, 0.43386000394821167, 0.4351400136947632, 0.4430199861526489, 0.442220002412796, 0.44266000390052795, 0.4445599913597107, 0.4424999952316284, 0.4431400001049042, 0.44284000992774963, 0.4432600140571594, 0.4451200067996979, 0.4412600100040436, 0.4440400004386902, 0.4434399902820587, 0.44359999895095825, 0.44718000292778015, 0.44519999623298645, 0.44488000869750977, 0.4441800117492676, 0.4479199945926666, 0.44567999243736267, 0.4448400139808655, 0.4461599886417389, 0.4478600025177002, 0.4455600082874298, 0.4456999897956848, 0.4451200067996979, 0.44839999079704285, 0.4486199915409088, 0.4479199945926666, 0.44655999541282654, 0.4470599889755249, 0.44971999526023865, 0.4482400119304657, 0.4492799937725067, 0.4467200040817261, 0.4492399990558624, 0.44749999046325684, 0.4496000111103058, 0.4508199989795685, 0.44835999608039856, 0.4492399990558624, 0.44995999336242676, 0.4497799873352051, 0.4515399932861328, 0.4526599943637848, 0.4494999945163727, 0.4514800012111664, 0.45028001070022583, 0.45107999444007874, 0.4512999951839447, 0.4497399926185608, 0.45311999320983887, 0.45166000723838806, 0.4514000117778778, 0.4529399871826172, 0.4534200131893158, 0.44896000623703003, 0.45254001021385193, 0.4521600008010864, 0.45329999923706055, 0.454120010137558, 0.45058000087738037, 0.45315998792648315, 0.454039990901947, 0.453359991312027, 0.4548400044441223, 0.4538800120353699, 0.45320001244544983, 0.4553000032901764, 0.45458000898361206, 0.4556199908256531, 0.4564400017261505, 0.45486000180244446, 0.45758000016212463, 0.4556399881839752, 0.45649999380111694, 0.45438000559806824, 0.4569999873638153, 0.45438000559806824, 0.45754000544548035, 0.45677998661994934, 0.4560999870300293, 0.4553000032901764, 0.45969998836517334, 0.4577600061893463, 0.458079993724823, 0.4575999975204468, 0.4577000141143799, 0.45820000767707825, 0.45691999793052673, 0.45660001039505005, 0.4589200019836426, 0.45833998918533325, 0.46028000116348267, 0.4600200057029724, 0.45570001006126404, 0.45802000164985657, 0.4571000039577484, 0.4601399898529053, 0.45851999521255493, 0.45833998918533325, 0.46149998903274536, 0.45715999603271484, 0.45886000990867615, 0.4582799971103668, 0.4610599875450134, 0.45833998918533325, 0.4614599943161011, 0.46206000447273254, 0.4615199863910675, 0.4573799967765808, 0.45956000685691833, 0.46083998680114746, 0.46268001198768616, 0.4620400071144104, 0.46226000785827637, 0.46195998787879944, 0.4620400071144104, 0.4603999853134155, 0.46112000942230225, 0.4625000059604645, 0.4634000062942505, 0.46116000413894653, 0.462660014629364, 0.46272000670433044, 0.4658200144767761, 0.4637399911880493, 0.4634400010108948, 0.46281999349594116, 0.46456000208854675, 0.46276000142097473, 0.4643799960613251, 0.46507999300956726, 0.4649200141429901, 0.46276000142097473, 0.4648999869823456, 0.46320000290870667, 0.4649600088596344, 0.4661000072956085, 0.4621399939060211, 0.46794000267982483, 0.462660014629364, 0.4630799889564514, 0.46502000093460083, 0.46518000960350037, 0.4661000072956085, 0.46682000160217285, 0.4667400121688843, 0.4662399888038635, 0.4677000045776367, 0.4672600030899048, 0.4661000072956085, 0.46650001406669617, 0.4654200077056885, 0.4659999907016754, 0.4696199893951416, 0.4687199890613556, 0.46713998913764954, 0.46884000301361084, 0.46625998616218567, 0.46724000573158264, 0.46873998641967773, 0.47058001160621643, 0.4673199951648712, 0.46744000911712646, 0.4700799882411957, 0.46889999508857727, 0.46977999806404114, 0.4704599976539612, 0.46794000267982483, 0.46917998790740967, 0.4714600145816803, 0.4706000089645386, 0.4712199866771698, 0.4713200032711029, 0.4689199924468994, 0.4729200005531311, 0.47005999088287354, 0.4685400128364563, 0.4721600115299225, 0.4707599878311157, 0.47130000591278076, 0.4721600115299225, 0.4712600111961365, 0.4704799950122833, 0.46869999170303345, 0.46959999203681946, 0.47095999121665955, 0.46983999013900757, 0.47137999534606934, 0.4665600061416626, 0.4736799895763397, 0.47363999485969543, 0.4719400107860565, 0.47501999139785767, 0.4725399911403656, 0.47488000988960266, 0.47165998816490173, 0.4715000092983246, 0.47398000955581665, 0.47176000475883484, 0.4767799973487854, 0.4787999987602234, 0.4779999852180481, 0.47699999809265137, 0.47633999586105347, 0.4791400134563446, 0.4754599928855896, 0.4771600067615509, 0.47609999775886536, 0.477400004863739, 0.47775998711586, 0.4770199954509735, 0.4768199920654297, 0.4790399968624115, 0.47690001130104065, 0.4778600037097931, 0.48061999678611755, 0.47661998867988586, 0.4796600043773651, 0.48076000809669495, 0.4776400029659271, 0.47839999198913574, 0.47699999809265137, 0.4790000021457672, 0.4778999984264374, 0.47947999835014343, 0.47892001271247864, 0.4778999984264374, 0.4794600009918213, 0.4784800112247467, 0.4792400002479553, 0.47986000776290894, 0.47971999645233154, 0.47811999917030334, 0.4801599979400635, 0.4785799980163574, 0.4814000129699707, 0.478300005197525, 0.4822399914264679, 0.47982001304626465, 0.4803600013256073, 0.47694000601768494, 0.4819599986076355, 0.4804399907588959, 0.4790399968624115, 0.4815399944782257, 0.48096001148223877, 0.47999998927116394, 0.48047998547554016, 0.4791800081729889, 0.4800400137901306, 0.4793199896812439, 0.47815999388694763, 0.4783399999141693, 0.4806399941444397, 0.47944000363349915, 0.4804399907588959, 0.4809800088405609, 0.4798800051212311, 0.4789600074291229, 0.4810999929904938, 0.48173999786376953, 0.4819999933242798, 0.4803999960422516, 0.4798800051212311, 0.4812600016593933, 0.48113998770713806, 0.480540007352829, 0.4841200113296509, 0.4821999967098236, 0.48166000843048096, 0.47944000363349915, 0.480459988117218, 0.4829599857330322, 0.4830000102519989, 0.4821400046348572, 0.48194000124931335, 0.4791400134563446, 0.4791400134563446, 0.481440007686615, 0.4819999933242798, 0.4837000072002411, 0.4798400104045868, 0.48263999819755554, 0.4822799861431122, 0.483460009098053, 0.48155999183654785, 0.4828999936580658, 0.48184001445770264, 0.4829599857330322, 0.48489999771118164, 0.48170000314712524, 0.48315998911857605, 0.4828599989414215, 0.48377999663352966, 0.4830799996852875, 0.4834200143814087, 0.482699990272522, 0.4849199950695038, 0.48350000381469727, 0.48429998755455017, 0.4825800061225891, 0.4854600131511688, 0.48326000571250916, 0.48537999391555786, 0.48142001032829285, 0.4851599931716919, 0.48420000076293945, 0.4837599992752075, 0.48357999324798584, 0.48263999819755554, 0.4845600128173828, 0.4841200113296509, 0.4830000102519989, 0.48614001274108887, 0.48221999406814575, 0.4860999882221222, 0.4854600131511688, 0.4858799874782562, 0.48590001463890076, 0.4842199981212616, 0.48471999168395996, 0.483460009098053, 0.4860999882221222, 0.482699990272522, 0.4857200086116791, 0.4832800030708313, 0.4880000054836273, 0.4864400029182434, 0.4849799871444702, 0.4837400019168854, 0.48495998978614807, 0.48539999127388, 0.48598000407218933, 0.48350000381469727, 0.4845399856567383, 0.4863399863243103, 0.483379989862442, 0.4873400032520294, 0.4872399866580963, 0.483240008354187, 0.4855799973011017, 0.4839400053024292, 0.4875999987125397, 0.48673999309539795, 0.48660001158714294, 0.4870400130748749, 0.4857200086116791, 0.4870400130748749, 0.4850800037384033, 0.4872399866580963, 0.4869000017642975, 0.487199991941452, 0.48548001050949097, 0.48646000027656555, 0.48857998847961426, 0.4841200113296509, 0.48405998945236206, 0.4864799976348877, 0.4883599877357483, 0.4851599931716919, 0.48715999722480774, 0.4866600036621094, 0.48774001002311707, 0.48919999599456787, 0.48611998558044434, 0.4873400032520294, 0.4877200126647949, 0.4854399859905243, 0.48715999722480774, 0.48730000853538513, 0.4848000109195709, 0.48993998765945435, 0.48805999755859375, 0.4876599907875061, 0.4879800081253052, 0.48809999227523804, 0.48809999227523804, 0.4897400140762329, 0.4875600039958954, 0.48833999037742615, 0.48805999755859375, 0.4915800094604492, 0.48631998896598816, 0.4878999888896942, 0.486299991607666, 0.48871999979019165, 0.4896799921989441, 0.48736000061035156, 0.4880400002002716, 0.4895400106906891, 0.4871799945831299, 0.4889799952507019, 0.490200012922287, 0.4893600046634674, 0.4884600043296814, 0.48980000615119934, 0.4888800084590912, 0.4906800091266632, 0.49059998989105225, 0.488319993019104, 0.489300012588501, 0.48984000086784363, 0.48914000391960144, 0.48976001143455505, 0.4891600012779236, 0.49000000953674316, 0.4921000003814697, 0.49129998683929443, 0.4895400106906891, 0.4909999966621399, 0.49079999327659607, 0.4894599914550781, 0.49042001366615295, 0.49050000309944153, 0.49028000235557556, 0.4918400049209595, 0.4907599985599518, 0.49164000153541565, 0.4925200045108795, 0.488180011510849, 0.49066001176834106, 0.48962000012397766, 0.4904400110244751, 0.4892599880695343, 0.49066001176834106, 0.48890000581741333, 0.4893999993801117, 0.4888400137424469, 0.48853999376296997, 0.49272000789642334, 0.4884200096130371, 0.4881199896335602, 0.4909600019454956, 0.4909600019454956, 0.4900200068950653, 0.4885199964046478, 0.4907200038433075, 0.4909999966621399, 0.4925200045108795, 0.4955199956893921, 0.49055999517440796, 0.49441999197006226, 0.48938000202178955, 0.49195998907089233, 0.4920400083065033, 0.49132001399993896, 0.4906800091266632, 0.49285998940467834, 0.4911400079727173, 0.49215999245643616, 0.4927000105381012, 0.49281999468803406, 0.4925000071525574, 0.49410000443458557, 0.49206000566482544, 0.49268001317977905, 0.4928399920463562, 0.4934999942779541, 0.4907599985599518, 0.4943999946117401, 0.49371999502182007, 0.4899199903011322, 0.49371999502182007, 0.49366000294685364, 0.4929800033569336, 0.4943999946117401, 0.49281999468803406, 0.49239999055862427, 0.49531999230384827, 0.4930399954319, 0.49535998702049255, 0.4915199875831604, 0.4944800138473511, 0.49470001459121704, 0.4956200122833252, 0.49421998858451843, 0.49393999576568604, 0.49281999468803406, 0.49327999353408813, 0.49487999081611633, 0.4919799864292145, 0.4946399927139282, 0.4938800036907196, 0.4925599992275238, 0.4952400028705597, 0.4930399954319, 0.49070000648498535, 0.49474000930786133, 0.4948599934577942, 0.49132001399993896, 0.49643999338150024, 0.49404001235961914, 0.49737998843193054, 0.49570000171661377, 0.4969399869441986, 0.4962800145149231, 0.49441999197006226, 0.4947200119495392, 0.49559998512268066, 0.49928000569343567, 0.49654000997543335, 0.4966000020503998, 0.49803999066352844, 0.4970400035381317, 0.49904000759124756, 0.4986000061035156, 0.4978199899196625, 0.5004000067710876, 0.4988600015640259, 0.4957199990749359, 0.5000200271606445, 0.4986799955368042, 0.4981600046157837, 0.49900001287460327, 0.500980019569397, 0.4973599910736084, 0.4970400035381317, 0.4991999864578247, 0.49880000948905945, 0.4984399974346161, 0.5009400248527527, 0.5003600120544434, 0.4973199963569641, 0.49842000007629395, 0.4997200071811676, 0.5003200173377991, 0.49761998653411865, 0.4992600083351135, 0.5001999735832214, 0.49928000569343567, 0.4994400143623352, 0.49845999479293823, 0.5001000165939331, 0.4983200132846832, 0.5020400285720825, 0.5004600286483765, 0.4996199905872345, 0.49838000535964966, 0.501039981842041, 0.4979200065135956, 0.5002599954605103, 0.49939998984336853, 0.5006600022315979, 0.4998199939727783, 0.5005599856376648, 0.49838000535964966, 0.4984799921512604, 0.5001400113105774, 0.49873998761177063, 0.4985800087451935, 0.49946001172065735, 0.5006600022315979, 0.5017600059509277, 0.4999600052833557, 0.5004799962043762, 0.49983999133110046, 0.5006800293922424, 0.49678000807762146, 0.5029000043869019, 0.5009599924087524, 0.5044599771499634, 0.4997200071811676, 0.5002800226211548, 0.49779999256134033, 0.4971599876880646, 0.49636000394821167, 0.49856001138687134, 0.5016199946403503, 0.5022600293159485, 0.5015599727630615, 0.4984799921512604, 0.4975599944591522, 0.49779999256134033, 0.49889999628067017, 0.5000799894332886, 0.49733999371528625, 0.5006600022315979, 0.4966999888420105, 0.5000799894332886, 0.4974200129508972, 0.5004799962043762, 0.4984799921512604, 0.4993399977684021, 0.500760018825531, 0.499099999666214, 0.5004000067710876, 0.49757999181747437, 0.498879998922348, 0.5010600090026855, 0.49983999133110046, 0.5023800134658813, 0.4978399872779846, 0.5000600218772888, 0.5009400248527527, 0.4974200129508972, 0.4987199902534485, 0.5002999901771545, 0.500819981098175, 0.4976600110530853, 0.5008800029754639, 0.5017399787902832, 0.5007799863815308, 0.49796000123023987, 0.5015199780464172, 0.5008599758148193, 0.5021600127220154, 0.5037400126457214, 0.5005800127983093, 0.5019599795341492, 0.5037199854850769, 0.5016999840736389, 0.49955999851226807, 0.501479983329773, 0.5016999840736389, 0.49761998653411865, 0.4975399971008301, 0.49803999066352844, 0.49873998761177063, 0.5026000142097473, 0.4992600083351135, 0.5009199976921082, 0.49893999099731445, 0.501479983329773, 0.500220000743866, 0.5025399923324585, 0.5006200075149536, 0.5000200271606445, 0.5019999742507935, 0.4996199905872345, 0.4986799955368042, 0.500760018825531, 0.49955999851226807, 0.5018200278282166, 0.5002999901771545, 0.502240002155304, 0.5012800097465515, 0.5004600286483765, 0.5012400150299072, 0.5033800005912781, 0.5040799975395203, 0.49994000792503357, 0.5002400279045105, 0.5015400052070618, 0.500760018825531, 0.5009199976921082, 0.49880000948905945, 0.49939998984336853, 0.5024399757385254, 0.5021799802780151, 0.5030800104141235, 0.5055800080299377, 0.5016199946403503, 0.5017399787902832, 0.500980019569397, 0.4983200132846832, 0.5005800127983093, 0.5030800104141235, 0.5020400285720825, 0.5035200119018555, 0.5033000111579895, 0.5009599924087524, 0.5023199915885925, 0.5025799870491028, 0.5023800134658813, 0.5009400248527527, 0.5015400052070618, 0.5023199915885925, 0.5, 0.5051000118255615, 0.499099999666214, 0.5004400014877319, 0.5011000037193298, 0.5020400285720825, 0.5014200210571289, 0.49935999512672424, 0.505079984664917, 0.5002599954605103, 0.5002400279045105, 0.5029399991035461, 0.49939998984336853, 0.5019599795341492, 0.5025799870491028, 0.5026999711990356, 0.49900001287460327, 0.4978399872779846, 0.5002999901771545, 0.5000799894332886, 0.5039200186729431, 0.49955999851226807, 0.5010200142860413, 0.5017600059509277, 0.5029199719429016, 0.5000399947166443, 0.5019000172615051, 0.5008599758148193, 0.5011799931526184, 0.5027599930763245, 0.5012999773025513, 0.5021399855613708, 0.5042600035667419, 0.5015199780464172, 0.5019800066947937, 0.5017600059509277, 0.5034800171852112, 0.5010200142860413, 0.5001800060272217, 0.5008800029754639, 0.5047799944877625, 0.5017799735069275, 0.5044199824333191, 0.5013399720191956, 0.5018600225448608, 0.5021399855613708, 0.5024200081825256, 0.5019599795341492, 0.5009999871253967, 0.5030199885368347, 0.5016599893569946, 0.5026800036430359, 0.5001199841499329, 0.5051400065422058, 0.5027999877929688, 0.5027400255203247, 0.5027599930763245, 0.5040799975395203, 0.5034999847412109, 0.5021399855613708, 0.5031800270080566, 0.5007399916648865, 0.5008000135421753, 0.5023000240325928, 0.502240002155304, 0.5031200051307678, 0.5032399892807007, 0.5020400285720825, 0.503600001335144, 0.5017200112342834, 0.5041400194168091, 0.5026999711990356, 0.5041000247001648, 0.5026800036430359, 0.5029199719429016, 0.5049200057983398, 0.5017399787902832, 0.5044199824333191, 0.5053600072860718, 0.5027400255203247, 0.5040599703788757, 0.5031200051307678, 0.5040199756622314, 0.5006600022315979, 0.5057200193405151, 0.5016599893569946, 0.5016599893569946, 0.5034599900245667, 0.5012800097465515, 0.5052400231361389, 0.5018600225448608, 0.5039200186729431, 0.5010799765586853, 0.5048400163650513, 0.5026999711990356, 0.5019599795341492, 0.5012400150299072, 0.5042399764060974, 0.5037199854850769, 0.5034599900245667, 0.5029199719429016, 0.502240002155304, 0.5026800036430359, 0.5036600232124329, 0.5049999952316284, 0.5018799901008606, 0.5052800178527832, 0.5024799704551697, 0.504580020904541, 0.5006200075149536, 0.5024200081825256, 0.502240002155304, 0.5046200156211853, 0.5029399991035461, 0.5047600269317627, 0.5011399984359741, 0.5043799877166748, 0.5053399801254272, 0.5031800270080566, 0.505020022392273, 0.5019199848175049, 0.5032600164413452, 0.5033800005912781, 0.5055000185966492, 0.5022600293159485, 0.5029199719429016, 0.502560019493103, 0.5031599998474121, 0.5012199878692627, 0.5073800086975098, 0.503000020980835, 0.5061600208282471], 'val_loss': [4.601250171661377, 4.58420991897583, 4.495017051696777, 4.352419376373291, 4.183651924133301, 4.1417012214660645, 4.041938781738281, 3.9487452507019043, 3.903748035430908, 3.839449882507324, 3.789210081100464, 3.7698543071746826, 3.7096612453460693, 3.670250415802002, 3.6746437549591064, 3.600543737411499, 3.5165092945098877, 3.4945971965789795, 3.4262754917144775, 3.412154197692871, 3.375779390335083, 3.3356058597564697, 3.315373420715332, 3.24147891998291, 3.2163491249084473, 3.1943891048431396, 3.174849271774292, 3.1335580348968506, 3.116060972213745, 3.0903401374816895, 3.0694780349731445, 3.074563980102539, 3.033698320388794, 3.025846481323242, 3.016568422317505, 3.0178487300872803, 2.955233573913574, 2.9319896697998047, 2.9176974296569824, 2.9078028202056885, 2.896986246109009, 2.924609899520874, 2.8610377311706543, 2.8637688159942627, 2.8795008659362793, 2.8303637504577637, 2.8261241912841797, 2.838275909423828, 2.827638626098633, 2.79241943359375, 2.795689582824707, 2.7655141353607178, 2.8147940635681152, 2.797407388687134, 2.7907028198242188, 2.737203598022461, 2.730818748474121, 2.7371275424957275, 2.7344441413879395, 2.728549003601074, 2.695204973220825, 2.7106680870056152, 2.6966211795806885, 2.683414936065674, 2.6801042556762695, 2.678071975708008, 2.671408176422119, 2.670382499694824, 2.691743850708008, 2.669398307800293, 2.6522903442382812, 2.6785190105438232, 2.665733575820923, 2.706489086151123, 2.6334545612335205, 2.622535467147827, 2.6137027740478516, 2.615766763687134, 2.6132965087890625, 2.6556406021118164, 2.60530948638916, 2.636615514755249, 2.607604742050171, 2.6036033630371094, 2.588346004486084, 2.5992205142974854, 2.6090543270111084, 2.5944409370422363, 2.586303234100342, 2.6031932830810547, 2.5665342807769775, 2.5934576988220215, 2.569431781768799, 2.550795078277588, 2.545527458190918, 2.6106772422790527, 2.566833257675171, 2.5267369747161865, 2.5552752017974854, 2.542402505874634, 2.5339698791503906, 2.5082144737243652, 2.526676893234253, 2.5158627033233643, 2.5000998973846436, 2.4895665645599365, 2.4969656467437744, 2.520326852798462, 2.484689950942993, 2.496492385864258, 2.490041732788086, 2.491037130355835, 2.4964232444763184, 2.496995210647583, 2.5020406246185303, 2.504730224609375, 2.480215549468994, 2.5005273818969727, 2.480775833129883, 2.47222638130188, 2.4897289276123047, 2.5006051063537598, 2.5274643898010254, 2.4764745235443115, 2.4756553173065186, 2.4779083728790283, 2.4788787364959717, 2.4872114658355713, 2.487089157104492, 2.4652020931243896, 2.5126328468322754, 2.474716901779175, 2.4640629291534424, 2.4946768283843994, 2.4662768840789795, 2.5058372020721436, 2.4899861812591553, 2.476978063583374, 2.4840805530548096, 2.4616386890411377, 2.4702107906341553, 2.4599204063415527, 2.4708850383758545, 2.4629225730895996, 2.4897444248199463, 2.4604380130767822, 2.45798397064209, 2.4717600345611572, 2.490283966064453, 2.4546070098876953, 2.465648889541626, 2.464867353439331, 2.485522508621216, 2.456636428833008, 2.461239814758301, 2.4695403575897217, 2.4471068382263184, 2.4481313228607178, 2.470912456512451, 2.451976776123047, 2.4534976482391357, 2.455059289932251, 2.4469783306121826, 2.4394233226776123, 2.4641952514648438, 2.436145782470703, 2.433213710784912, 2.4582438468933105, 2.446791648864746, 2.4685826301574707, 2.4344253540039062, 2.4299161434173584, 2.478773355484009, 2.4492666721343994, 2.4677278995513916, 2.455246925354004, 2.454162836074829, 2.442108154296875, 2.439033269882202, 2.4370648860931396, 2.447115659713745, 2.4651825428009033, 2.4455809593200684, 2.430861711502075, 2.4251699447631836, 2.4722719192504883, 2.4538190364837646, 2.4640021324157715, 2.4332451820373535, 2.4405932426452637, 2.430401563644409, 2.436929702758789, 2.4444150924682617, 2.434889078140259, 2.426356554031372, 2.4194071292877197, 2.427408456802368, 2.42798113822937, 2.4353532791137695, 2.4427409172058105, 2.4136440753936768, 2.4170424938201904, 2.40468692779541, 2.4166903495788574, 2.4017112255096436, 2.3982937335968018, 2.4041078090667725, 2.4039530754089355, 2.4125232696533203, 2.4027764797210693, 2.401073694229126, 2.4215972423553467, 2.400235414505005, 2.4199178218841553, 2.3991997241973877, 2.4111135005950928, 2.404747486114502, 2.422154188156128, 2.430863857269287, 2.4034781455993652, 2.4070003032684326, 2.4096736907958984, 2.406076431274414, 2.4019908905029297, 2.398056983947754, 2.4024980068206787, 2.4366354942321777, 2.4009180068969727, 2.4121930599212646, 2.40173077583313, 2.4097530841827393, 2.415370225906372, 2.4053702354431152, 2.3963916301727295, 2.393886089324951, 2.3922643661499023, 2.410496711730957, 2.4009287357330322, 2.4053380489349365, 2.4132838249206543, 2.4022369384765625, 2.402020215988159, 2.430016040802002, 2.402449131011963, 2.3894271850585938, 2.4049570560455322, 2.3998241424560547, 2.440617561340332, 2.4127180576324463, 2.3920602798461914, 2.396757125854492, 2.39839768409729, 2.393425464630127, 2.388554811477661, 2.425649642944336, 2.404628038406372, 2.389775514602661, 2.393817663192749, 2.4022610187530518, 2.395933151245117, 2.39719557762146, 2.3914852142333984, 2.398682117462158, 2.3847429752349854, 2.416048765182495, 2.39909291267395, 2.397202253341675, 2.3886961936950684, 2.3946430683135986, 2.4075117111206055, 2.4014506340026855, 2.402305841445923, 2.3847532272338867, 2.3899686336517334, 2.4021496772766113, 2.3861403465270996, 2.395690441131592, 2.3889429569244385, 2.3935041427612305, 2.408485174179077, 2.3845207691192627, 2.3910629749298096, 2.3783302307128906, 2.3909194469451904, 2.395444631576538, 2.411648750305176, 2.3892276287078857, 2.4231560230255127, 2.397739887237549, 2.384335517883301, 2.406296730041504, 2.396409749984741, 2.383664846420288, 2.3860321044921875, 2.4082961082458496, 2.3915843963623047, 2.3915562629699707, 2.400531768798828, 2.3797080516815186, 2.39412784576416, 2.403799295425415, 2.3888754844665527, 2.4109408855438232, 2.3866677284240723, 2.377587080001831, 2.3907253742218018, 2.397747755050659, 2.393437385559082, 2.380620002746582, 2.3846747875213623, 2.3942039012908936, 2.398801326751709, 2.389819622039795, 2.37615966796875, 2.373210906982422, 2.383784770965576, 2.41019868850708, 2.37789249420166, 2.3892383575439453, 2.378537178039551, 2.376741886138916, 2.3664469718933105, 2.375410556793213, 2.3937184810638428, 2.398538827896118, 2.395651340484619, 2.3841872215270996, 2.4100773334503174, 2.4061310291290283, 2.4129533767700195, 2.3831825256347656, 2.415027618408203, 2.394456148147583, 2.4067890644073486, 2.3877065181732178, 2.3911893367767334, 2.372527837753296, 2.392642021179199, 2.3857431411743164, 2.4033753871917725, 2.377046585083008, 2.4125261306762695, 2.3865420818328857, 2.3800270557403564, 2.386187791824341, 2.3804092407226562, 2.3875479698181152, 2.3749587535858154, 2.4006125926971436, 2.368779182434082, 2.378661870956421, 2.3788764476776123, 2.382373332977295, 2.3821358680725098, 2.3734312057495117, 2.3716397285461426, 2.37288761138916, 2.380868673324585, 2.3664581775665283, 2.4055068492889404, 2.3773632049560547, 2.398693084716797, 2.371823787689209, 2.3806893825531006, 2.3749186992645264, 2.389699935913086, 2.363135814666748, 2.3832688331604004, 2.3872482776641846, 2.3736917972564697, 2.3760805130004883, 2.392652750015259, 2.3890738487243652, 2.388127088546753, 2.430967092514038, 2.4020211696624756, 2.3794443607330322, 2.3791677951812744, 2.367225170135498, 2.381010055541992, 2.3659591674804688, 2.401810646057129, 2.3717894554138184, 2.3744540214538574, 2.3791205883026123, 2.364142656326294, 2.379178524017334, 2.377454996109009, 2.384226083755493, 2.373823642730713, 2.376413106918335, 2.3789703845977783, 2.373722791671753, 2.363260507583618, 2.3635480403900146, 2.3684794902801514, 2.3705692291259766, 2.373532772064209, 2.396597146987915, 2.372284412384033, 2.3595385551452637, 2.369396209716797, 2.3759043216705322, 2.366156816482544, 2.363969087600708, 2.3742966651916504, 2.3715968132019043, 2.3723788261413574, 2.3599255084991455, 2.3646256923675537, 2.363696575164795, 2.351682186126709, 2.36696457862854, 2.3750128746032715, 2.3659932613372803, 2.3663554191589355, 2.3851161003112793, 2.364877462387085, 2.363269805908203, 2.369643211364746, 2.361085891723633, 2.3709301948547363, 2.3660452365875244, 2.365133285522461, 2.3725433349609375, 2.3638815879821777, 2.360811233520508, 2.3668296337127686, 2.361443042755127, 2.3681745529174805, 2.3728830814361572, 2.368809938430786, 2.374438762664795, 2.3703720569610596, 2.374732494354248, 2.36678409576416, 2.359172821044922, 2.3638880252838135, 2.366151809692383, 2.3658735752105713, 2.358943223953247, 2.365989923477173, 2.359689712524414, 2.365826368331909, 2.3606390953063965, 2.380156993865967, 2.352918863296509, 2.364665985107422, 2.3662843704223633, 2.3628716468811035, 2.366029739379883, 2.356832504272461, 2.3622219562530518, 2.367380380630493, 2.367755651473999, 2.364560604095459, 2.375775098800659, 2.359144449234009, 2.372546911239624, 2.3677456378936768, 2.354696035385132, 2.3653340339660645, 2.3645694255828857, 2.360684871673584, 2.3669419288635254, 2.3595051765441895, 2.368725061416626, 2.364633321762085, 2.3704001903533936, 2.361422061920166, 2.361201286315918, 2.354548931121826, 2.3672523498535156, 2.35477614402771, 2.3685197830200195, 2.353752613067627, 2.3564183712005615, 2.3614845275878906, 2.360957145690918, 2.372331142425537, 2.360387086868286, 2.360136032104492, 2.3819196224212646, 2.3546838760375977, 2.359694004058838, 2.369638204574585, 2.356377601623535, 2.358981132507324, 2.3581535816192627, 2.358644962310791, 2.357564926147461, 2.3697919845581055, 2.3583502769470215, 2.3613686561584473, 2.3548102378845215, 2.3824543952941895, 2.355131149291992, 2.365537405014038, 2.3533859252929688, 2.3596584796905518, 2.381291151046753, 2.3643274307250977, 2.3934829235076904, 2.361173152923584, 2.3692967891693115, 2.368511438369751, 2.368633508682251, 2.3680458068847656, 2.363696575164795, 2.361475944519043, 2.3636434078216553, 2.3632636070251465, 2.3660199642181396, 2.3789381980895996, 2.368285894393921, 2.357801675796509, 2.3618698120117188, 2.362835645675659, 2.3681137561798096, 2.363738775253296, 2.363051414489746, 2.3648550510406494, 2.365895986557007, 2.3537094593048096, 2.3614625930786133, 2.3676021099090576, 2.3558695316314697, 2.3583319187164307, 2.3621792793273926, 2.3748836517333984, 2.354496479034424, 2.3592114448547363, 2.3706276416778564, 2.357038974761963, 2.3692057132720947, 2.352982521057129, 2.3632874488830566, 2.3634767532348633, 2.3710856437683105, 2.351313352584839, 2.356173515319824, 2.3681607246398926, 2.3627309799194336, 2.365055799484253, 2.3610520362854004, 2.382028579711914, 2.3545243740081787, 2.3613502979278564, 2.3683478832244873, 2.3590264320373535, 2.3753809928894043, 2.3584744930267334, 2.368468999862671, 2.35160756111145, 2.357490062713623, 2.371342658996582, 2.3686156272888184, 2.363238573074341, 2.3614470958709717, 2.354163408279419, 2.357255697250366, 2.3580007553100586, 2.3684499263763428, 2.361403226852417, 2.3561911582946777, 2.360236406326294, 2.3632965087890625, 2.367093563079834, 2.3719112873077393, 2.364076852798462, 2.3631176948547363, 2.371453285217285, 2.365816593170166, 2.356597423553467, 2.347439765930176, 2.354118585586548, 2.3547682762145996, 2.37184476852417, 2.3615949153900146, 2.3558428287506104, 2.3601317405700684, 2.3591630458831787, 2.361274003982544, 2.3601906299591064, 2.361452102661133, 2.3592324256896973, 2.3689305782318115, 2.3682875633239746, 2.3579835891723633, 2.3612537384033203, 2.3681392669677734, 2.3712899684906006, 2.3516504764556885, 2.3758058547973633, 2.3629024028778076, 2.3507843017578125, 2.357280969619751, 2.3622350692749023, 2.3521366119384766, 2.3697831630706787, 2.358854293823242, 2.366732597351074, 2.367692708969116, 2.3556160926818848, 2.356799840927124, 2.352019786834717, 2.3652541637420654, 2.3514959812164307, 2.37919020652771, 2.358686685562134, 2.3695621490478516, 2.354971170425415, 2.3633909225463867, 2.359805107116699, 2.357917308807373, 2.365548849105835, 2.3552229404449463, 2.3502066135406494, 2.3596138954162598, 2.361232042312622, 2.3585948944091797, 2.356403112411499, 2.347764492034912, 2.3714563846588135, 2.3619747161865234, 2.364192008972168, 2.3637642860412598, 2.3663432598114014, 2.390174150466919, 2.3682572841644287, 2.3640646934509277, 2.3602256774902344, 2.353661060333252, 2.352191925048828, 2.3551695346832275, 2.357785701751709, 2.363957643508911, 2.3607475757598877, 2.356907606124878, 2.3723082542419434, 2.345418691635132, 2.356905937194824, 2.3537228107452393, 2.3566501140594482, 2.3554868698120117, 2.3572373390197754, 2.36510968208313, 2.3638153076171875, 2.3724122047424316, 2.354775905609131, 2.3602147102355957, 2.3535208702087402, 2.3672919273376465, 2.3528614044189453, 2.3815503120422363, 2.357494354248047, 2.357869863510132, 2.3541340827941895, 2.386601448059082, 2.359992027282715, 2.3575034141540527, 2.3522422313690186, 2.350548267364502, 2.352705717086792, 2.3587095737457275, 2.3681728839874268, 2.351090908050537, 2.359057903289795, 2.3574752807617188, 2.3609323501586914, 2.367786407470703, 2.3761463165283203, 2.361215829849243, 2.350813627243042, 2.359269142150879, 2.3543901443481445, 2.3610997200012207, 2.3524489402770996, 2.3521416187286377, 2.3668949604034424, 2.3589954376220703, 2.377420425415039, 2.3562264442443848, 2.361232280731201, 2.359959602355957, 2.3632705211639404, 2.3596951961517334, 2.3680763244628906, 2.3597147464752197, 2.35568904876709, 2.3563761711120605, 2.353212594985962, 2.370313882827759, 2.352287530899048, 2.366349220275879, 2.3525350093841553, 2.363748550415039, 2.3635447025299072, 2.3638057708740234, 2.3647336959838867, 2.3486266136169434, 2.3528990745544434, 2.358320713043213, 2.3494904041290283, 2.349392890930176, 2.3526155948638916, 2.351029396057129, 2.358243465423584, 2.3518612384796143, 2.3537473678588867, 2.353201150894165, 2.348567008972168, 2.348360538482666, 2.3478784561157227, 2.3529889583587646, 2.35321044921875, 2.352463960647583, 2.349400758743286, 2.3495538234710693, 2.3537580966949463, 2.353868246078491, 2.346728563308716, 2.35845947265625, 2.3543665409088135, 2.351450204849243, 2.3534936904907227, 2.356187582015991, 2.353489875793457, 2.3510377407073975, 2.351799964904785, 2.358887195587158, 2.3506345748901367, 2.346994161605835, 2.3504252433776855, 2.3664708137512207, 2.35355281829834, 2.354888677597046, 2.3537111282348633, 2.3523237705230713, 2.3537654876708984, 2.347919225692749, 2.352555513381958, 2.3523519039154053, 2.3453121185302734, 2.354409694671631, 2.3600926399230957, 2.355746030807495, 2.3540637493133545, 2.35522198677063, 2.34919810295105, 2.3514137268066406, 2.355025291442871, 2.3542301654815674, 2.356740713119507, 2.355635404586792, 2.3508613109588623, 2.3520419597625732, 2.357553005218506, 2.354030132293701, 2.3524410724639893, 2.356823682785034, 2.3459835052490234, 2.3539061546325684, 2.350191593170166, 2.355421781539917, 2.3501992225646973, 2.3517844676971436, 2.3543074131011963, 2.3490676879882812, 2.3474769592285156, 2.353566884994507, 2.349365711212158, 2.355675220489502, 2.3490278720855713, 2.3481531143188477, 2.3521268367767334, 2.3517982959747314, 2.3559813499450684, 2.3626341819763184, 2.360438346862793, 2.3612186908721924, 2.351041793823242, 2.3528945446014404, 2.348698139190674, 2.3546173572540283, 2.3539326190948486, 2.352235794067383, 2.3539228439331055, 2.3570919036865234, 2.351994037628174, 2.3530027866363525, 2.355574607849121, 2.350787401199341, 2.3528409004211426, 2.3485889434814453, 2.363138198852539, 2.354619264602661, 2.352062225341797, 2.35025691986084, 2.3522629737854004, 2.3558883666992188, 2.3482415676116943, 2.3532357215881348, 2.357088804244995, 2.3504955768585205, 2.3489744663238525, 2.349306344985962, 2.3509764671325684, 2.35093092918396, 2.346578598022461, 2.3521063327789307, 2.3551578521728516, 2.349491596221924, 2.351654529571533, 2.3537955284118652, 2.3512799739837646, 2.3535454273223877, 2.346506357192993, 2.3530707359313965, 2.3561410903930664, 2.36114501953125, 2.359184741973877, 2.3501853942871094, 2.3560993671417236, 2.355491876602173, 2.3542721271514893, 2.3484280109405518, 2.360128402709961, 2.348581314086914, 2.3557231426239014, 2.351562738418579, 2.3576560020446777, 2.351316213607788, 2.351355791091919, 2.348113775253296, 2.356956720352173, 2.3585715293884277, 2.3567447662353516, 2.3517563343048096, 2.353029251098633, 2.3521947860717773, 2.348165512084961, 2.3503565788269043, 2.3585987091064453, 2.354189872741699, 2.350054979324341, 2.3463661670684814, 2.357109308242798, 2.351850986480713, 2.3502073287963867, 2.3534469604492188, 2.349456787109375, 2.3516921997070312, 2.362370014190674, 2.355079174041748, 2.354201078414917, 2.3511085510253906, 2.3565287590026855, 2.354254961013794, 2.3544762134552, 2.3503870964050293, 2.3531932830810547, 2.351161241531372, 2.351621389389038, 2.3476319313049316, 2.347254753112793, 2.3502440452575684, 2.3566715717315674, 2.352116107940674, 2.355877637863159, 2.356565237045288, 2.350527048110962, 2.353922128677368, 2.353485107421875, 2.356112241744995, 2.3548531532287598, 2.352322816848755, 2.3550405502319336, 2.3557214736938477, 2.345623016357422, 2.3552744388580322, 2.3488147258758545, 2.354243278503418, 2.349842071533203, 2.354311466217041, 2.3558080196380615, 2.3554584980010986, 2.3506340980529785, 2.346442461013794, 2.349630355834961, 2.3479926586151123, 2.347288131713867, 2.35481858253479, 2.3510165214538574, 2.3519163131713867, 2.3539116382598877, 2.356444835662842, 2.349752902984619, 2.3538131713867188, 2.3500475883483887, 2.355668306350708, 2.354616165161133, 2.350651979446411, 2.3479785919189453, 2.3535377979278564, 2.3495845794677734, 2.3512895107269287, 2.3488094806671143, 2.3498220443725586, 2.3488516807556152, 2.3508243560791016, 2.3529999256134033, 2.3596160411834717, 2.3531808853149414, 2.3542611598968506, 2.3557193279266357, 2.3484888076782227, 2.3489861488342285, 2.3506100177764893, 2.3526432514190674, 2.348781108856201, 2.3501226902008057, 2.350372314453125, 2.3546195030212402, 2.3582963943481445, 2.356220006942749, 2.349093437194824, 2.3508734703063965, 2.355311870574951, 2.346825122833252, 2.3469183444976807, 2.355229616165161, 2.354705572128296, 2.353455066680908, 2.3526463508605957, 2.353889226913452, 2.356886863708496, 2.351637840270996, 2.3545644283294678, 2.3554015159606934, 2.3513412475585938, 2.353764057159424, 2.3547518253326416, 2.3544435501098633, 2.350351572036743, 2.349900722503662, 2.3525757789611816, 2.3567428588867188, 2.352688789367676, 2.3519275188446045, 2.3540632724761963, 2.3490817546844482, 2.34366512298584, 2.3517796993255615, 2.3522467613220215, 2.356444835662842, 2.35139536857605, 2.3508126735687256, 2.351531744003296, 2.3531172275543213, 2.350499153137207, 2.3486063480377197, 2.3497250080108643, 2.352980613708496, 2.3493549823760986, 2.354386806488037, 2.34944486618042, 2.3496124744415283, 2.3513355255126953, 2.3534798622131348, 2.347701072692871, 2.350029468536377, 2.3523330688476562, 2.347435235977173, 2.351194143295288, 2.3476836681365967, 2.353008985519409, 2.3592419624328613, 2.3493118286132812, 2.3516147136688232, 2.3511009216308594, 2.3510451316833496, 2.3523073196411133, 2.35412859916687, 2.350534439086914, 2.3562521934509277, 2.3479714393615723, 2.3554227352142334, 2.3504981994628906, 2.3528411388397217, 2.354583263397217, 2.357970714569092, 2.3530185222625732, 2.3499553203582764, 2.349548578262329, 2.354641914367676, 2.352030038833618, 2.354945659637451, 2.3587052822113037, 2.3588409423828125], 'val_accuracy': [0.01209999993443489, 0.01730000041425228, 0.024800000712275505, 0.03460000082850456, 0.055799998342990875, 0.06539999693632126, 0.08169999718666077, 0.09640000015497208, 0.09709999710321426, 0.11180000007152557, 0.12639999389648438, 0.12939999997615814, 0.1386999934911728, 0.1446000039577484, 0.14790000021457672, 0.16030000150203705, 0.17710000276565552, 0.18160000443458557, 0.19249999523162842, 0.19609999656677246, 0.19920000433921814, 0.20669999718666077, 0.20999999344348907, 0.22439999878406525, 0.2257000058889389, 0.2312999963760376, 0.23929999768733978, 0.24449999630451202, 0.24709999561309814, 0.2515000104904175, 0.2551000118255615, 0.2551000118255615, 0.26170000433921814, 0.2669000029563904, 0.26820001006126404, 0.26660001277923584, 0.2784999907016754, 0.28040000796318054, 0.28540000319480896, 0.28839999437332153, 0.28610000014305115, 0.2897999882698059, 0.2957000136375427, 0.2953000068664551, 0.29269999265670776, 0.2992999851703644, 0.30149999260902405, 0.3061000108718872, 0.29980000853538513, 0.3100000023841858, 0.30880001187324524, 0.3165000081062317, 0.3124000132083893, 0.3091000020503998, 0.31310001015663147, 0.32010000944137573, 0.3176000118255615, 0.32589998841285706, 0.3199999928474426, 0.3248000144958496, 0.33390000462532043, 0.32589998841285706, 0.3310000002384186, 0.33219999074935913, 0.33379998803138733, 0.3327000141143799, 0.33799999952316284, 0.33390000462532043, 0.3325999975204468, 0.33550000190734863, 0.3400999903678894, 0.33180001378059387, 0.3400999903678894, 0.32409998774528503, 0.34299999475479126, 0.3431999981403351, 0.3490999937057495, 0.34790000319480896, 0.3474999964237213, 0.33820000290870667, 0.3506999909877777, 0.3433000147342682, 0.3492000102996826, 0.3499999940395355, 0.34850001335144043, 0.351500004529953, 0.3450999855995178, 0.34790000319480896, 0.3538999855518341, 0.34630000591278076, 0.3553999960422516, 0.35109999775886536, 0.3528999984264374, 0.35670000314712524, 0.36039999127388, 0.34880000352859497, 0.3553999960422516, 0.367000013589859, 0.3578000068664551, 0.36399999260902405, 0.3653999865055084, 0.37040001153945923, 0.3677000105381012, 0.36579999327659607, 0.3693000078201294, 0.37299999594688416, 0.3711000084877014, 0.36899998784065247, 0.37299999594688416, 0.36890000104904175, 0.3711000084877014, 0.3750999867916107, 0.3693000078201294, 0.3718999922275543, 0.3686999976634979, 0.3671000003814697, 0.37310001254081726, 0.3668999969959259, 0.37400001287460327, 0.3756999969482422, 0.3702000081539154, 0.3671000003814697, 0.36230000853538513, 0.37279999256134033, 0.3758000135421753, 0.37380000948905945, 0.37470000982284546, 0.3725999891757965, 0.37369999289512634, 0.3774000108242035, 0.36489999294281006, 0.37369999289512634, 0.37869998812675476, 0.36910000443458557, 0.37700000405311584, 0.3677000105381012, 0.373199999332428, 0.3772999942302704, 0.37220001220703125, 0.37380000948905945, 0.3790999948978424, 0.37860000133514404, 0.3756999969482422, 0.3781999945640564, 0.3718000054359436, 0.3788999915122986, 0.3774000108242035, 0.37790000438690186, 0.36899998784065247, 0.37950000166893005, 0.3774000108242035, 0.37869998812675476, 0.3725999891757965, 0.3776000142097473, 0.3750999867916107, 0.3772999942302704, 0.37959998846054077, 0.38089999556541443, 0.37369999289512634, 0.37950000166893005, 0.37959998846054077, 0.37599998712539673, 0.37779998779296875, 0.3831999897956848, 0.37560001015663147, 0.38449999690055847, 0.3833000063896179, 0.37689998745918274, 0.3799999952316284, 0.3776000142097473, 0.38269999623298645, 0.38850000500679016, 0.37380000948905945, 0.3804999887943268, 0.3765000104904175, 0.37860000133514404, 0.3774000108242035, 0.3824000060558319, 0.3865000009536743, 0.3855000138282776, 0.3831000030040741, 0.37770000100135803, 0.3817000091075897, 0.38429999351501465, 0.3898000121116638, 0.38019999861717224, 0.38670000433921814, 0.37720000743865967, 0.38600000739097595, 0.3828999996185303, 0.38280001282691956, 0.38280001282691956, 0.3813000023365021, 0.38370001316070557, 0.3871999979019165, 0.38580000400543213, 0.3882000148296356, 0.38839998841285706, 0.38350000977516174, 0.38530001044273376, 0.3901999890804291, 0.3894999921321869, 0.39340001344680786, 0.38659998774528503, 0.3903000056743622, 0.39570000767707825, 0.3928000032901764, 0.3919999897480011, 0.3882000148296356, 0.3935999870300293, 0.39329999685287476, 0.388700008392334, 0.39340001344680786, 0.3882000148296356, 0.39079999923706055, 0.3882000148296356, 0.39239999651908875, 0.39070001244544983, 0.38749998807907104, 0.3912999927997589, 0.3921999931335449, 0.3928000032901764, 0.3887999951839447, 0.39239999651908875, 0.3928000032901764, 0.3921999931335449, 0.3873000144958496, 0.3921999931335449, 0.3894999921321869, 0.3959999978542328, 0.38839998841285706, 0.39340001344680786, 0.3910999894142151, 0.39149999618530273, 0.39559999108314514, 0.39410001039505005, 0.388700008392334, 0.39399999380111694, 0.38960000872612, 0.38769999146461487, 0.3953999876976013, 0.3939000070095062, 0.3882000148296356, 0.39250001311302185, 0.39660000801086426, 0.39259999990463257, 0.39590001106262207, 0.3840000033378601, 0.3896999955177307, 0.4002000093460083, 0.3917999863624573, 0.3919999897480011, 0.3955000042915344, 0.39739999175071716, 0.38760000467300415, 0.3935000002384186, 0.39719998836517334, 0.3952000141143799, 0.39410001039505005, 0.3937000036239624, 0.391400009393692, 0.3971000015735626, 0.3955000042915344, 0.39820000529289246, 0.3880000114440918, 0.3937999904155731, 0.3921999931335449, 0.39640000462532043, 0.3946000039577484, 0.39320001006126404, 0.39579999446868896, 0.39629998803138733, 0.39820000529289246, 0.39399999380111694, 0.39750000834465027, 0.39649999141693115, 0.39730000495910645, 0.3971000015735626, 0.39980000257492065, 0.39559999108314514, 0.39989998936653137, 0.3970000147819519, 0.400299996137619, 0.39629998803138733, 0.3952000141143799, 0.39340001344680786, 0.3986000120639801, 0.388700008392334, 0.39750000834465027, 0.39649999141693115, 0.3962000012397766, 0.3953000009059906, 0.40130001306533813, 0.39500001072883606, 0.3946000039577484, 0.39730000495910645, 0.3968999981880188, 0.39489999413490295, 0.3978999853134155, 0.3946000039577484, 0.3935000002384186, 0.3971000015735626, 0.3952000141143799, 0.39660000801086426, 0.4002000093460083, 0.39809998869895935, 0.3968999981880188, 0.39750000834465027, 0.39980000257492065, 0.3971000015735626, 0.3935000002384186, 0.39410001039505005, 0.39809998869895935, 0.39959999918937683, 0.40149998664855957, 0.39959999918937683, 0.39329999685287476, 0.40220001339912415, 0.3955000042915344, 0.399399995803833, 0.3982999920845032, 0.4011000096797943, 0.4041999876499176, 0.3950999975204468, 0.39340001344680786, 0.3937000036239624, 0.40149998664855957, 0.3946000039577484, 0.39399999380111694, 0.38999998569488525, 0.40070000290870667, 0.3921000063419342, 0.39649999141693115, 0.39329999685287476, 0.39809998869895935, 0.4009999930858612, 0.4034000039100647, 0.397599995136261, 0.39969998598098755, 0.3935999870300293, 0.39899998903274536, 0.3917999863624573, 0.40070000290870667, 0.40139999985694885, 0.39579999446868896, 0.3961000144481659, 0.39590001106262207, 0.4004000127315521, 0.3944000005722046, 0.4025999903678894, 0.3995000123977661, 0.4002000093460083, 0.4016999900341034, 0.3971000015735626, 0.40049999952316284, 0.4020000100135803, 0.40070000290870667, 0.39969998598098755, 0.4016999900341034, 0.3944000005722046, 0.40119999647140503, 0.3935000002384186, 0.40059998631477356, 0.3982999920845032, 0.3986000120639801, 0.3946000039577484, 0.4009999930858612, 0.3970000147819519, 0.39590001106262207, 0.39969998598098755, 0.40290001034736633, 0.39719998836517334, 0.3937999904155731, 0.3986000120639801, 0.3880000114440918, 0.39480000734329224, 0.39719998836517334, 0.4004000127315521, 0.4056999981403351, 0.4016999900341034, 0.400299996137619, 0.39239999651908875, 0.4011000096797943, 0.40130001306533813, 0.39980000257492065, 0.40380001068115234, 0.4016999900341034, 0.39750000834465027, 0.398499995470047, 0.3977000117301941, 0.39890000224113464, 0.40070000290870667, 0.4018000066280365, 0.40380001068115234, 0.4032000005245209, 0.3982999920845032, 0.4004000127315521, 0.39809998869895935, 0.39899998903274536, 0.399399995803833, 0.40070000290870667, 0.40209999680519104, 0.3984000086784363, 0.4023999869823456, 0.4032999873161316, 0.397599995136261, 0.39980000257492065, 0.40139999985694885, 0.40369999408721924, 0.4034000039100647, 0.4002000093460083, 0.4043999910354614, 0.4007999897003174, 0.3993000090122223, 0.40209999680519104, 0.4018000066280365, 0.40059998631477356, 0.40220001339912415, 0.40130001306533813, 0.4047999978065491, 0.4050000011920929, 0.40130001306533813, 0.40290001034736633, 0.399399995803833, 0.399399995803833, 0.4027999937534332, 0.40209999680519104, 0.4034000039100647, 0.4065000116825104, 0.40380001068115234, 0.40049999952316284, 0.40119999647140503, 0.40049999952316284, 0.40220001339912415, 0.4007999897003174, 0.40230000019073486, 0.40290001034736633, 0.39989998936653137, 0.40310001373291016, 0.4027999937534332, 0.4052000045776367, 0.40130001306533813, 0.4016000032424927, 0.4020000100135803, 0.4025000035762787, 0.39660000801086426, 0.4007999897003174, 0.4023999869823456, 0.4027999937534332, 0.4000999927520752, 0.40380001068115234, 0.40209999680519104, 0.4049000144004822, 0.4018000066280365, 0.4016000032424927, 0.4018000066280365, 0.3991999924182892, 0.4027000069618225, 0.400299996137619, 0.4027999937534332, 0.40389999747276306, 0.4018999934196472, 0.4027000069618225, 0.40459999442100525, 0.3993000090122223, 0.4032999873161316, 0.4002000093460083, 0.4011000096797943, 0.4034000039100647, 0.4025000035762787, 0.4036000072956085, 0.4036000072956085, 0.4027000069618225, 0.4009999930858612, 0.40290001034736633, 0.40369999408721924, 0.40549999475479126, 0.4025000035762787, 0.40389999747276306, 0.4000999927520752, 0.4050999879837036, 0.40529999136924744, 0.3982999920845032, 0.40290001034736633, 0.40299999713897705, 0.4023999869823456, 0.40299999713897705, 0.4050000011920929, 0.40459999442100525, 0.4036000072956085, 0.4025000035762787, 0.40290001034736633, 0.40639999508857727, 0.4036000072956085, 0.4041999876499176, 0.3991999924182892, 0.40400001406669617, 0.4018000066280365, 0.40290001034736633, 0.40389999747276306, 0.400299996137619, 0.4027000069618225, 0.39399999380111694, 0.40310001373291016, 0.4004000127315521, 0.4000000059604645, 0.40070000290870667, 0.4034999907016754, 0.4025000035762787, 0.4058000147342682, 0.4016000032424927, 0.40220001339912415, 0.40549999475479126, 0.4009999930858612, 0.4032000005245209, 0.4043999910354614, 0.40230000019073486, 0.4025999903678894, 0.4018999934196472, 0.40230000019073486, 0.4027000069618225, 0.40470001101493835, 0.40380001068115234, 0.4027000069618225, 0.4041000008583069, 0.4016000032424927, 0.4043000042438507, 0.4011000096797943, 0.40290001034736633, 0.40139999985694885, 0.4052000045776367, 0.4020000100135803, 0.397599995136261, 0.4036000072956085, 0.40220001339912415, 0.40369999408721924, 0.4027999937534332, 0.4032000005245209, 0.39879998564720154, 0.40059998631477356, 0.4050999879837036, 0.39980000257492065, 0.40310001373291016, 0.40450000762939453, 0.4052000045776367, 0.3993000090122223, 0.40290001034736633, 0.4025000035762787, 0.39980000257492065, 0.4058000147342682, 0.40119999647140503, 0.40389999747276306, 0.39969998598098755, 0.4050000011920929, 0.40619999170303345, 0.39750000834465027, 0.4016000032424927, 0.40130001306533813, 0.4034000039100647, 0.40630000829696655, 0.4032999873161316, 0.40380001068115234, 0.4036000072956085, 0.4027999937534332, 0.4059000015258789, 0.40450000762939453, 0.40310001373291016, 0.4025999903678894, 0.39910000562667847, 0.4025000035762787, 0.40310001373291016, 0.4020000100135803, 0.4027000069618225, 0.4059999883174896, 0.4083000123500824, 0.4032999873161316, 0.4050000011920929, 0.40049999952316284, 0.40299999713897705, 0.4058000147342682, 0.40380001068115234, 0.40400001406669617, 0.40369999408721924, 0.4023999869823456, 0.40049999952316284, 0.4050999879837036, 0.4034000039100647, 0.40059998631477356, 0.4034999907016754, 0.40290001034736633, 0.40380001068115234, 0.40209999680519104, 0.4050999879837036, 0.4009000062942505, 0.4043999910354614, 0.40529999136924744, 0.40549999475479126, 0.40529999136924744, 0.4074999988079071, 0.4016000032424927, 0.4047999978065491, 0.40380001068115234, 0.4016999900341034, 0.4050999879837036, 0.40400001406669617, 0.4049000144004822, 0.4011000096797943, 0.4058000147342682, 0.3993000090122223, 0.4027000069618225, 0.40310001373291016, 0.4058000147342682, 0.40369999408721924, 0.4011000096797943, 0.4043999910354614, 0.4011000096797943, 0.4011000096797943, 0.40689998865127563, 0.40310001373291016, 0.4050999879837036, 0.4043999910354614, 0.40549999475479126, 0.4065000116825104, 0.4020000100135803, 0.4043000042438507, 0.4034000039100647, 0.4027999937534332, 0.40139999985694885, 0.39739999175071716, 0.4025000035762787, 0.4041999876499176, 0.4036000072956085, 0.40549999475479126, 0.4052000045776367, 0.4041999876499176, 0.40389999747276306, 0.40380001068115234, 0.4032999873161316, 0.40380001068115234, 0.4034000039100647, 0.4090000092983246, 0.40220001339912415, 0.4059000015258789, 0.4049000144004822, 0.40400001406669617, 0.4050000011920929, 0.4025999903678894, 0.4004000127315521, 0.40130001306533813, 0.4027999937534332, 0.4043000042438507, 0.40610000491142273, 0.4025000035762787, 0.4083000123500824, 0.3984000086784363, 0.4036000072956085, 0.40549999475479126, 0.40689998865127563, 0.3952000141143799, 0.4043000042438507, 0.40230000019073486, 0.40549999475479126, 0.40119999647140503, 0.40610000491142273, 0.40380001068115234, 0.39959999918937683, 0.4049000144004822, 0.40230000019073486, 0.4058000147342682, 0.4041999876499176, 0.4020000100135803, 0.4018000066280365, 0.4009999930858612, 0.4077000021934509, 0.4025999903678894, 0.40400001406669617, 0.4025000035762787, 0.40779998898506165, 0.4034999907016754, 0.4011000096797943, 0.4025000035762787, 0.39910000562667847, 0.40560001134872437, 0.40290001034736633, 0.4058000147342682, 0.40389999747276306, 0.4025999903678894, 0.4020000100135803, 0.4027000069618225, 0.40619999170303345, 0.4049000144004822, 0.40459999442100525, 0.4000999927520752, 0.40610000491142273, 0.4041999876499176, 0.4059000015258789, 0.40220001339912415, 0.40380001068115234, 0.4041999876499176, 0.4020000100135803, 0.4047999978065491, 0.4068000018596649, 0.4052000045776367, 0.4059000015258789, 0.40700000524520874, 0.4059999883174896, 0.4056999981403351, 0.4050999879837036, 0.4065000116825104, 0.4050999879837036, 0.4043000042438507, 0.4049000144004822, 0.4056999981403351, 0.40610000491142273, 0.4066999852657318, 0.4065999984741211, 0.4058000147342682, 0.40709999203681946, 0.40619999170303345, 0.40619999170303345, 0.4043000042438507, 0.4077000021934509, 0.4059999883174896, 0.40700000524520874, 0.40540000796318054, 0.40639999508857727, 0.4052000045776367, 0.4059000015258789, 0.40639999508857727, 0.4058000147342682, 0.40549999475479126, 0.4056999981403351, 0.40630000829696655, 0.40639999508857727, 0.4032000005245209, 0.40619999170303345, 0.40560001134872437, 0.4050999879837036, 0.4059000015258789, 0.40450000762939453, 0.4047999978065491, 0.4066999852657318, 0.40529999136924744, 0.4059000015258789, 0.4056999981403351, 0.40389999747276306, 0.4049000144004822, 0.40700000524520874, 0.4050000011920929, 0.4092000126838684, 0.40540000796318054, 0.4059999883174896, 0.4043000042438507, 0.4059000015258789, 0.40529999136924744, 0.4050000011920929, 0.4059999883174896, 0.4034000039100647, 0.4058000147342682, 0.40470001101493835, 0.4041000008583069, 0.4066999852657318, 0.4058000147342682, 0.4066999852657318, 0.4041999876499176, 0.40470001101493835, 0.40540000796318054, 0.40540000796318054, 0.4047999978065491, 0.4066999852657318, 0.4059999883174896, 0.40529999136924744, 0.4032000005245209, 0.40860000252723694, 0.40720000863075256, 0.4066999852657318, 0.40619999170303345, 0.40560001134872437, 0.4018000066280365, 0.4041000008583069, 0.40540000796318054, 0.4058000147342682, 0.4052000045776367, 0.4049000144004822, 0.40450000762939453, 0.4058000147342682, 0.4059000015258789, 0.4058000147342682, 0.40380001068115234, 0.40459999442100525, 0.4065999984741211, 0.4049000144004822, 0.40709999203681946, 0.4056999981403351, 0.40779998898506165, 0.40130001306533813, 0.40700000524520874, 0.4058000147342682, 0.4058000147342682, 0.40720000863075256, 0.40450000762939453, 0.40869998931884766, 0.40790000557899475, 0.40540000796318054, 0.4050000011920929, 0.40779998898506165, 0.4072999954223633, 0.4077000021934509, 0.4074000120162964, 0.40779998898506165, 0.4065000116825104, 0.4052000045776367, 0.4059000015258789, 0.4034999907016754, 0.4047999978065491, 0.40549999475479126, 0.4059000015258789, 0.4066999852657318, 0.40610000491142273, 0.40560001134872437, 0.40220001339912415, 0.40299999713897705, 0.40540000796318054, 0.40540000796318054, 0.40630000829696655, 0.40619999170303345, 0.4074000120162964, 0.40290001034736633, 0.4059000015258789, 0.40450000762939453, 0.4068000018596649, 0.40459999442100525, 0.4041999876499176, 0.4065999984741211, 0.40639999508857727, 0.4050999879837036, 0.40549999475479126, 0.4072999954223633, 0.40639999508857727, 0.40560001134872437, 0.4047999978065491, 0.4068000018596649, 0.40709999203681946, 0.4059000015258789, 0.4049000144004822, 0.40689998865127563, 0.40779998898506165, 0.40369999408721924, 0.4050999879837036, 0.40639999508857727, 0.4058000147342682, 0.4056999981403351, 0.4059999883174896, 0.4050999879837036, 0.40529999136924744, 0.4059999883174896, 0.4074999988079071, 0.40540000796318054, 0.40529999136924744, 0.40610000491142273, 0.41019999980926514, 0.4065999984741211, 0.40799999237060547, 0.4074000120162964, 0.4065999984741211, 0.40700000524520874, 0.4072999954223633, 0.4034999907016754, 0.4066999852657318, 0.4059000015258789, 0.4032999873161316, 0.40700000524520874, 0.4050999879837036, 0.4058000147342682, 0.4059999883174896, 0.40560001134872437, 0.4074000120162964, 0.40630000829696655, 0.40540000796318054, 0.40720000863075256, 0.4032000005245209, 0.4066999852657318, 0.4047999978065491, 0.4052000045776367, 0.40639999508857727, 0.4058000147342682, 0.4049000144004822, 0.40459999442100525, 0.4072999954223633, 0.40619999170303345, 0.4059000015258789, 0.40779998898506165, 0.40700000524520874, 0.4059999883174896, 0.40549999475479126, 0.4056999981403351, 0.40540000796318054, 0.40619999170303345, 0.4074999988079071, 0.40720000863075256, 0.40450000762939453, 0.4050000011920929, 0.40639999508857727, 0.4074999988079071, 0.4043999910354614, 0.4068000018596649, 0.4047999978065491, 0.40639999508857727, 0.40849998593330383, 0.4065999984741211, 0.4065999984741211, 0.4059999883174896, 0.40470001101493835, 0.4065000116825104, 0.40610000491142273, 0.40610000491142273, 0.4077000021934509, 0.40779998898506165, 0.4052000045776367, 0.40529999136924744, 0.4066999852657318, 0.4077000021934509, 0.4059000015258789, 0.4075999855995178, 0.4047999978065491, 0.4043000042438507, 0.4065999984741211, 0.40549999475479126, 0.4059999883174896, 0.4104999899864197, 0.40790000557899475, 0.4072999954223633, 0.40720000863075256, 0.4059999883174896, 0.4081000089645386, 0.4072999954223633, 0.40619999170303345, 0.40689998865127563, 0.40689998865127563, 0.4059999883174896, 0.40709999203681946, 0.40720000863075256, 0.40689998865127563, 0.40720000863075256, 0.4077000021934509, 0.4083000123500824, 0.4075999855995178, 0.40709999203681946, 0.4092000126838684, 0.4049000144004822, 0.40540000796318054, 0.40779998898506165, 0.4099999964237213, 0.40709999203681946, 0.4059000015258789, 0.4041000008583069, 0.40720000863075256, 0.41019999980926514, 0.40720000863075256, 0.4043000042438507, 0.4058000147342682, 0.4081999957561493, 0.40779998898506165, 0.4081000089645386, 0.4081000089645386, 0.4056999981403351, 0.4081000089645386, 0.40860000252723694, 0.40610000491142273, 0.40529999136924744, 0.4066999852657318, 0.4090000092983246, 0.40700000524520874, 0.4077000021934509, 0.4077000021934509, 0.4074999988079071, 0.4059000015258789, 0.40389999747276306, 0.40880000591278076, 0.40849998593330383, 0.4058000147342682, 0.4090999960899353, 0.40610000491142273, 0.4065000116825104, 0.40779998898506165, 0.40610000491142273, 0.4065999984741211, 0.40639999508857727, 0.4092000126838684, 0.4068000018596649, 0.40529999136924744, 0.4050000011920929, 0.4065000116825104, 0.40880000591278076, 0.40790000557899475, 0.4072999954223633, 0.40799999237060547, 0.40720000863075256, 0.40380001068115234, 0.4050999879837036], 'lr': [0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]}\n"
          ]
        }
      ]
    }
  ]
}